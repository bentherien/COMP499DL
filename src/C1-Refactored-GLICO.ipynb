{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import gc\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "from IPython.core.display import display, HTML\n",
    "from numpy.random import RandomState\n",
    "from wide_resnet import WideResNet\n",
    "from auto_augment import AutoAugment, Cutout\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cifar_loader import SmallSampleController\n",
    "\n",
    "sys.path.insert(0,'glico-learning-small-sample/glico_model')\n",
    "\n",
    "from tester import runGlico\n",
    "\n",
    "\n",
    "\n",
    "# display(HTML(\"<style>.container { width:40% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getAcc(preds,targets):\n",
    "    return np.sum([1 if preds[i] == targets[i] else 0 for i in range(len(preds))])/len(preds)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
    "    \"\"\"\n",
    "    Summary: Implements the training procedure for a given model\n",
    "    == params ==\n",
    "    model: the model to test\n",
    "    device: cuda or cpu \n",
    "    optimizer: the optimizer for our training\n",
    "    train_loader: dataloader for our train data\n",
    "    display: output flag\n",
    "    == output ==\n",
    "    the mean train loss, the train accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    lossTracker = []\n",
    "    \n",
    "    targets=[]\n",
    "    preds=[]\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossTracker.append(loss.detach())\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(output,1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            targets.extend(target.cpu().numpy())\n",
    "        \n",
    "    lossTracker = [x.item() for x in lossTracker]\n",
    "    meanLoss = np.mean(lossTracker)\n",
    "    accuracy = getAcc(preds,targets)\n",
    "    if display:\n",
    "        print('Train Epoch: {} [acc: {:.0f}%]\\tLoss: {:.6f}'.format(\n",
    "          epoch, 100. * accuracy, meanLoss))\n",
    "        \n",
    "    return accuracy, meanLoss\n",
    "\n",
    "\n",
    "def glicoTrain(model, device, train_loader, optimizer, epoch, glicoLoader,replaceProb=0.5,display=True):\n",
    "    \"\"\"\n",
    "    Summary: Implements the training procedure for a given model\n",
    "    == params ==\n",
    "    model: the model to test\n",
    "    device: cuda or cpu \n",
    "    optimizer: the optimizer for our training\n",
    "    train_loader: dataloader for our train data\n",
    "    display: output flag\n",
    "    == output ==\n",
    "    the mean train loss, the train accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    lossTracker = []\n",
    "    \n",
    "    targets=[]\n",
    "    preds=[]\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #replace samples with samples from glico with probability replaceprob\n",
    "        data = glicoLoader.replaceBatch(data,target,replaceProb) \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossTracker.append(loss.detach())\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(output,1).cpu().numpy()\n",
    "            preds.extend(pred)\n",
    "            targets.extend(target.cpu().numpy())\n",
    "        \n",
    "    lossTracker = [x.item() for x in lossTracker]\n",
    "    meanLoss = np.mean(lossTracker)\n",
    "    accuracy = getAcc(preds,targets)\n",
    "    if display:\n",
    "        print('Train Epoch: {} [acc: {:.0f}%]\\tLoss: {:.6f}'.format(\n",
    "          epoch, 100. * accuracy, meanLoss))\n",
    "        \n",
    "    return accuracy, meanLoss\n",
    "\n",
    "\n",
    "\n",
    "def test(model, device, test_loader,verbose=True):\n",
    "    \"\"\"\n",
    "    Summary: Implements the testing procedure for a given model\n",
    "    == params ==\n",
    "    model: the model to test\n",
    "    device: cuda or cpu \n",
    "    test_loader: dataloader for our test data\n",
    "    verbose: output flag\n",
    "    == output ==\n",
    "    the mean test loss, the test accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "\n",
    "    meanLoss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    if verbose: print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        mean_test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "        \n",
    "    return accuracy, meanLoss\n",
    "\n",
    "\n",
    "def checkTest(model,device,valSets,valTracker,latexTracker,epoch,\n",
    "              model_name,optim_name,lr,totalTestSamples,seed,verbose=True):\n",
    "    \"\"\"\n",
    "    Summary: checks the test accuracy, prints, and saves statistics\n",
    "    \"\"\"\n",
    "    tempAcc = []\n",
    "    tempLoss = []\n",
    "    for val_loader in valSets:\n",
    "        acc,loss = test(model, device, val_loader,verbose = False)\n",
    "        tempAcc.append(acc)\n",
    "        tempLoss.append(loss)\n",
    "        \n",
    "    meanAcc = np.mean(tempAcc)\n",
    "    stdAcc = np.std(tempAcc)\n",
    "    \n",
    "    meanLoss = np.mean(tempLoss)\n",
    "    if verbose:\n",
    "        print('[Trained for {} epochs and tested on {} sets of 2000 images]\\\n",
    "        Avg Acc: {:.2f} +- {:.2f} , Avg Loss: {:.2f}'.format(\n",
    "            epoch,VALIDATION_SET_NUM,meanAcc,stdAcc,meanLoss))\n",
    "        \n",
    "        \n",
    "    tableRow = getLatexRow(architecture=model_name,epoch=epoch,accuracy=meanAcc,optim=optim_name,\n",
    "                           lr=lr,totalTestSamples=totalTestSamples,dataAug=\"Nothing\",\n",
    "                           seed=seed,title=False)\n",
    "    \n",
    "    latexTracker.append(tableRow)\n",
    "        \n",
    "    valTracker[\"allLoss\"].extend(tempLoss)\n",
    "    valTracker[\"allAcc\"].extend(tempAcc)\n",
    "    valTracker[\"meanLoss\"].append(meanLoss)\n",
    "    valTracker[\"meanAcc\"].append(meanAcc)\n",
    "    valTracker[\"stdAcc\"].append(stdAcc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLatexRow(architecture,epoch,accuracy,optim,lr,\n",
    "                totalTestSamples,dataAug,seed,title=False):\n",
    "    \"\"\"\n",
    "    Summary: generates one row of latex for a results table\n",
    "    \"\"\"\n",
    "    categories = [\"Model\",\"Epoch\",\"Accuracy\",\"Optimizer\",\"lr\",\"Test Sample Num\",\n",
    "                  \"data augmentation\",\"seed\"]\n",
    "    row = [str(architecture),str(epoch),str(round(accuracy,3)),str(optim),\n",
    "           str(lr),str(totalTestSamples),str(dataAug),str(seed)]\n",
    "    \n",
    "    if title:\n",
    "        c = \"&\".join(categories)\n",
    "        r = \"&\".join(row)\n",
    "        return \"{}\\\\\\\\\\n{}\\\\\\\\\".format(c,r)\n",
    "    else:\n",
    "        r = \"&\".join(row)\n",
    "        return \"{}\\\\\\\\\".format(r)\n",
    "    \n",
    "    \n",
    "def plot(xlist,ylist,xlab,ylab,title,color,label,savedir=\".\",save=False):\n",
    "    \"\"\"\n",
    "    Summary: plots the given list of numbers against its idices and \n",
    "    allows for high resolution saving\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.plot(xlist,ylist,color=color,marker=\".\",label=label)\n",
    "    plt.legend()\n",
    "    \n",
    "    if save:\n",
    "        if not os.path.isdir(savedir):\n",
    "            os.mkdir(savedir)\n",
    "        filepath = os.path.join(savedir,\"{}\".format(title))\n",
    "        plt.savefig(filepath+\".pdf\")\n",
    "        os.system(\"pdftoppm -png -r 300 {}.pdf {}.png\".format(filepath,filepath))\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(model_name):\n",
    "    if \"wide\" in model_name.lower():\n",
    "        return WideResNet(28, 10, num_classes=10)\n",
    "    elif \"fix\" in model_name.lower():\n",
    "        return EfficientNet.from_pretrained(model_name) # change to not be pretrained\n",
    "    \n",
    "    \n",
    "def getOptimizer128(optimizer_name,parameters):\n",
    "    if \"sgd\" in  optimizer_name.lower():\n",
    "        LR = 0.09\n",
    "        optim = torch.optim.SGD(parameters, \n",
    "                                  lr=LR, momentum=0.9,\n",
    "                                  weight_decay=0.0005)\n",
    "        return optim, LR\n",
    "    elif \"adam\" in optimizer_name.lower():\n",
    "        LR = 0.001\n",
    "        optim = torch.optim.Adam(parameters, \n",
    "                              lr=LR, weight_decay=0)\n",
    "        return optim, LR\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Generated new permutation of the CIFAR train dataset with                 seed:1620010424, train sample num: 100, test sample num: 2000\n",
      "\n",
      "\n",
      "\n",
      "[*** NEW PRINT ***]nag_params: NAGParams(nz=512, force_l2=False, is_pixel=True, z_init='rndm', is_classifier=True, disc_net='conv', loss='ce', data_name='cifar-10', noise_proj=True, shot=0), rn: tester.py_cifar100_test_run, dataset <class 'list'>\n",
      "\n",
      "\n",
      "\n",
      "[DEBUG] data name=cifar-10, data res = 32\n",
      "[NEW CODE] image_params:ImageParams(sz=(32, 32), nc=3, n=100, mu=None, sd=None)\n",
      "not eval | augment : TRUE\n",
      "=>Generated data loader, res=32, workers=6 transform=Compose(\n",
      "    ToTensor()\n",
      ") sampler=None\n",
      "[DEBUG] dataset name: <class 'torch.utils.data.dataset.subset'>,offset_labels=0\n",
      "torch.Size([100, 512])\n",
      "init_models_weights(self): init rndm\n",
      "num classes = 10\n",
      "dataset size = 100\n",
      "not eval | augment : TRUE\n",
      "=>Generated data loader, res=32, workers=6 transform=Compose(\n",
      "    ToTensor()\n",
      ") sampler=None\n",
      "=>epoch:0/750  resolution:32 batch:128, lr1.000000e-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/Documents/github/COMP499DL/src/glico-learning-small-sample/glico_model/utils.py:168: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/1]\tTime  0.645 ( 0.645)\tData  0.260 ( 0.260)\tLoss 8.55879 (8.55879)\td_Loss 2.32977 (2.32977)\n",
      "=>NAG Epoch: 0 Error: 8.558786392211914, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_0.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_0.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_0.pkl\n",
      "Show images...\n",
      "=>epoch:1/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [1][0/1]\tTime  0.300 ( 0.300)\tData  0.271 ( 0.271)\tLoss 8.51396 (8.51396)\td_Loss 2.34086 (2.34086)\n",
      "=>NAG Epoch: 1 Error: 8.513964653015137, Time:     0.01m\n",
      "=>epoch:2/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [2][0/1]\tTime  0.296 ( 0.296)\tData  0.267 ( 0.267)\tLoss 8.42989 (8.42989)\td_Loss 2.35310 (2.35310)\n",
      "=>NAG Epoch: 2 Error: 8.429893493652344, Time:     0.01m\n",
      "=>epoch:3/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [3][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 8.27003 (8.27003)\td_Loss 2.31783 (2.31783)\n",
      "=>NAG Epoch: 3 Error: 8.270033836364746, Time:     0.01m\n",
      "=>epoch:4/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [4][0/1]\tTime  0.299 ( 0.299)\tData  0.267 ( 0.267)\tLoss 8.19332 (8.19332)\td_Loss 2.35455 (2.35455)\n",
      "=>NAG Epoch: 4 Error: 8.193318367004395, Time:     0.01m\n",
      "=>epoch:5/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [5][0/1]\tTime  0.302 ( 0.302)\tData  0.271 ( 0.271)\tLoss 8.11264 (8.11264)\td_Loss 2.30928 (2.30928)\n",
      "=>NAG Epoch: 5 Error: 8.112638473510742, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_5.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_5.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_5.pkl\n",
      "=>epoch:6/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [6][0/1]\tTime  0.307 ( 0.307)\tData  0.276 ( 0.276)\tLoss 8.08872 (8.08872)\td_Loss 2.32535 (2.32535)\n",
      "=>NAG Epoch: 6 Error: 8.08871841430664, Time:     0.01m\n",
      "=>epoch:7/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [7][0/1]\tTime  0.321 ( 0.321)\tData  0.289 ( 0.289)\tLoss 8.07093 (8.07093)\td_Loss 2.35959 (2.35959)\n",
      "=>NAG Epoch: 7 Error: 8.070927619934082, Time:     0.01m\n",
      "=>epoch:8/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [8][0/1]\tTime  0.322 ( 0.322)\tData  0.291 ( 0.291)\tLoss 8.04106 (8.04106)\td_Loss 2.35889 (2.35889)\n",
      "=>NAG Epoch: 8 Error: 8.041061401367188, Time:     0.01m\n",
      "=>epoch:9/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [9][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 8.00228 (8.00228)\td_Loss 2.35378 (2.35378)\n",
      "=>NAG Epoch: 9 Error: 8.002283096313477, Time:     0.01m\n",
      "=>epoch:10/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [10][0/1]\tTime  0.304 ( 0.304)\tData  0.273 ( 0.273)\tLoss 7.95256 (7.95256)\td_Loss 2.32935 (2.32935)\n",
      "=>NAG Epoch: 10 Error: 7.952556610107422, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_10.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_10.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_10.pkl\n",
      "=>epoch:11/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [11][0/1]\tTime  0.319 ( 0.319)\tData  0.288 ( 0.288)\tLoss 7.91294 (7.91294)\td_Loss 2.31289 (2.31289)\n",
      "=>NAG Epoch: 11 Error: 7.91294002532959, Time:     0.01m\n",
      "=>epoch:12/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [12][0/1]\tTime  0.309 ( 0.309)\tData  0.279 ( 0.279)\tLoss 7.85462 (7.85462)\td_Loss 2.28571 (2.28571)\n",
      "=>NAG Epoch: 12 Error: 7.854619979858398, Time:     0.01m\n",
      "=>epoch:13/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [13][0/1]\tTime  0.318 ( 0.318)\tData  0.287 ( 0.287)\tLoss 7.85332 (7.85332)\td_Loss 2.32837 (2.32837)\n",
      "=>NAG Epoch: 13 Error: 7.853316307067871, Time:     0.01m\n",
      "=>epoch:14/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [14][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 7.84188 (7.84188)\td_Loss 2.35670 (2.35670)\n",
      "=>NAG Epoch: 14 Error: 7.841878414154053, Time:     0.01m\n",
      "=>epoch:15/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [15][0/1]\tTime  0.317 ( 0.317)\tData  0.287 ( 0.287)\tLoss 7.81978 (7.81978)\td_Loss 2.34772 (2.34772)\n",
      "=>NAG Epoch: 15 Error: 7.819779396057129, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_15.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_15.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_15.pkl\n",
      "=>epoch:16/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [16][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 7.72800 (7.72800)\td_Loss 2.29020 (2.29020)\n",
      "=>NAG Epoch: 16 Error: 7.727999687194824, Time:     0.01m\n",
      "=>epoch:17/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [17][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 7.74376 (7.74376)\td_Loss 2.32812 (2.32812)\n",
      "=>NAG Epoch: 17 Error: 7.743762016296387, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:18/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [18][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 7.64773 (7.64773)\td_Loss 2.25318 (2.25318)\n",
      "=>NAG Epoch: 18 Error: 7.647729396820068, Time:     0.01m\n",
      "=>epoch:19/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [19][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 7.64290 (7.64290)\td_Loss 2.24781 (2.24781)\n",
      "=>NAG Epoch: 19 Error: 7.64289665222168, Time:     0.01m\n",
      "=>epoch:20/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [20][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 7.58246 (7.58246)\td_Loss 2.23331 (2.23331)\n",
      "=>NAG Epoch: 20 Error: 7.582459926605225, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_20.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_20.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_20.pkl\n",
      "=>epoch:21/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [21][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 7.54810 (7.54810)\td_Loss 2.19505 (2.19505)\n",
      "=>NAG Epoch: 21 Error: 7.548102378845215, Time:     0.01m\n",
      "=>epoch:22/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [22][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 7.49744 (7.49744)\td_Loss 2.16473 (2.16473)\n",
      "=>NAG Epoch: 22 Error: 7.497437953948975, Time:     0.01m\n",
      "=>epoch:23/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [23][0/1]\tTime  0.313 ( 0.313)\tData  0.284 ( 0.284)\tLoss 7.45175 (7.45175)\td_Loss 2.16086 (2.16086)\n",
      "=>NAG Epoch: 23 Error: 7.451747894287109, Time:     0.01m\n",
      "=>epoch:24/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [24][0/1]\tTime  0.304 ( 0.304)\tData  0.273 ( 0.273)\tLoss 7.47022 (7.47022)\td_Loss 2.16599 (2.16599)\n",
      "=>NAG Epoch: 24 Error: 7.470220565795898, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:25/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [25][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 7.37475 (7.37475)\td_Loss 2.12996 (2.12996)\n",
      "=>NAG Epoch: 25 Error: 7.374749660491943, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_25.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_25.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_25.pkl\n",
      "=>epoch:26/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [26][0/1]\tTime  0.291 ( 0.291)\tData  0.260 ( 0.260)\tLoss 7.32763 (7.32763)\td_Loss 2.07272 (2.07272)\n",
      "=>NAG Epoch: 26 Error: 7.327630996704102, Time:     0.01m\n",
      "=>epoch:27/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [27][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 7.31518 (7.31518)\td_Loss 2.06759 (2.06759)\n",
      "=>NAG Epoch: 27 Error: 7.315176963806152, Time:     0.01m\n",
      "=>epoch:28/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [28][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 7.30304 (7.30304)\td_Loss 2.08156 (2.08156)\n",
      "=>NAG Epoch: 28 Error: 7.303040504455566, Time:     0.01m\n",
      "=>epoch:29/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [29][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 7.21216 (7.21216)\td_Loss 2.06256 (2.06256)\n",
      "=>NAG Epoch: 29 Error: 7.212161064147949, Time:     0.01m\n",
      "=>epoch:30/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [30][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 7.18213 (7.18213)\td_Loss 1.97215 (1.97215)\n",
      "=>NAG Epoch: 30 Error: 7.182125091552734, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_30.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_30.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_30.pkl\n",
      "=>epoch:31/750  resolution:32 batch:128, lr1.000000e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [31][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 7.07978 (7.07978)\td_Loss 1.89031 (1.89031)\n",
      "=>NAG Epoch: 31 Error: 7.079784393310547, Time:     0.01m\n",
      "=>epoch:32/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [32][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 7.08693 (7.08693)\td_Loss 1.87127 (1.87127)\n",
      "=>NAG Epoch: 32 Error: 7.086932182312012, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:33/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [33][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 7.02147 (7.02147)\td_Loss 1.86036 (1.86036)\n",
      "=>NAG Epoch: 33 Error: 7.021470546722412, Time:     0.01m\n",
      "=>epoch:34/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [34][0/1]\tTime  0.310 ( 0.310)\tData  0.280 ( 0.280)\tLoss 7.02162 (7.02162)\td_Loss 1.83507 (1.83507)\n",
      "=>NAG Epoch: 34 Error: 7.021623134613037, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:35/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [35][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 6.95557 (6.95557)\td_Loss 1.84863 (1.84863)\n",
      "=>NAG Epoch: 35 Error: 6.955574989318848, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_35.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_35.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_35.pkl\n",
      "=>epoch:36/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [36][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 6.96123 (6.96123)\td_Loss 1.84113 (1.84113)\n",
      "=>NAG Epoch: 36 Error: 6.961226940155029, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:37/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [37][0/1]\tTime  0.328 ( 0.328)\tData  0.297 ( 0.297)\tLoss 6.86853 (6.86853)\td_Loss 1.80594 (1.80594)\n",
      "=>NAG Epoch: 37 Error: 6.868531227111816, Time:     0.01m\n",
      "=>epoch:38/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [38][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 6.84963 (6.84963)\td_Loss 1.70498 (1.70498)\n",
      "=>NAG Epoch: 38 Error: 6.8496294021606445, Time:     0.01m\n",
      "=>epoch:39/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [39][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 6.78704 (6.78704)\td_Loss 1.69841 (1.69841)\n",
      "=>NAG Epoch: 39 Error: 6.787042617797852, Time:     0.01m\n",
      "=>epoch:40/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [40][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 6.78501 (6.78501)\td_Loss 1.68754 (1.68754)\n",
      "=>NAG Epoch: 40 Error: 6.785009860992432, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_40.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_40.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_40.pkl\n",
      "=>epoch:41/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [41][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 6.71203 (6.71203)\td_Loss 1.67693 (1.67693)\n",
      "=>NAG Epoch: 41 Error: 6.712029933929443, Time:     0.01m\n",
      "=>epoch:42/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [42][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 6.72562 (6.72562)\td_Loss 1.67216 (1.67216)\n",
      "=>NAG Epoch: 42 Error: 6.725620746612549, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:43/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [43][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 6.65291 (6.65291)\td_Loss 1.66965 (1.66965)\n",
      "=>NAG Epoch: 43 Error: 6.652907371520996, Time:     0.01m\n",
      "=>epoch:44/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [44][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 6.65758 (6.65758)\td_Loss 1.66759 (1.66759)\n",
      "=>NAG Epoch: 44 Error: 6.657577037811279, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:45/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [45][0/1]\tTime  0.292 ( 0.292)\tData  0.261 ( 0.261)\tLoss 6.60636 (6.60636)\td_Loss 1.66655 (1.66655)\n",
      "=>NAG Epoch: 45 Error: 6.6063551902771, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_45.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_45.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_45.pkl\n",
      "=>epoch:46/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [46][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 6.58445 (6.58445)\td_Loss 1.66557 (1.66557)\n",
      "=>NAG Epoch: 46 Error: 6.584445476531982, Time:     0.01m\n",
      "=>epoch:47/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [47][0/1]\tTime  0.285 ( 0.285)\tData  0.255 ( 0.255)\tLoss 6.54723 (6.54723)\td_Loss 1.66548 (1.66548)\n",
      "=>NAG Epoch: 47 Error: 6.547229766845703, Time:     0.01m\n",
      "=>epoch:48/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [48][0/1]\tTime  0.301 ( 0.301)\tData  0.270 ( 0.270)\tLoss 6.54071 (6.54071)\td_Loss 1.66348 (1.66348)\n",
      "=>NAG Epoch: 48 Error: 6.540712833404541, Time:     0.01m\n",
      "=>epoch:49/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [49][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 6.51734 (6.51734)\td_Loss 1.66591 (1.66591)\n",
      "=>NAG Epoch: 49 Error: 6.517338275909424, Time:     0.01m\n",
      "=>epoch:50/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [50][0/1]\tTime  0.358 ( 0.358)\tData  0.325 ( 0.325)\tLoss 6.47281 (6.47281)\td_Loss 1.66215 (1.66215)\n",
      "=>NAG Epoch: 50 Error: 6.472805976867676, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_50.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_50.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_50.pkl\n",
      "Show images...\n",
      "=>epoch:51/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [51][0/1]\tTime  0.310 ( 0.310)\tData  0.280 ( 0.280)\tLoss 6.45437 (6.45437)\td_Loss 1.66426 (1.66426)\n",
      "=>NAG Epoch: 51 Error: 6.454373836517334, Time:     0.01m\n",
      "=>epoch:52/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [52][0/1]\tTime  0.307 ( 0.307)\tData  0.276 ( 0.276)\tLoss 6.39870 (6.39870)\td_Loss 1.66123 (1.66123)\n",
      "=>NAG Epoch: 52 Error: 6.39870023727417, Time:     0.01m\n",
      "=>epoch:53/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [53][0/1]\tTime  0.298 ( 0.298)\tData  0.266 ( 0.266)\tLoss 6.40247 (6.40247)\td_Loss 1.66420 (1.66420)\n",
      "=>NAG Epoch: 53 Error: 6.402467250823975, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:54/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [54][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 6.33325 (6.33325)\td_Loss 1.65953 (1.65953)\n",
      "=>NAG Epoch: 54 Error: 6.333245754241943, Time:     0.01m\n",
      "=>epoch:55/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [55][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 6.35374 (6.35374)\td_Loss 1.66299 (1.66299)\n",
      "=>NAG Epoch: 55 Error: 6.35373592376709, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:56/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [56][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 6.28012 (6.28012)\td_Loss 1.65886 (1.65886)\n",
      "=>NAG Epoch: 56 Error: 6.280121803283691, Time:     0.01m\n",
      "=>epoch:57/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [57][0/1]\tTime  0.329 ( 0.329)\tData  0.298 ( 0.298)\tLoss 6.29988 (6.29988)\td_Loss 1.66088 (1.66088)\n",
      "=>NAG Epoch: 57 Error: 6.299876689910889, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:58/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [58][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 6.26737 (6.26737)\td_Loss 1.66167 (1.66167)\n",
      "=>NAG Epoch: 58 Error: 6.26737117767334, Time:     0.01m\n",
      "=>epoch:59/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [59][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 6.32364 (6.32364)\td_Loss 1.66269 (1.66269)\n",
      "=>NAG Epoch: 59 Error: 6.323642730712891, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:60/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [60][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 6.23570 (6.23570)\td_Loss 1.65846 (1.65846)\n",
      "=>NAG Epoch: 60 Error: 6.23570442199707, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_60.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_60.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_60.pkl\n",
      "=>epoch:61/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [61][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 6.23384 (6.23384)\td_Loss 1.65856 (1.65856)\n",
      "=>NAG Epoch: 61 Error: 6.233843803405762, Time:     0.01m\n",
      "=>epoch:62/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [62][0/1]\tTime  0.310 ( 0.310)\tData  0.279 ( 0.279)\tLoss 6.19165 (6.19165)\td_Loss 1.65497 (1.65497)\n",
      "=>NAG Epoch: 62 Error: 6.191654205322266, Time:     0.01m\n",
      "=>epoch:63/750  resolution:32 batch:128, lr1.000000e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 6.15942 (6.15942)\td_Loss 1.65037 (1.65037)\n",
      "=>NAG Epoch: 63 Error: 6.159422874450684, Time:     0.01m\n",
      "=>epoch:64/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [64][0/1]\tTime  0.294 ( 0.294)\tData  0.262 ( 0.262)\tLoss 6.13697 (6.13697)\td_Loss 1.62957 (1.62957)\n",
      "=>NAG Epoch: 64 Error: 6.136966705322266, Time:     0.01m\n",
      "=>epoch:65/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [65][0/1]\tTime  0.302 ( 0.302)\tData  0.271 ( 0.271)\tLoss 6.08325 (6.08325)\td_Loss 1.61898 (1.61898)\n",
      "=>NAG Epoch: 65 Error: 6.083247184753418, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_65.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_65.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_65.pkl\n",
      "=>epoch:66/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [66][0/1]\tTime  0.307 ( 0.307)\tData  0.275 ( 0.275)\tLoss 6.08051 (6.08051)\td_Loss 1.60427 (1.60427)\n",
      "=>NAG Epoch: 66 Error: 6.080510139465332, Time:     0.01m\n",
      "=>epoch:67/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [67][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 6.01998 (6.01998)\td_Loss 1.59908 (1.59908)\n",
      "=>NAG Epoch: 67 Error: 6.019981861114502, Time:     0.01m\n",
      "=>epoch:68/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [68][0/1]\tTime  0.320 ( 0.320)\tData  0.290 ( 0.290)\tLoss 6.02726 (6.02726)\td_Loss 1.58579 (1.58579)\n",
      "=>NAG Epoch: 68 Error: 6.027261257171631, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:69/750  resolution:32 batch:128, lr1.000000e-03\n",
      "Epoch: [69][0/1]\tTime  0.299 ( 0.299)\tData  0.267 ( 0.267)\tLoss 5.95903 (5.95903)\td_Loss 1.58184 (1.58184)\n",
      "=>NAG Epoch: 69 Error: 5.959028244018555, Time:     0.01m\n",
      "=>epoch:70/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [70][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 5.97682 (5.97682)\td_Loss 1.57927 (1.57927)\n",
      "=>NAG Epoch: 70 Error: 5.976815223693848, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:71/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [71][0/1]\tTime  0.297 ( 0.297)\tData  0.268 ( 0.268)\tLoss 5.77780 (5.77780)\td_Loss 1.57302 (1.57302)\n",
      "=>NAG Epoch: 71 Error: 5.777798652648926, Time:     0.01m\n",
      "=>epoch:72/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [72][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 5.75956 (5.75956)\td_Loss 1.57511 (1.57511)\n",
      "=>NAG Epoch: 72 Error: 5.75956392288208, Time:     0.01m\n",
      "=>epoch:73/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [73][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 5.74004 (5.74004)\td_Loss 1.57351 (1.57351)\n",
      "=>NAG Epoch: 73 Error: 5.740041255950928, Time:     0.01m\n",
      "=>epoch:74/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [74][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 5.71190 (5.71190)\td_Loss 1.57363 (1.57363)\n",
      "=>NAG Epoch: 74 Error: 5.711901664733887, Time:     0.01m\n",
      "=>epoch:75/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [75][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 5.69581 (5.69581)\td_Loss 1.57309 (1.57309)\n",
      "=>NAG Epoch: 75 Error: 5.695814609527588, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_75.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_75.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_75.pkl\n",
      "=>epoch:76/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [76][0/1]\tTime  0.323 ( 0.323)\tData  0.293 ( 0.293)\tLoss 5.67110 (5.67110)\td_Loss 1.57117 (1.57117)\n",
      "=>NAG Epoch: 76 Error: 5.671099662780762, Time:     0.01m\n",
      "=>epoch:77/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [77][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 5.65620 (5.65620)\td_Loss 1.56621 (1.56621)\n",
      "=>NAG Epoch: 77 Error: 5.656204700469971, Time:     0.01m\n",
      "=>epoch:78/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [78][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 5.63214 (5.63214)\td_Loss 1.56533 (1.56533)\n",
      "=>NAG Epoch: 78 Error: 5.632135391235352, Time:     0.01m\n",
      "=>epoch:79/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [79][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 5.62005 (5.62005)\td_Loss 1.56544 (1.56544)\n",
      "=>NAG Epoch: 79 Error: 5.620053291320801, Time:     0.01m\n",
      "=>epoch:80/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [80][0/1]\tTime  0.302 ( 0.302)\tData  0.272 ( 0.272)\tLoss 5.59270 (5.59270)\td_Loss 1.56387 (1.56387)\n",
      "=>NAG Epoch: 80 Error: 5.592703819274902, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_80.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_80.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_80.pkl\n",
      "=>epoch:81/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [81][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 5.58666 (5.58666)\td_Loss 1.56392 (1.56392)\n",
      "=>NAG Epoch: 81 Error: 5.586660385131836, Time:     0.01m\n",
      "=>epoch:82/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [82][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 5.56214 (5.56214)\td_Loss 1.56414 (1.56414)\n",
      "=>NAG Epoch: 82 Error: 5.562135219573975, Time:     0.01m\n",
      "=>epoch:83/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [83][0/1]\tTime  0.300 ( 0.300)\tData  0.270 ( 0.270)\tLoss 5.55667 (5.55667)\td_Loss 1.56401 (1.56401)\n",
      "=>NAG Epoch: 83 Error: 5.556674957275391, Time:     0.01m\n",
      "=>epoch:84/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [84][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 5.52988 (5.52988)\td_Loss 1.56385 (1.56385)\n",
      "=>NAG Epoch: 84 Error: 5.529876708984375, Time:     0.01m\n",
      "=>epoch:85/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [85][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 5.52722 (5.52722)\td_Loss 1.56405 (1.56405)\n",
      "=>NAG Epoch: 85 Error: 5.527224540710449, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_85.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_85.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_85.pkl\n",
      "=>epoch:86/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [86][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 5.50147 (5.50147)\td_Loss 1.56419 (1.56419)\n",
      "=>NAG Epoch: 86 Error: 5.501471519470215, Time:     0.01m\n",
      "=>epoch:87/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [87][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 5.49483 (5.49483)\td_Loss 1.56407 (1.56407)\n",
      "=>NAG Epoch: 87 Error: 5.494830131530762, Time:     0.01m\n",
      "=>epoch:88/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [88][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 5.47522 (5.47522)\td_Loss 1.56375 (1.56375)\n",
      "=>NAG Epoch: 88 Error: 5.475224494934082, Time:     0.01m\n",
      "=>epoch:89/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [89][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 5.46978 (5.46978)\td_Loss 1.56354 (1.56354)\n",
      "=>NAG Epoch: 89 Error: 5.469778060913086, Time:     0.01m\n",
      "=>epoch:90/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [90][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 5.44756 (5.44756)\td_Loss 1.56380 (1.56380)\n",
      "=>NAG Epoch: 90 Error: 5.447555065155029, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_90.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_90.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_90.pkl\n",
      "=>epoch:91/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [91][0/1]\tTime  0.316 ( 0.316)\tData  0.286 ( 0.286)\tLoss 5.44347 (5.44347)\td_Loss 1.56314 (1.56314)\n",
      "=>NAG Epoch: 91 Error: 5.4434661865234375, Time:     0.01m\n",
      "=>epoch:92/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [92][0/1]\tTime  0.307 ( 0.307)\tData  0.277 ( 0.277)\tLoss 5.41975 (5.41975)\td_Loss 1.56220 (1.56220)\n",
      "=>NAG Epoch: 92 Error: 5.419750690460205, Time:     0.01m\n",
      "=>epoch:93/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [93][0/1]\tTime  0.298 ( 0.298)\tData  0.269 ( 0.269)\tLoss 5.41529 (5.41529)\td_Loss 1.56113 (1.56113)\n",
      "=>NAG Epoch: 93 Error: 5.41528844833374, Time:     0.01m\n",
      "=>epoch:94/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [94][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 5.39056 (5.39056)\td_Loss 1.55623 (1.55623)\n",
      "=>NAG Epoch: 94 Error: 5.39055871963501, Time:     0.01m\n",
      "=>epoch:95/750  resolution:32 batch:128, lr5.000000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [95][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 5.38796 (5.38796)\td_Loss 1.55323 (1.55323)\n",
      "=>NAG Epoch: 95 Error: 5.387956142425537, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_95.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_95.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_95.pkl\n",
      "=>epoch:96/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [96][0/1]\tTime  0.289 ( 0.289)\tData  0.258 ( 0.258)\tLoss 5.36667 (5.36667)\td_Loss 1.55305 (1.55305)\n",
      "=>NAG Epoch: 96 Error: 5.366673469543457, Time:     0.01m\n",
      "=>epoch:97/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [97][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 5.36712 (5.36712)\td_Loss 1.55164 (1.55164)\n",
      "=>NAG Epoch: 97 Error: 5.3671183586120605, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:98/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [98][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 5.34139 (5.34139)\td_Loss 1.55092 (1.55092)\n",
      "=>NAG Epoch: 98 Error: 5.341391563415527, Time:     0.01m\n",
      "=>epoch:99/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [99][0/1]\tTime  0.324 ( 0.324)\tData  0.292 ( 0.292)\tLoss 5.33400 (5.33400)\td_Loss 1.54537 (1.54537)\n",
      "=>NAG Epoch: 99 Error: 5.334001541137695, Time:     0.01m\n",
      "=>epoch:100/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [100][0/1]\tTime  0.349 ( 0.349)\tData  0.319 ( 0.319)\tLoss 5.31431 (5.31431)\td_Loss 1.54297 (1.54297)\n",
      "=>NAG Epoch: 100 Error: 5.314309597015381, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_100.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_100.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_100.pkl\n",
      "Show images...\n",
      "=>epoch:101/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [101][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 5.31034 (5.31034)\td_Loss 1.53979 (1.53979)\n",
      "=>NAG Epoch: 101 Error: 5.310336112976074, Time:     0.01m\n",
      "=>epoch:102/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [102][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 5.28621 (5.28621)\td_Loss 1.53097 (1.53097)\n",
      "=>NAG Epoch: 102 Error: 5.286210060119629, Time:     0.01m\n",
      "=>epoch:103/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [103][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 5.27762 (5.27762)\td_Loss 1.52701 (1.52701)\n",
      "=>NAG Epoch: 103 Error: 5.277622222900391, Time:     0.01m\n",
      "=>epoch:104/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [104][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 5.26515 (5.26515)\td_Loss 1.52425 (1.52425)\n",
      "=>NAG Epoch: 104 Error: 5.265151023864746, Time:     0.01m\n",
      "=>epoch:105/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [105][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 5.25484 (5.25484)\td_Loss 1.52120 (1.52120)\n",
      "=>NAG Epoch: 105 Error: 5.2548441886901855, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_105.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_105.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_105.pkl\n",
      "=>epoch:106/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [106][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 5.22790 (5.22790)\td_Loss 1.50901 (1.50901)\n",
      "=>NAG Epoch: 106 Error: 5.2278971672058105, Time:     0.01m\n",
      "=>epoch:107/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [107][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 5.21942 (5.21942)\td_Loss 1.49917 (1.49917)\n",
      "=>NAG Epoch: 107 Error: 5.219417095184326, Time:     0.01m\n",
      "=>epoch:108/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [108][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 5.20201 (5.20201)\td_Loss 1.49397 (1.49397)\n",
      "=>NAG Epoch: 108 Error: 5.2020111083984375, Time:     0.01m\n",
      "=>epoch:109/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [109][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 5.19171 (5.19171)\td_Loss 1.48518 (1.48518)\n",
      "=>NAG Epoch: 109 Error: 5.19171142578125, Time:     0.01m\n",
      "=>epoch:110/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [110][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 5.17452 (5.17452)\td_Loss 1.48035 (1.48035)\n",
      "=>NAG Epoch: 110 Error: 5.174520015716553, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_110.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_110.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_110.pkl\n",
      "=>epoch:111/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [111][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 5.16952 (5.16952)\td_Loss 1.48028 (1.48028)\n",
      "=>NAG Epoch: 111 Error: 5.169517993927002, Time:     0.01m\n",
      "=>epoch:112/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [112][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 5.15070 (5.15070)\td_Loss 1.47912 (1.47912)\n",
      "=>NAG Epoch: 112 Error: 5.150701522827148, Time:     0.01m\n",
      "=>epoch:113/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [113][0/1]\tTime  0.289 ( 0.289)\tData  0.258 ( 0.258)\tLoss 5.14648 (5.14648)\td_Loss 1.47916 (1.47916)\n",
      "=>NAG Epoch: 113 Error: 5.146478652954102, Time:     0.01m\n",
      "=>epoch:114/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [114][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 5.12670 (5.12670)\td_Loss 1.47780 (1.47780)\n",
      "=>NAG Epoch: 114 Error: 5.126701354980469, Time:     0.01m\n",
      "=>epoch:115/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [115][0/1]\tTime  0.296 ( 0.296)\tData  0.267 ( 0.267)\tLoss 5.12565 (5.12565)\td_Loss 1.47572 (1.47572)\n",
      "=>NAG Epoch: 115 Error: 5.125649929046631, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_115.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_115.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_115.pkl\n",
      "=>epoch:116/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [116][0/1]\tTime  0.286 ( 0.286)\tData  0.257 ( 0.257)\tLoss 5.10026 (5.10026)\td_Loss 1.46892 (1.46892)\n",
      "=>NAG Epoch: 116 Error: 5.100256443023682, Time:     0.01m\n",
      "=>epoch:117/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [117][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 5.10459 (5.10459)\td_Loss 1.46991 (1.46991)\n",
      "=>NAG Epoch: 117 Error: 5.104586601257324, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:118/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [118][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 5.07803 (5.07803)\td_Loss 1.46945 (1.46945)\n",
      "=>NAG Epoch: 118 Error: 5.078031063079834, Time:     0.01m\n",
      "=>epoch:119/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [119][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 5.08532 (5.08532)\td_Loss 1.46958 (1.46958)\n",
      "=>NAG Epoch: 119 Error: 5.085315227508545, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:120/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [120][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 5.05726 (5.05726)\td_Loss 1.46903 (1.46903)\n",
      "=>NAG Epoch: 120 Error: 5.057258605957031, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_120.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_120.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_120.pkl\n",
      "=>epoch:121/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [121][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 5.06100 (5.06100)\td_Loss 1.46970 (1.46970)\n",
      "=>NAG Epoch: 121 Error: 5.061001300811768, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:122/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [122][0/1]\tTime  0.315 ( 0.315)\tData  0.285 ( 0.285)\tLoss 5.03407 (5.03407)\td_Loss 1.46916 (1.46916)\n",
      "=>NAG Epoch: 122 Error: 5.034073829650879, Time:     0.01m\n",
      "=>epoch:123/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [123][0/1]\tTime  0.294 ( 0.294)\tData  0.262 ( 0.262)\tLoss 5.03932 (5.03932)\td_Loss 1.46961 (1.46961)\n",
      "=>NAG Epoch: 123 Error: 5.039318084716797, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:124/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [124][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 5.01506 (5.01506)\td_Loss 1.46937 (1.46937)\n",
      "=>NAG Epoch: 124 Error: 5.015059471130371, Time:     0.01m\n",
      "=>epoch:125/750  resolution:32 batch:128, lr5.000000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [125][0/1]\tTime  0.329 ( 0.329)\tData  0.297 ( 0.297)\tLoss 5.01804 (5.01804)\td_Loss 1.46905 (1.46905)\n",
      "=>NAG Epoch: 125 Error: 5.018039226531982, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:126/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [126][0/1]\tTime  0.310 ( 0.310)\tData  0.279 ( 0.279)\tLoss 4.99229 (4.99229)\td_Loss 1.46873 (1.46873)\n",
      "=>NAG Epoch: 126 Error: 4.992288112640381, Time:     0.01m\n",
      "=>epoch:127/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [127][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 4.99217 (4.99217)\td_Loss 1.46913 (1.46913)\n",
      "=>NAG Epoch: 127 Error: 4.992172718048096, Time:     0.01m\n",
      "=>epoch:128/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [128][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 4.97181 (4.97181)\td_Loss 1.46918 (1.46918)\n",
      "=>NAG Epoch: 128 Error: 4.971814155578613, Time:     0.01m\n",
      "=>epoch:129/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [129][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 4.96634 (4.96634)\td_Loss 1.46882 (1.46882)\n",
      "=>NAG Epoch: 129 Error: 4.966340065002441, Time:     0.01m\n",
      "=>epoch:130/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [130][0/1]\tTime  0.302 ( 0.302)\tData  0.270 ( 0.270)\tLoss 4.95058 (4.95058)\td_Loss 1.46904 (1.46904)\n",
      "=>NAG Epoch: 130 Error: 4.950584411621094, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_130.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_130.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_130.pkl\n",
      "=>epoch:131/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [131][0/1]\tTime  0.345 ( 0.345)\tData  0.313 ( 0.313)\tLoss 4.94369 (4.94369)\td_Loss 1.46908 (1.46908)\n",
      "=>NAG Epoch: 131 Error: 4.943690299987793, Time:     0.01m\n",
      "=>epoch:132/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [132][0/1]\tTime  0.285 ( 0.285)\tData  0.256 ( 0.256)\tLoss 4.92873 (4.92873)\td_Loss 1.46855 (1.46855)\n",
      "=>NAG Epoch: 132 Error: 4.928734302520752, Time:     0.01m\n",
      "=>epoch:133/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [133][0/1]\tTime  0.307 ( 0.307)\tData  0.276 ( 0.276)\tLoss 4.92557 (4.92557)\td_Loss 1.46878 (1.46878)\n",
      "=>NAG Epoch: 133 Error: 4.925568580627441, Time:     0.01m\n",
      "=>epoch:134/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [134][0/1]\tTime  0.296 ( 0.296)\tData  0.267 ( 0.267)\tLoss 4.91039 (4.91039)\td_Loss 1.46841 (1.46841)\n",
      "=>NAG Epoch: 134 Error: 4.91038703918457, Time:     0.01m\n",
      "=>epoch:135/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [135][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.90583 (4.90583)\td_Loss 1.46894 (1.46894)\n",
      "=>NAG Epoch: 135 Error: 4.905825138092041, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_135.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_135.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_135.pkl\n",
      "=>epoch:136/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [136][0/1]\tTime  0.300 ( 0.300)\tData  0.270 ( 0.270)\tLoss 4.89044 (4.89044)\td_Loss 1.46823 (1.46823)\n",
      "=>NAG Epoch: 136 Error: 4.890440464019775, Time:     0.01m\n",
      "=>epoch:137/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [137][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 4.89122 (4.89122)\td_Loss 1.46876 (1.46876)\n",
      "=>NAG Epoch: 137 Error: 4.89121675491333, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:138/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [138][0/1]\tTime  0.294 ( 0.294)\tData  0.262 ( 0.262)\tLoss 4.87328 (4.87328)\td_Loss 1.46818 (1.46818)\n",
      "=>NAG Epoch: 138 Error: 4.873281478881836, Time:     0.01m\n",
      "=>epoch:139/750  resolution:32 batch:128, lr5.000000e-04\n",
      "Epoch: [139][0/1]\tTime  0.295 ( 0.295)\tData  0.266 ( 0.266)\tLoss 4.87019 (4.87019)\td_Loss 1.46856 (1.46856)\n",
      "=>NAG Epoch: 139 Error: 4.870188236236572, Time:     0.01m\n",
      "=>epoch:140/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [140][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.85256 (4.85256)\td_Loss 1.46776 (1.46776)\n",
      "=>NAG Epoch: 140 Error: 4.852560997009277, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_140.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_140.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_140.pkl\n",
      "=>epoch:141/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [141][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.75654 (4.75654)\td_Loss 1.46661 (1.46661)\n",
      "=>NAG Epoch: 141 Error: 4.756536483764648, Time:     0.01m\n",
      "=>epoch:142/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [142][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 4.74923 (4.74923)\td_Loss 1.46755 (1.46755)\n",
      "=>NAG Epoch: 142 Error: 4.749228477478027, Time:     0.01m\n",
      "=>epoch:143/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [143][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 4.73901 (4.73901)\td_Loss 1.46754 (1.46754)\n",
      "=>NAG Epoch: 143 Error: 4.739009380340576, Time:     0.01m\n",
      "=>epoch:144/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [144][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 4.72590 (4.72590)\td_Loss 1.46729 (1.46729)\n",
      "=>NAG Epoch: 144 Error: 4.725902557373047, Time:     0.01m\n",
      "=>epoch:145/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [145][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.71762 (4.71762)\td_Loss 1.46767 (1.46767)\n",
      "=>NAG Epoch: 145 Error: 4.717621803283691, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_145.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_145.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_145.pkl\n",
      "=>epoch:146/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [146][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 4.71747 (4.71747)\td_Loss 1.46775 (1.46775)\n",
      "=>NAG Epoch: 146 Error: 4.717465877532959, Time:     0.01m\n",
      "=>epoch:147/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [147][0/1]\tTime  0.313 ( 0.313)\tData  0.282 ( 0.282)\tLoss 4.70728 (4.70728)\td_Loss 1.46795 (1.46795)\n",
      "=>NAG Epoch: 147 Error: 4.707280158996582, Time:     0.01m\n",
      "=>epoch:148/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [148][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 4.69984 (4.69984)\td_Loss 1.46726 (1.46726)\n",
      "=>NAG Epoch: 148 Error: 4.699837684631348, Time:     0.01m\n",
      "=>epoch:149/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [149][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 4.69250 (4.69250)\td_Loss 1.46774 (1.46774)\n",
      "=>NAG Epoch: 149 Error: 4.692498683929443, Time:     0.01m\n",
      "=>epoch:150/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [150][0/1]\tTime  0.293 ( 0.293)\tData  0.262 ( 0.262)\tLoss 4.68350 (4.68350)\td_Loss 1.46703 (1.46703)\n",
      "=>NAG Epoch: 150 Error: 4.683501720428467, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_150.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_150.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_150.pkl\n",
      "Show images...\n",
      "=>epoch:151/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [151][0/1]\tTime  0.307 ( 0.307)\tData  0.275 ( 0.275)\tLoss 4.67856 (4.67856)\td_Loss 1.46775 (1.46775)\n",
      "=>NAG Epoch: 151 Error: 4.678564071655273, Time:     0.01m\n",
      "=>epoch:152/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [152][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.66508 (4.66508)\td_Loss 1.46703 (1.46703)\n",
      "=>NAG Epoch: 152 Error: 4.6650776863098145, Time:     0.01m\n",
      "=>epoch:153/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [153][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 4.66084 (4.66084)\td_Loss 1.46757 (1.46757)\n",
      "=>NAG Epoch: 153 Error: 4.660842418670654, Time:     0.01m\n",
      "=>epoch:154/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [154][0/1]\tTime  0.293 ( 0.293)\tData  0.262 ( 0.262)\tLoss 4.65144 (4.65144)\td_Loss 1.46700 (1.46700)\n",
      "=>NAG Epoch: 154 Error: 4.651440620422363, Time:     0.01m\n",
      "=>epoch:155/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [155][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 4.64407 (4.64407)\td_Loss 1.46794 (1.46794)\n",
      "=>NAG Epoch: 155 Error: 4.644070148468018, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_155.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_155.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_155.pkl\n",
      "=>epoch:156/750  resolution:32 batch:128, lr2.500000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [156][0/1]\tTime  0.295 ( 0.295)\tData  0.266 ( 0.266)\tLoss 4.63409 (4.63409)\td_Loss 1.46719 (1.46719)\n",
      "=>NAG Epoch: 156 Error: 4.634086608886719, Time:     0.01m\n",
      "=>epoch:157/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [157][0/1]\tTime  0.303 ( 0.303)\tData  0.274 ( 0.274)\tLoss 4.63254 (4.63254)\td_Loss 1.46756 (1.46756)\n",
      "=>NAG Epoch: 157 Error: 4.632535457611084, Time:     0.01m\n",
      "=>epoch:158/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [158][0/1]\tTime  0.303 ( 0.303)\tData  0.270 ( 0.270)\tLoss 4.62157 (4.62157)\td_Loss 1.46701 (1.46701)\n",
      "=>NAG Epoch: 158 Error: 4.6215667724609375, Time:     0.01m\n",
      "=>epoch:159/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [159][0/1]\tTime  0.326 ( 0.326)\tData  0.296 ( 0.296)\tLoss 4.61717 (4.61717)\td_Loss 1.46781 (1.46781)\n",
      "=>NAG Epoch: 159 Error: 4.617172718048096, Time:     0.01m\n",
      "=>epoch:160/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [160][0/1]\tTime  0.297 ( 0.297)\tData  0.268 ( 0.268)\tLoss 4.60848 (4.60848)\td_Loss 1.46672 (1.46672)\n",
      "=>NAG Epoch: 160 Error: 4.60848331451416, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_160.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_160.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_160.pkl\n",
      "=>epoch:161/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [161][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.60403 (4.60403)\td_Loss 1.46739 (1.46739)\n",
      "=>NAG Epoch: 161 Error: 4.604026794433594, Time:     0.01m\n",
      "=>epoch:162/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [162][0/1]\tTime  0.284 ( 0.284)\tData  0.255 ( 0.255)\tLoss 4.59680 (4.59680)\td_Loss 1.46680 (1.46680)\n",
      "=>NAG Epoch: 162 Error: 4.596797466278076, Time:     0.01m\n",
      "=>epoch:163/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [163][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 4.58952 (4.58952)\td_Loss 1.46720 (1.46720)\n",
      "=>NAG Epoch: 163 Error: 4.589518070220947, Time:     0.01m\n",
      "=>epoch:164/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [164][0/1]\tTime  0.291 ( 0.291)\tData  0.260 ( 0.260)\tLoss 4.57878 (4.57878)\td_Loss 1.46706 (1.46706)\n",
      "=>NAG Epoch: 164 Error: 4.578775882720947, Time:     0.01m\n",
      "=>epoch:165/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [165][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 4.57642 (4.57642)\td_Loss 1.46710 (1.46710)\n",
      "=>NAG Epoch: 165 Error: 4.576416492462158, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_165.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_165.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_165.pkl\n",
      "=>epoch:166/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [166][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 4.56670 (4.56670)\td_Loss 1.46660 (1.46660)\n",
      "=>NAG Epoch: 166 Error: 4.566699028015137, Time:     0.01m\n",
      "=>epoch:167/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [167][0/1]\tTime  0.292 ( 0.292)\tData  0.260 ( 0.260)\tLoss 4.56501 (4.56501)\td_Loss 1.46728 (1.46728)\n",
      "=>NAG Epoch: 167 Error: 4.56500768661499, Time:     0.01m\n",
      "=>epoch:168/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [168][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 4.55451 (4.55451)\td_Loss 1.46692 (1.46692)\n",
      "=>NAG Epoch: 168 Error: 4.554505825042725, Time:     0.01m\n",
      "=>epoch:169/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [169][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 4.55058 (4.55058)\td_Loss 1.46724 (1.46724)\n",
      "=>NAG Epoch: 169 Error: 4.550584316253662, Time:     0.01m\n",
      "=>epoch:170/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [170][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 4.54005 (4.54005)\td_Loss 1.46672 (1.46672)\n",
      "=>NAG Epoch: 170 Error: 4.540051460266113, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_170.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_170.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_170.pkl\n",
      "=>epoch:171/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [171][0/1]\tTime  0.318 ( 0.318)\tData  0.287 ( 0.287)\tLoss 4.53879 (4.53879)\td_Loss 1.46727 (1.46727)\n",
      "=>NAG Epoch: 171 Error: 4.538785457611084, Time:     0.01m\n",
      "=>epoch:172/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [172][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 4.52777 (4.52777)\td_Loss 1.46660 (1.46660)\n",
      "=>NAG Epoch: 172 Error: 4.527766227722168, Time:     0.01m\n",
      "=>epoch:173/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [173][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.52492 (4.52492)\td_Loss 1.46689 (1.46689)\n",
      "=>NAG Epoch: 173 Error: 4.524919509887695, Time:     0.01m\n",
      "=>epoch:174/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [174][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 4.51434 (4.51434)\td_Loss 1.46685 (1.46685)\n",
      "=>NAG Epoch: 174 Error: 4.514339447021484, Time:     0.01m\n",
      "=>epoch:175/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [175][0/1]\tTime  0.299 ( 0.299)\tData  0.267 ( 0.267)\tLoss 4.51300 (4.51300)\td_Loss 1.46702 (1.46702)\n",
      "=>NAG Epoch: 175 Error: 4.513001918792725, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_175.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_175.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_175.pkl\n",
      "=>epoch:176/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [176][0/1]\tTime  0.301 ( 0.301)\tData  0.270 ( 0.270)\tLoss 4.50434 (4.50434)\td_Loss 1.46715 (1.46715)\n",
      "=>NAG Epoch: 176 Error: 4.504337787628174, Time:     0.01m\n",
      "=>epoch:177/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [177][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 4.50024 (4.50024)\td_Loss 1.46704 (1.46704)\n",
      "=>NAG Epoch: 177 Error: 4.500240802764893, Time:     0.01m\n",
      "=>epoch:178/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [178][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 4.49315 (4.49315)\td_Loss 1.46636 (1.46636)\n",
      "=>NAG Epoch: 178 Error: 4.4931535720825195, Time:     0.01m\n",
      "=>epoch:179/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [179][0/1]\tTime  0.297 ( 0.297)\tData  0.265 ( 0.265)\tLoss 4.49029 (4.49029)\td_Loss 1.46686 (1.46686)\n",
      "=>NAG Epoch: 179 Error: 4.490292549133301, Time:     0.01m\n",
      "=>epoch:180/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [180][0/1]\tTime  0.301 ( 0.301)\tData  0.270 ( 0.270)\tLoss 4.48083 (4.48083)\td_Loss 1.46637 (1.46637)\n",
      "=>NAG Epoch: 180 Error: 4.480833053588867, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_180.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_180.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_180.pkl\n",
      "=>epoch:181/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [181][0/1]\tTime  0.307 ( 0.307)\tData  0.277 ( 0.277)\tLoss 4.47700 (4.47700)\td_Loss 1.46689 (1.46689)\n",
      "=>NAG Epoch: 181 Error: 4.476999282836914, Time:     0.01m\n",
      "=>epoch:182/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [182][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.46837 (4.46837)\td_Loss 1.46652 (1.46652)\n",
      "=>NAG Epoch: 182 Error: 4.468372344970703, Time:     0.01m\n",
      "=>epoch:183/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [183][0/1]\tTime  0.293 ( 0.293)\tData  0.262 ( 0.262)\tLoss 4.46577 (4.46577)\td_Loss 1.46703 (1.46703)\n",
      "=>NAG Epoch: 183 Error: 4.465773105621338, Time:     0.01m\n",
      "=>epoch:184/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [184][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 4.45585 (4.45585)\td_Loss 1.46647 (1.46647)\n",
      "=>NAG Epoch: 184 Error: 4.4558539390563965, Time:     0.01m\n",
      "=>epoch:185/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [185][0/1]\tTime  0.304 ( 0.304)\tData  0.273 ( 0.273)\tLoss 4.45310 (4.45310)\td_Loss 1.46719 (1.46719)\n",
      "=>NAG Epoch: 185 Error: 4.453100681304932, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_185.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_185.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_185.pkl\n",
      "=>epoch:186/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [186][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.44853 (4.44853)\td_Loss 1.46630 (1.46630)\n",
      "=>NAG Epoch: 186 Error: 4.448532581329346, Time:     0.01m\n",
      "=>epoch:187/750  resolution:32 batch:128, lr2.500000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [187][0/1]\tTime  0.306 ( 0.306)\tData  0.274 ( 0.274)\tLoss 4.44216 (4.44216)\td_Loss 1.46708 (1.46708)\n",
      "=>NAG Epoch: 187 Error: 4.442156791687012, Time:     0.01m\n",
      "=>epoch:188/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [188][0/1]\tTime  0.308 ( 0.308)\tData  0.277 ( 0.277)\tLoss 4.43301 (4.43301)\td_Loss 1.46609 (1.46609)\n",
      "=>NAG Epoch: 188 Error: 4.433007717132568, Time:     0.01m\n",
      "=>epoch:189/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [189][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 4.42970 (4.42970)\td_Loss 1.46686 (1.46686)\n",
      "=>NAG Epoch: 189 Error: 4.429704189300537, Time:     0.01m\n",
      "=>epoch:190/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [190][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 4.42305 (4.42305)\td_Loss 1.46642 (1.46642)\n",
      "=>NAG Epoch: 190 Error: 4.42304801940918, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_190.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_190.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_190.pkl\n",
      "=>epoch:191/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [191][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 4.42080 (4.42080)\td_Loss 1.46707 (1.46707)\n",
      "=>NAG Epoch: 191 Error: 4.420802116394043, Time:     0.01m\n",
      "=>epoch:192/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [192][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 4.41148 (4.41148)\td_Loss 1.46590 (1.46590)\n",
      "=>NAG Epoch: 192 Error: 4.411478042602539, Time:     0.01m\n",
      "=>epoch:193/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [193][0/1]\tTime  0.301 ( 0.301)\tData  0.270 ( 0.270)\tLoss 4.40626 (4.40626)\td_Loss 1.46707 (1.46707)\n",
      "=>NAG Epoch: 193 Error: 4.406264781951904, Time:     0.01m\n",
      "=>epoch:194/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [194][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 4.39902 (4.39902)\td_Loss 1.46599 (1.46599)\n",
      "=>NAG Epoch: 194 Error: 4.3990159034729, Time:     0.01m\n",
      "=>epoch:195/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [195][0/1]\tTime  0.300 ( 0.300)\tData  0.270 ( 0.270)\tLoss 4.39640 (4.39640)\td_Loss 1.46690 (1.46690)\n",
      "=>NAG Epoch: 195 Error: 4.396397590637207, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_195.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_195.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_195.pkl\n",
      "=>epoch:196/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [196][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 4.39000 (4.39000)\td_Loss 1.46623 (1.46623)\n",
      "=>NAG Epoch: 196 Error: 4.389998912811279, Time:     0.01m\n",
      "=>epoch:197/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [197][0/1]\tTime  0.339 ( 0.339)\tData  0.306 ( 0.306)\tLoss 4.38526 (4.38526)\td_Loss 1.46705 (1.46705)\n",
      "=>NAG Epoch: 197 Error: 4.385260581970215, Time:     0.01m\n",
      "=>epoch:198/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [198][0/1]\tTime  0.300 ( 0.300)\tData  0.270 ( 0.270)\tLoss 4.37579 (4.37579)\td_Loss 1.46614 (1.46614)\n",
      "=>NAG Epoch: 198 Error: 4.375786781311035, Time:     0.01m\n",
      "=>epoch:199/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [199][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 4.37197 (4.37197)\td_Loss 1.46660 (1.46660)\n",
      "=>NAG Epoch: 199 Error: 4.371974468231201, Time:     0.01m\n",
      "=>epoch:200/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [200][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 4.36741 (4.36741)\td_Loss 1.46598 (1.46598)\n",
      "=>NAG Epoch: 200 Error: 4.367411136627197, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_200.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_200.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_200.pkl\n",
      "Show images...\n",
      "=>epoch:201/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [201][0/1]\tTime  0.339 ( 0.339)\tData  0.308 ( 0.308)\tLoss 4.36589 (4.36589)\td_Loss 1.46674 (1.46674)\n",
      "=>NAG Epoch: 201 Error: 4.365891456604004, Time:     0.01m\n",
      "=>epoch:202/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [202][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 4.35632 (4.35632)\td_Loss 1.46601 (1.46601)\n",
      "=>NAG Epoch: 202 Error: 4.356318950653076, Time:     0.01m\n",
      "=>epoch:203/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [203][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 4.35432 (4.35432)\td_Loss 1.46677 (1.46677)\n",
      "=>NAG Epoch: 203 Error: 4.354323387145996, Time:     0.01m\n",
      "=>epoch:204/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [204][0/1]\tTime  0.287 ( 0.287)\tData  0.258 ( 0.258)\tLoss 4.34693 (4.34693)\td_Loss 1.46599 (1.46599)\n",
      "=>NAG Epoch: 204 Error: 4.346926689147949, Time:     0.01m\n",
      "=>epoch:205/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [205][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 4.34459 (4.34459)\td_Loss 1.46636 (1.46636)\n",
      "=>NAG Epoch: 205 Error: 4.344594955444336, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_205.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_205.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_205.pkl\n",
      "=>epoch:206/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [206][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 4.33607 (4.33607)\td_Loss 1.46601 (1.46601)\n",
      "=>NAG Epoch: 206 Error: 4.336066722869873, Time:     0.01m\n",
      "=>epoch:207/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [207][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.33159 (4.33159)\td_Loss 1.46659 (1.46659)\n",
      "=>NAG Epoch: 207 Error: 4.3315911293029785, Time:     0.01m\n",
      "=>epoch:208/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [208][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 4.32578 (4.32578)\td_Loss 1.46620 (1.46620)\n",
      "=>NAG Epoch: 208 Error: 4.325778484344482, Time:     0.01m\n",
      "=>epoch:209/750  resolution:32 batch:128, lr2.500000e-04\n",
      "Epoch: [209][0/1]\tTime  0.286 ( 0.286)\tData  0.256 ( 0.256)\tLoss 4.32310 (4.32310)\td_Loss 1.46653 (1.46653)\n",
      "=>NAG Epoch: 209 Error: 4.3231024742126465, Time:     0.01m\n",
      "=>epoch:210/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [210][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 4.31443 (4.31443)\td_Loss 1.46621 (1.46621)\n",
      "=>NAG Epoch: 210 Error: 4.314426422119141, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_210.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_210.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_210.pkl\n",
      "=>epoch:211/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [211][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.26928 (4.26928)\td_Loss 1.46569 (1.46569)\n",
      "=>NAG Epoch: 211 Error: 4.269277095794678, Time:     0.01m\n",
      "=>epoch:212/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [212][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 4.26243 (4.26243)\td_Loss 1.46593 (1.46593)\n",
      "=>NAG Epoch: 212 Error: 4.262434005737305, Time:     0.01m\n",
      "=>epoch:213/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [213][0/1]\tTime  0.289 ( 0.289)\tData  0.258 ( 0.258)\tLoss 4.26924 (4.26924)\td_Loss 1.46584 (1.46584)\n",
      "=>NAG Epoch: 213 Error: 4.269240379333496, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:214/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [214][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 4.25878 (4.25878)\td_Loss 1.46567 (1.46567)\n",
      "=>NAG Epoch: 214 Error: 4.258778095245361, Time:     0.01m\n",
      "=>epoch:215/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [215][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 4.25854 (4.25854)\td_Loss 1.46594 (1.46594)\n",
      "=>NAG Epoch: 215 Error: 4.258540630340576, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_215.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_215.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_215.pkl\n",
      "=>epoch:216/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [216][0/1]\tTime  0.286 ( 0.286)\tData  0.257 ( 0.257)\tLoss 4.25015 (4.25015)\td_Loss 1.46589 (1.46589)\n",
      "=>NAG Epoch: 216 Error: 4.250147819519043, Time:     0.01m\n",
      "=>epoch:217/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [217][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 4.24822 (4.24822)\td_Loss 1.46578 (1.46578)\n",
      "=>NAG Epoch: 217 Error: 4.248222827911377, Time:     0.01m\n",
      "=>epoch:218/750  resolution:32 batch:128, lr1.250000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [218][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 4.24063 (4.24063)\td_Loss 1.46568 (1.46568)\n",
      "=>NAG Epoch: 218 Error: 4.240632057189941, Time:     0.01m\n",
      "=>epoch:219/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [219][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 4.23799 (4.23799)\td_Loss 1.46576 (1.46576)\n",
      "=>NAG Epoch: 219 Error: 4.237991809844971, Time:     0.01m\n",
      "=>epoch:220/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [220][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 4.23094 (4.23094)\td_Loss 1.46573 (1.46573)\n",
      "=>NAG Epoch: 220 Error: 4.230940818786621, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_220.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_220.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_220.pkl\n",
      "=>epoch:221/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [221][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 4.23052 (4.23052)\td_Loss 1.46570 (1.46570)\n",
      "=>NAG Epoch: 221 Error: 4.230515003204346, Time:     0.01m\n",
      "=>epoch:222/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [222][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 4.22380 (4.22380)\td_Loss 1.46594 (1.46594)\n",
      "=>NAG Epoch: 222 Error: 4.223795413970947, Time:     0.01m\n",
      "=>epoch:223/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [223][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 4.22100 (4.22100)\td_Loss 1.46572 (1.46572)\n",
      "=>NAG Epoch: 223 Error: 4.220999240875244, Time:     0.01m\n",
      "=>epoch:224/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [224][0/1]\tTime  0.285 ( 0.285)\tData  0.255 ( 0.255)\tLoss 4.21600 (4.21600)\td_Loss 1.46570 (1.46570)\n",
      "=>NAG Epoch: 224 Error: 4.215999603271484, Time:     0.01m\n",
      "=>epoch:225/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [225][0/1]\tTime  0.313 ( 0.313)\tData  0.283 ( 0.283)\tLoss 4.21267 (4.21267)\td_Loss 1.46556 (1.46556)\n",
      "=>NAG Epoch: 225 Error: 4.21267032623291, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_225.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_225.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_225.pkl\n",
      "=>epoch:226/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [226][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 4.20824 (4.20824)\td_Loss 1.46544 (1.46544)\n",
      "=>NAG Epoch: 226 Error: 4.208237171173096, Time:     0.01m\n",
      "=>epoch:227/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [227][0/1]\tTime  0.306 ( 0.306)\tData  0.276 ( 0.276)\tLoss 4.20440 (4.20440)\td_Loss 1.46566 (1.46566)\n",
      "=>NAG Epoch: 227 Error: 4.204403400421143, Time:     0.01m\n",
      "=>epoch:228/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [228][0/1]\tTime  0.306 ( 0.306)\tData  0.275 ( 0.275)\tLoss 4.19790 (4.19790)\td_Loss 1.46555 (1.46555)\n",
      "=>NAG Epoch: 228 Error: 4.197895050048828, Time:     0.01m\n",
      "=>epoch:229/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [229][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 4.19644 (4.19644)\td_Loss 1.46537 (1.46537)\n",
      "=>NAG Epoch: 229 Error: 4.196440696716309, Time:     0.01m\n",
      "=>epoch:230/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [230][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.19183 (4.19183)\td_Loss 1.46547 (1.46547)\n",
      "=>NAG Epoch: 230 Error: 4.191833972930908, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_230.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_230.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_230.pkl\n",
      "=>epoch:231/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [231][0/1]\tTime  0.292 ( 0.292)\tData  0.261 ( 0.261)\tLoss 4.18856 (4.18856)\td_Loss 1.46561 (1.46561)\n",
      "=>NAG Epoch: 231 Error: 4.188562870025635, Time:     0.01m\n",
      "=>epoch:232/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [232][0/1]\tTime  0.309 ( 0.309)\tData  0.279 ( 0.279)\tLoss 4.18296 (4.18296)\td_Loss 1.46554 (1.46554)\n",
      "=>NAG Epoch: 232 Error: 4.182960033416748, Time:     0.01m\n",
      "=>epoch:233/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [233][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 4.17909 (4.17909)\td_Loss 1.46552 (1.46552)\n",
      "=>NAG Epoch: 233 Error: 4.179094314575195, Time:     0.01m\n",
      "=>epoch:234/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [234][0/1]\tTime  0.307 ( 0.307)\tData  0.277 ( 0.277)\tLoss 4.17477 (4.17477)\td_Loss 1.46554 (1.46554)\n",
      "=>NAG Epoch: 234 Error: 4.174774646759033, Time:     0.01m\n",
      "=>epoch:235/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [235][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 4.17355 (4.17355)\td_Loss 1.46544 (1.46544)\n",
      "=>NAG Epoch: 235 Error: 4.173550605773926, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_235.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_235.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_235.pkl\n",
      "=>epoch:236/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [236][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.17006 (4.17006)\td_Loss 1.46528 (1.46528)\n",
      "=>NAG Epoch: 236 Error: 4.170060157775879, Time:     0.01m\n",
      "=>epoch:237/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [237][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.16573 (4.16573)\td_Loss 1.46545 (1.46545)\n",
      "=>NAG Epoch: 237 Error: 4.1657304763793945, Time:     0.01m\n",
      "=>epoch:238/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [238][0/1]\tTime  0.302 ( 0.302)\tData  0.270 ( 0.270)\tLoss 4.16071 (4.16071)\td_Loss 1.46532 (1.46532)\n",
      "=>NAG Epoch: 238 Error: 4.160712242126465, Time:     0.01m\n",
      "=>epoch:239/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [239][0/1]\tTime  0.363 ( 0.363)\tData  0.333 ( 0.333)\tLoss 4.15735 (4.15735)\td_Loss 1.46532 (1.46532)\n",
      "=>NAG Epoch: 239 Error: 4.157350540161133, Time:     0.01m\n",
      "=>epoch:240/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [240][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 4.15407 (4.15407)\td_Loss 1.46538 (1.46538)\n",
      "=>NAG Epoch: 240 Error: 4.154070854187012, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_240.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_240.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_240.pkl\n",
      "=>epoch:241/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [241][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 4.15002 (4.15002)\td_Loss 1.46540 (1.46540)\n",
      "=>NAG Epoch: 241 Error: 4.1500244140625, Time:     0.01m\n",
      "=>epoch:242/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [242][0/1]\tTime  0.314 ( 0.314)\tData  0.284 ( 0.284)\tLoss 4.14545 (4.14545)\td_Loss 1.46536 (1.46536)\n",
      "=>NAG Epoch: 242 Error: 4.145450115203857, Time:     0.01m\n",
      "=>epoch:243/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [243][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 4.14379 (4.14379)\td_Loss 1.46535 (1.46535)\n",
      "=>NAG Epoch: 243 Error: 4.143786907196045, Time:     0.01m\n",
      "=>epoch:244/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [244][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 4.13869 (4.13869)\td_Loss 1.46523 (1.46523)\n",
      "=>NAG Epoch: 244 Error: 4.138694763183594, Time:     0.01m\n",
      "=>epoch:245/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [245][0/1]\tTime  0.301 ( 0.301)\tData  0.272 ( 0.272)\tLoss 4.13677 (4.13677)\td_Loss 1.46517 (1.46517)\n",
      "=>NAG Epoch: 245 Error: 4.136769771575928, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_245.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_245.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_245.pkl\n",
      "=>epoch:246/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [246][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 4.13021 (4.13021)\td_Loss 1.46522 (1.46522)\n",
      "=>NAG Epoch: 246 Error: 4.130208492279053, Time:     0.01m\n",
      "=>epoch:247/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [247][0/1]\tTime  0.296 ( 0.296)\tData  0.267 ( 0.267)\tLoss 4.12809 (4.12809)\td_Loss 1.46554 (1.46554)\n",
      "=>NAG Epoch: 247 Error: 4.128089427947998, Time:     0.01m\n",
      "=>epoch:248/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [248][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 4.12385 (4.12385)\td_Loss 1.46533 (1.46533)\n",
      "=>NAG Epoch: 248 Error: 4.1238508224487305, Time:     0.01m\n",
      "=>epoch:249/750  resolution:32 batch:128, lr1.250000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [249][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 4.12073 (4.12073)\td_Loss 1.46525 (1.46525)\n",
      "=>NAG Epoch: 249 Error: 4.120730400085449, Time:     0.01m\n",
      "=>epoch:250/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [250][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 4.11594 (4.11594)\td_Loss 1.46522 (1.46522)\n",
      "=>NAG Epoch: 250 Error: 4.115941047668457, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_250.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_250.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_250.pkl\n",
      "Show images...\n",
      "=>epoch:251/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [251][0/1]\tTime  0.328 ( 0.328)\tData  0.297 ( 0.297)\tLoss 4.11327 (4.11327)\td_Loss 1.46516 (1.46516)\n",
      "=>NAG Epoch: 251 Error: 4.1132731437683105, Time:     0.01m\n",
      "=>epoch:252/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [252][0/1]\tTime  0.301 ( 0.301)\tData  0.272 ( 0.272)\tLoss 4.11048 (4.11048)\td_Loss 1.46526 (1.46526)\n",
      "=>NAG Epoch: 252 Error: 4.110480308532715, Time:     0.01m\n",
      "=>epoch:253/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [253][0/1]\tTime  0.320 ( 0.320)\tData  0.280 ( 0.280)\tLoss 4.10685 (4.10685)\td_Loss 1.46520 (1.46520)\n",
      "=>NAG Epoch: 253 Error: 4.10685396194458, Time:     0.01m\n",
      "=>epoch:254/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [254][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 4.10212 (4.10212)\td_Loss 1.46519 (1.46519)\n",
      "=>NAG Epoch: 254 Error: 4.102121353149414, Time:     0.01m\n",
      "=>epoch:255/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [255][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 4.10124 (4.10124)\td_Loss 1.46515 (1.46515)\n",
      "=>NAG Epoch: 255 Error: 4.101235866546631, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_255.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_255.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_255.pkl\n",
      "=>epoch:256/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [256][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 4.09622 (4.09622)\td_Loss 1.46511 (1.46511)\n",
      "=>NAG Epoch: 256 Error: 4.096219062805176, Time:     0.01m\n",
      "=>epoch:257/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [257][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 4.09184 (4.09184)\td_Loss 1.46520 (1.46520)\n",
      "=>NAG Epoch: 257 Error: 4.091835021972656, Time:     0.01m\n",
      "=>epoch:258/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [258][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 4.08935 (4.08935)\td_Loss 1.46511 (1.46511)\n",
      "=>NAG Epoch: 258 Error: 4.089345932006836, Time:     0.01m\n",
      "=>epoch:259/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [259][0/1]\tTime  0.313 ( 0.313)\tData  0.281 ( 0.281)\tLoss 4.08581 (4.08581)\td_Loss 1.46520 (1.46520)\n",
      "=>NAG Epoch: 259 Error: 4.085813522338867, Time:     0.01m\n",
      "=>epoch:260/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [260][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 4.08249 (4.08249)\td_Loss 1.46506 (1.46506)\n",
      "=>NAG Epoch: 260 Error: 4.082486152648926, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_260.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_260.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_260.pkl\n",
      "=>epoch:261/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [261][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 4.08049 (4.08049)\td_Loss 1.46517 (1.46517)\n",
      "=>NAG Epoch: 261 Error: 4.080491065979004, Time:     0.01m\n",
      "=>epoch:262/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [262][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 4.07525 (4.07525)\td_Loss 1.46512 (1.46512)\n",
      "=>NAG Epoch: 262 Error: 4.075247764587402, Time:     0.01m\n",
      "=>epoch:263/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [263][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 4.07246 (4.07246)\td_Loss 1.46511 (1.46511)\n",
      "=>NAG Epoch: 263 Error: 4.072457313537598, Time:     0.01m\n",
      "=>epoch:264/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [264][0/1]\tTime  0.301 ( 0.301)\tData  0.268 ( 0.268)\tLoss 4.06899 (4.06899)\td_Loss 1.46518 (1.46518)\n",
      "=>NAG Epoch: 264 Error: 4.0689873695373535, Time:     0.01m\n",
      "=>epoch:265/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [265][0/1]\tTime  0.358 ( 0.358)\tData  0.327 ( 0.327)\tLoss 4.06630 (4.06630)\td_Loss 1.46493 (1.46493)\n",
      "=>NAG Epoch: 265 Error: 4.066295146942139, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_265.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_265.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_265.pkl\n",
      "=>epoch:266/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [266][0/1]\tTime  0.311 ( 0.311)\tData  0.280 ( 0.280)\tLoss 4.06395 (4.06395)\td_Loss 1.46500 (1.46500)\n",
      "=>NAG Epoch: 266 Error: 4.063952445983887, Time:     0.01m\n",
      "=>epoch:267/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [267][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 4.06092 (4.06092)\td_Loss 1.46521 (1.46521)\n",
      "=>NAG Epoch: 267 Error: 4.060920238494873, Time:     0.01m\n",
      "=>epoch:268/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [268][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 4.05475 (4.05475)\td_Loss 1.46513 (1.46513)\n",
      "=>NAG Epoch: 268 Error: 4.054745197296143, Time:     0.01m\n",
      "=>epoch:269/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [269][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 4.05443 (4.05443)\td_Loss 1.46504 (1.46504)\n",
      "=>NAG Epoch: 269 Error: 4.0544281005859375, Time:     0.01m\n",
      "=>epoch:270/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [270][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 4.04967 (4.04967)\td_Loss 1.46509 (1.46509)\n",
      "=>NAG Epoch: 270 Error: 4.0496745109558105, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_270.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_270.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_270.pkl\n",
      "=>epoch:271/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [271][0/1]\tTime  0.318 ( 0.318)\tData  0.287 ( 0.287)\tLoss 4.04535 (4.04535)\td_Loss 1.46491 (1.46491)\n",
      "=>NAG Epoch: 271 Error: 4.045352935791016, Time:     0.01m\n",
      "=>epoch:272/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [272][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 4.04285 (4.04285)\td_Loss 1.46494 (1.46494)\n",
      "=>NAG Epoch: 272 Error: 4.042853832244873, Time:     0.01m\n",
      "=>epoch:273/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [273][0/1]\tTime  0.327 ( 0.327)\tData  0.296 ( 0.296)\tLoss 4.03982 (4.03982)\td_Loss 1.46482 (1.46482)\n",
      "=>NAG Epoch: 273 Error: 4.039824962615967, Time:     0.01m\n",
      "=>epoch:274/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [274][0/1]\tTime  0.309 ( 0.309)\tData  0.279 ( 0.279)\tLoss 4.03668 (4.03668)\td_Loss 1.46500 (1.46500)\n",
      "=>NAG Epoch: 274 Error: 4.036681175231934, Time:     0.01m\n",
      "=>epoch:275/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [275][0/1]\tTime  0.338 ( 0.338)\tData  0.307 ( 0.307)\tLoss 4.03503 (4.03503)\td_Loss 1.46481 (1.46481)\n",
      "=>NAG Epoch: 275 Error: 4.035032749176025, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_275.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_275.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_275.pkl\n",
      "=>epoch:276/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [276][0/1]\tTime  0.299 ( 0.299)\tData  0.267 ( 0.267)\tLoss 4.02984 (4.02984)\td_Loss 1.46501 (1.46501)\n",
      "=>NAG Epoch: 276 Error: 4.029836654663086, Time:     0.01m\n",
      "=>epoch:277/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [277][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 4.03032 (4.03032)\td_Loss 1.46495 (1.46495)\n",
      "=>NAG Epoch: 277 Error: 4.03032112121582, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:278/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [278][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 4.02151 (4.02151)\td_Loss 1.46506 (1.46506)\n",
      "=>NAG Epoch: 278 Error: 4.021505355834961, Time:     0.01m\n",
      "=>epoch:279/750  resolution:32 batch:128, lr1.250000e-04\n",
      "Epoch: [279][0/1]\tTime  0.317 ( 0.317)\tData  0.277 ( 0.277)\tLoss 4.02165 (4.02165)\td_Loss 1.46510 (1.46510)\n",
      "=>NAG Epoch: 279 Error: 4.0216498374938965, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:280/750  resolution:32 batch:128, lr6.250000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [280][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 4.01472 (4.01472)\td_Loss 1.46492 (1.46492)\n",
      "=>NAG Epoch: 280 Error: 4.014720439910889, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_280.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_280.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_280.pkl\n",
      "=>epoch:281/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [281][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.99687 (3.99687)\td_Loss 1.46486 (1.46486)\n",
      "=>NAG Epoch: 281 Error: 3.9968743324279785, Time:     0.01m\n",
      "=>epoch:282/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [282][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.99227 (3.99227)\td_Loss 1.46485 (1.46485)\n",
      "=>NAG Epoch: 282 Error: 3.9922726154327393, Time:     0.01m\n",
      "=>epoch:283/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [283][0/1]\tTime  0.296 ( 0.296)\tData  0.267 ( 0.267)\tLoss 3.99017 (3.99017)\td_Loss 1.46471 (1.46471)\n",
      "=>NAG Epoch: 283 Error: 3.990170955657959, Time:     0.01m\n",
      "=>epoch:284/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [284][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 3.98584 (3.98584)\td_Loss 1.46487 (1.46487)\n",
      "=>NAG Epoch: 284 Error: 3.985844850540161, Time:     0.01m\n",
      "=>epoch:285/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [285][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.98146 (3.98146)\td_Loss 1.46500 (1.46500)\n",
      "=>NAG Epoch: 285 Error: 3.981459617614746, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_285.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_285.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_285.pkl\n",
      "=>epoch:286/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [286][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.98062 (3.98062)\td_Loss 1.46507 (1.46507)\n",
      "=>NAG Epoch: 286 Error: 3.980618953704834, Time:     0.01m\n",
      "=>epoch:287/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [287][0/1]\tTime  0.304 ( 0.304)\tData  0.275 ( 0.275)\tLoss 3.97756 (3.97756)\td_Loss 1.46474 (1.46474)\n",
      "=>NAG Epoch: 287 Error: 3.977557420730591, Time:     0.01m\n",
      "=>epoch:288/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [288][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.97501 (3.97501)\td_Loss 1.46488 (1.46488)\n",
      "=>NAG Epoch: 288 Error: 3.9750144481658936, Time:     0.01m\n",
      "=>epoch:289/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [289][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.97173 (3.97173)\td_Loss 1.46465 (1.46465)\n",
      "=>NAG Epoch: 289 Error: 3.9717273712158203, Time:     0.01m\n",
      "=>epoch:290/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [290][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.96744 (3.96744)\td_Loss 1.46498 (1.46498)\n",
      "=>NAG Epoch: 290 Error: 3.9674413204193115, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_290.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_290.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_290.pkl\n",
      "=>epoch:291/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [291][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.96606 (3.96606)\td_Loss 1.46475 (1.46475)\n",
      "=>NAG Epoch: 291 Error: 3.9660627841949463, Time:     0.01m\n",
      "=>epoch:292/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [292][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.96469 (3.96469)\td_Loss 1.46486 (1.46486)\n",
      "=>NAG Epoch: 292 Error: 3.9646897315979004, Time:     0.01m\n",
      "=>epoch:293/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [293][0/1]\tTime  0.286 ( 0.286)\tData  0.256 ( 0.256)\tLoss 3.96121 (3.96121)\td_Loss 1.46464 (1.46464)\n",
      "=>NAG Epoch: 293 Error: 3.9612083435058594, Time:     0.01m\n",
      "=>epoch:294/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [294][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.96014 (3.96014)\td_Loss 1.46478 (1.46478)\n",
      "=>NAG Epoch: 294 Error: 3.9601404666900635, Time:     0.01m\n",
      "=>epoch:295/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [295][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.95574 (3.95574)\td_Loss 1.46458 (1.46458)\n",
      "=>NAG Epoch: 295 Error: 3.955742359161377, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_295.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_295.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_295.pkl\n",
      "=>epoch:296/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [296][0/1]\tTime  0.305 ( 0.305)\tData  0.275 ( 0.275)\tLoss 3.95273 (3.95273)\td_Loss 1.46465 (1.46465)\n",
      "=>NAG Epoch: 296 Error: 3.952727794647217, Time:     0.01m\n",
      "=>epoch:297/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [297][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.95011 (3.95011)\td_Loss 1.46462 (1.46462)\n",
      "=>NAG Epoch: 297 Error: 3.9501054286956787, Time:     0.01m\n",
      "=>epoch:298/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [298][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.94716 (3.94716)\td_Loss 1.46491 (1.46491)\n",
      "=>NAG Epoch: 298 Error: 3.947155237197876, Time:     0.01m\n",
      "=>epoch:299/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [299][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.94488 (3.94488)\td_Loss 1.46453 (1.46453)\n",
      "=>NAG Epoch: 299 Error: 3.9448776245117188, Time:     0.01m\n",
      "=>epoch:300/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [300][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.94215 (3.94215)\td_Loss 1.46484 (1.46484)\n",
      "=>NAG Epoch: 300 Error: 3.942152976989746, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_300.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_300.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_300.pkl\n",
      "Show images...\n",
      "=>epoch:301/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [301][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 3.94153 (3.94153)\td_Loss 1.46471 (1.46471)\n",
      "=>NAG Epoch: 301 Error: 3.941528797149658, Time:     0.01m\n",
      "=>epoch:302/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [302][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.93891 (3.93891)\td_Loss 1.46470 (1.46470)\n",
      "=>NAG Epoch: 302 Error: 3.938913345336914, Time:     0.01m\n",
      "=>epoch:303/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [303][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.93589 (3.93589)\td_Loss 1.46468 (1.46468)\n",
      "=>NAG Epoch: 303 Error: 3.9358930587768555, Time:     0.01m\n",
      "=>epoch:304/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [304][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.93264 (3.93264)\td_Loss 1.46468 (1.46468)\n",
      "=>NAG Epoch: 304 Error: 3.932636260986328, Time:     0.01m\n",
      "=>epoch:305/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [305][0/1]\tTime  0.286 ( 0.286)\tData  0.256 ( 0.256)\tLoss 3.92927 (3.92927)\td_Loss 1.46454 (1.46454)\n",
      "=>NAG Epoch: 305 Error: 3.9292702674865723, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_305.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_305.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_305.pkl\n",
      "=>epoch:306/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [306][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.92635 (3.92635)\td_Loss 1.46469 (1.46469)\n",
      "=>NAG Epoch: 306 Error: 3.9263510704040527, Time:     0.01m\n",
      "=>epoch:307/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [307][0/1]\tTime  0.287 ( 0.287)\tData  0.258 ( 0.258)\tLoss 3.92599 (3.92599)\td_Loss 1.46449 (1.46449)\n",
      "=>NAG Epoch: 307 Error: 3.925990104675293, Time:     0.01m\n",
      "=>epoch:308/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [308][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.92198 (3.92198)\td_Loss 1.46457 (1.46457)\n",
      "=>NAG Epoch: 308 Error: 3.9219775199890137, Time:     0.01m\n",
      "=>epoch:309/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [309][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 3.92010 (3.92010)\td_Loss 1.46459 (1.46459)\n",
      "=>NAG Epoch: 309 Error: 3.920097827911377, Time:     0.01m\n",
      "=>epoch:310/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [310][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.91693 (3.91693)\td_Loss 1.46459 (1.46459)\n",
      "=>NAG Epoch: 310 Error: 3.9169301986694336, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_310.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_310.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_310.pkl\n",
      "=>epoch:311/750  resolution:32 batch:128, lr6.250000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [311][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.91573 (3.91573)\td_Loss 1.46452 (1.46452)\n",
      "=>NAG Epoch: 311 Error: 3.9157261848449707, Time:     0.01m\n",
      "=>epoch:312/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [312][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.91328 (3.91328)\td_Loss 1.46458 (1.46458)\n",
      "=>NAG Epoch: 312 Error: 3.9132790565490723, Time:     0.01m\n",
      "=>epoch:313/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [313][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.91068 (3.91068)\td_Loss 1.46443 (1.46443)\n",
      "=>NAG Epoch: 313 Error: 3.910681962966919, Time:     0.01m\n",
      "=>epoch:314/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [314][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.90652 (3.90652)\td_Loss 1.46461 (1.46461)\n",
      "=>NAG Epoch: 314 Error: 3.9065167903900146, Time:     0.01m\n",
      "=>epoch:315/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [315][0/1]\tTime  0.289 ( 0.289)\tData  0.258 ( 0.258)\tLoss 3.90409 (3.90409)\td_Loss 1.46455 (1.46455)\n",
      "=>NAG Epoch: 315 Error: 3.9040937423706055, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_315.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_315.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_315.pkl\n",
      "=>epoch:316/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [316][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.90467 (3.90467)\td_Loss 1.46455 (1.46455)\n",
      "=>NAG Epoch: 316 Error: 3.9046740531921387, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:317/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [317][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.90013 (3.90013)\td_Loss 1.46452 (1.46452)\n",
      "=>NAG Epoch: 317 Error: 3.9001331329345703, Time:     0.01m\n",
      "=>epoch:318/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [318][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.89917 (3.89917)\td_Loss 1.46453 (1.46453)\n",
      "=>NAG Epoch: 318 Error: 3.899174213409424, Time:     0.01m\n",
      "=>epoch:319/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [319][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.89425 (3.89425)\td_Loss 1.46440 (1.46440)\n",
      "=>NAG Epoch: 319 Error: 3.8942465782165527, Time:     0.01m\n",
      "=>epoch:320/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [320][0/1]\tTime  0.300 ( 0.300)\tData  0.271 ( 0.271)\tLoss 3.89153 (3.89153)\td_Loss 1.46459 (1.46459)\n",
      "=>NAG Epoch: 320 Error: 3.891530990600586, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_320.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_320.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_320.pkl\n",
      "=>epoch:321/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [321][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.89002 (3.89002)\td_Loss 1.46440 (1.46440)\n",
      "=>NAG Epoch: 321 Error: 3.8900198936462402, Time:     0.01m\n",
      "=>epoch:322/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [322][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.88723 (3.88723)\td_Loss 1.46453 (1.46453)\n",
      "=>NAG Epoch: 322 Error: 3.887234687805176, Time:     0.01m\n",
      "=>epoch:323/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [323][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.88773 (3.88773)\td_Loss 1.46432 (1.46432)\n",
      "=>NAG Epoch: 323 Error: 3.8877344131469727, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:324/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [324][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.88530 (3.88530)\td_Loss 1.46451 (1.46451)\n",
      "=>NAG Epoch: 324 Error: 3.8853025436401367, Time:     0.01m\n",
      "=>epoch:325/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [325][0/1]\tTime  0.287 ( 0.287)\tData  0.258 ( 0.258)\tLoss 3.88239 (3.88239)\td_Loss 1.46447 (1.46447)\n",
      "=>NAG Epoch: 325 Error: 3.8823940753936768, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_325.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_325.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_325.pkl\n",
      "=>epoch:326/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [326][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.87869 (3.87869)\td_Loss 1.46463 (1.46463)\n",
      "=>NAG Epoch: 326 Error: 3.8786873817443848, Time:     0.01m\n",
      "=>epoch:327/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [327][0/1]\tTime  0.292 ( 0.292)\tData  0.260 ( 0.260)\tLoss 3.87727 (3.87727)\td_Loss 1.46451 (1.46451)\n",
      "=>NAG Epoch: 327 Error: 3.877269744873047, Time:     0.01m\n",
      "=>epoch:328/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [328][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.87455 (3.87455)\td_Loss 1.46438 (1.46438)\n",
      "=>NAG Epoch: 328 Error: 3.8745455741882324, Time:     0.01m\n",
      "=>epoch:329/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [329][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.87183 (3.87183)\td_Loss 1.46442 (1.46442)\n",
      "=>NAG Epoch: 329 Error: 3.8718314170837402, Time:     0.01m\n",
      "=>epoch:330/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [330][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 3.87093 (3.87093)\td_Loss 1.46455 (1.46455)\n",
      "=>NAG Epoch: 330 Error: 3.8709287643432617, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_330.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_330.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_330.pkl\n",
      "=>epoch:331/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [331][0/1]\tTime  0.320 ( 0.320)\tData  0.289 ( 0.289)\tLoss 3.86665 (3.86665)\td_Loss 1.46441 (1.46441)\n",
      "=>NAG Epoch: 331 Error: 3.866651773452759, Time:     0.01m\n",
      "=>epoch:332/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [332][0/1]\tTime  0.311 ( 0.311)\tData  0.280 ( 0.280)\tLoss 3.86528 (3.86528)\td_Loss 1.46465 (1.46465)\n",
      "=>NAG Epoch: 332 Error: 3.8652796745300293, Time:     0.01m\n",
      "=>epoch:333/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [333][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 3.86188 (3.86188)\td_Loss 1.46435 (1.46435)\n",
      "=>NAG Epoch: 333 Error: 3.8618791103363037, Time:     0.01m\n",
      "=>epoch:334/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [334][0/1]\tTime  0.323 ( 0.323)\tData  0.292 ( 0.292)\tLoss 3.86020 (3.86020)\td_Loss 1.46444 (1.46444)\n",
      "=>NAG Epoch: 334 Error: 3.8602046966552734, Time:     0.01m\n",
      "=>epoch:335/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [335][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.85756 (3.85756)\td_Loss 1.46435 (1.46435)\n",
      "=>NAG Epoch: 335 Error: 3.8575634956359863, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_335.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_335.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_335.pkl\n",
      "=>epoch:336/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [336][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.85743 (3.85743)\td_Loss 1.46457 (1.46457)\n",
      "=>NAG Epoch: 336 Error: 3.8574271202087402, Time:     0.01m\n",
      "=>epoch:337/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [337][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.85331 (3.85331)\td_Loss 1.46426 (1.46426)\n",
      "=>NAG Epoch: 337 Error: 3.8533053398132324, Time:     0.01m\n",
      "=>epoch:338/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [338][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.85282 (3.85282)\td_Loss 1.46434 (1.46434)\n",
      "=>NAG Epoch: 338 Error: 3.8528249263763428, Time:     0.01m\n",
      "=>epoch:339/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [339][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 3.84802 (3.84802)\td_Loss 1.46433 (1.46433)\n",
      "=>NAG Epoch: 339 Error: 3.8480224609375, Time:     0.01m\n",
      "=>epoch:340/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [340][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.84693 (3.84693)\td_Loss 1.46431 (1.46431)\n",
      "=>NAG Epoch: 340 Error: 3.8469321727752686, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_340.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_340.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_340.pkl\n",
      "=>epoch:341/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [341][0/1]\tTime  0.302 ( 0.302)\tData  0.270 ( 0.270)\tLoss 3.84412 (3.84412)\td_Loss 1.46438 (1.46438)\n",
      "=>NAG Epoch: 341 Error: 3.8441171646118164, Time:     0.01m\n",
      "=>epoch:342/750  resolution:32 batch:128, lr6.250000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [342][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.84218 (3.84218)\td_Loss 1.46448 (1.46448)\n",
      "=>NAG Epoch: 342 Error: 3.8421757221221924, Time:     0.01m\n",
      "=>epoch:343/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [343][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.84105 (3.84105)\td_Loss 1.46431 (1.46431)\n",
      "=>NAG Epoch: 343 Error: 3.8410491943359375, Time:     0.01m\n",
      "=>epoch:344/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [344][0/1]\tTime  0.292 ( 0.292)\tData  0.261 ( 0.261)\tLoss 3.83956 (3.83956)\td_Loss 1.46431 (1.46431)\n",
      "=>NAG Epoch: 344 Error: 3.8395557403564453, Time:     0.01m\n",
      "=>epoch:345/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [345][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.83684 (3.83684)\td_Loss 1.46435 (1.46435)\n",
      "=>NAG Epoch: 345 Error: 3.836836814880371, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_345.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_345.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_345.pkl\n",
      "=>epoch:346/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [346][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.83428 (3.83428)\td_Loss 1.46432 (1.46432)\n",
      "=>NAG Epoch: 346 Error: 3.834277629852295, Time:     0.01m\n",
      "=>epoch:347/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [347][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 3.83098 (3.83098)\td_Loss 1.46422 (1.46422)\n",
      "=>NAG Epoch: 347 Error: 3.8309824466705322, Time:     0.01m\n",
      "=>epoch:348/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [348][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.82899 (3.82899)\td_Loss 1.46452 (1.46452)\n",
      "=>NAG Epoch: 348 Error: 3.828989267349243, Time:     0.01m\n",
      "=>epoch:349/750  resolution:32 batch:128, lr6.250000e-05\n",
      "Epoch: [349][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.82676 (3.82676)\td_Loss 1.46419 (1.46419)\n",
      "=>NAG Epoch: 349 Error: 3.8267645835876465, Time:     0.01m\n",
      "=>epoch:350/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [350][0/1]\tTime  0.298 ( 0.298)\tData  0.266 ( 0.266)\tLoss 3.82412 (3.82412)\td_Loss 1.46431 (1.46431)\n",
      "=>NAG Epoch: 350 Error: 3.824117660522461, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_350.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_350.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_350.pkl\n",
      "Show images...\n",
      "=>epoch:351/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [351][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.81686 (3.81686)\td_Loss 1.46426 (1.46426)\n",
      "=>NAG Epoch: 351 Error: 3.8168632984161377, Time:     0.01m\n",
      "=>epoch:352/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [352][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.81624 (3.81624)\td_Loss 1.46418 (1.46418)\n",
      "=>NAG Epoch: 352 Error: 3.8162410259246826, Time:     0.01m\n",
      "=>epoch:353/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [353][0/1]\tTime  0.355 ( 0.355)\tData  0.324 ( 0.324)\tLoss 3.81540 (3.81540)\td_Loss 1.46426 (1.46426)\n",
      "=>NAG Epoch: 353 Error: 3.8154029846191406, Time:     0.01m\n",
      "=>epoch:354/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [354][0/1]\tTime  0.355 ( 0.355)\tData  0.324 ( 0.324)\tLoss 3.81303 (3.81303)\td_Loss 1.46424 (1.46424)\n",
      "=>NAG Epoch: 354 Error: 3.81303071975708, Time:     0.01m\n",
      "=>epoch:355/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [355][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.81169 (3.81169)\td_Loss 1.46420 (1.46420)\n",
      "=>NAG Epoch: 355 Error: 3.81168532371521, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_355.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_355.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_355.pkl\n",
      "=>epoch:356/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [356][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.81258 (3.81258)\td_Loss 1.46406 (1.46406)\n",
      "=>NAG Epoch: 356 Error: 3.8125767707824707, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:357/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [357][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.80567 (3.80567)\td_Loss 1.46412 (1.46412)\n",
      "=>NAG Epoch: 357 Error: 3.8056728839874268, Time:     0.01m\n",
      "=>epoch:358/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [358][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.80525 (3.80525)\td_Loss 1.46418 (1.46418)\n",
      "=>NAG Epoch: 358 Error: 3.8052499294281006, Time:     0.01m\n",
      "=>epoch:359/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [359][0/1]\tTime  0.313 ( 0.313)\tData  0.283 ( 0.283)\tLoss 3.80724 (3.80724)\td_Loss 1.46413 (1.46413)\n",
      "=>NAG Epoch: 359 Error: 3.807243585586548, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:360/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [360][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.80303 (3.80303)\td_Loss 1.46422 (1.46422)\n",
      "=>NAG Epoch: 360 Error: 3.8030331134796143, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_360.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_360.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_360.pkl\n",
      "=>epoch:361/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [361][0/1]\tTime  0.311 ( 0.311)\tData  0.281 ( 0.281)\tLoss 3.80234 (3.80234)\td_Loss 1.46409 (1.46409)\n",
      "=>NAG Epoch: 361 Error: 3.8023428916931152, Time:     0.01m\n",
      "=>epoch:362/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [362][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.80059 (3.80059)\td_Loss 1.46407 (1.46407)\n",
      "=>NAG Epoch: 362 Error: 3.8005857467651367, Time:     0.01m\n",
      "=>epoch:363/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [363][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 3.79990 (3.79990)\td_Loss 1.46409 (1.46409)\n",
      "=>NAG Epoch: 363 Error: 3.799898147583008, Time:     0.01m\n",
      "=>epoch:364/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [364][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 3.79741 (3.79741)\td_Loss 1.46417 (1.46417)\n",
      "=>NAG Epoch: 364 Error: 3.7974138259887695, Time:     0.01m\n",
      "=>epoch:365/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [365][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.79698 (3.79698)\td_Loss 1.46406 (1.46406)\n",
      "=>NAG Epoch: 365 Error: 3.7969777584075928, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_365.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_365.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_365.pkl\n",
      "=>epoch:366/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [366][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.79573 (3.79573)\td_Loss 1.46420 (1.46420)\n",
      "=>NAG Epoch: 366 Error: 3.795729637145996, Time:     0.01m\n",
      "=>epoch:367/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [367][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.79327 (3.79327)\td_Loss 1.46408 (1.46408)\n",
      "=>NAG Epoch: 367 Error: 3.7932748794555664, Time:     0.01m\n",
      "=>epoch:368/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [368][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.79185 (3.79185)\td_Loss 1.46405 (1.46405)\n",
      "=>NAG Epoch: 368 Error: 3.791848659515381, Time:     0.01m\n",
      "=>epoch:369/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [369][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 3.78945 (3.78945)\td_Loss 1.46415 (1.46415)\n",
      "=>NAG Epoch: 369 Error: 3.789454221725464, Time:     0.01m\n",
      "=>epoch:370/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [370][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.78819 (3.78819)\td_Loss 1.46397 (1.46397)\n",
      "=>NAG Epoch: 370 Error: 3.7881851196289062, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_370.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_370.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_370.pkl\n",
      "=>epoch:371/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [371][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.78761 (3.78761)\td_Loss 1.46408 (1.46408)\n",
      "=>NAG Epoch: 371 Error: 3.7876133918762207, Time:     0.01m\n",
      "=>epoch:372/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [372][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.78608 (3.78608)\td_Loss 1.46403 (1.46403)\n",
      "=>NAG Epoch: 372 Error: 3.7860779762268066, Time:     0.01m\n",
      "=>epoch:373/750  resolution:32 batch:128, lr3.125000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [373][0/1]\tTime  0.309 ( 0.309)\tData  0.279 ( 0.279)\tLoss 3.78389 (3.78389)\td_Loss 1.46407 (1.46407)\n",
      "=>NAG Epoch: 373 Error: 3.7838902473449707, Time:     0.01m\n",
      "=>epoch:374/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [374][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.78253 (3.78253)\td_Loss 1.46401 (1.46401)\n",
      "=>NAG Epoch: 374 Error: 3.7825264930725098, Time:     0.01m\n",
      "=>epoch:375/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [375][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.78282 (3.78282)\td_Loss 1.46413 (1.46413)\n",
      "=>NAG Epoch: 375 Error: 3.7828168869018555, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:376/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [376][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.77901 (3.77901)\td_Loss 1.46398 (1.46398)\n",
      "=>NAG Epoch: 376 Error: 3.7790122032165527, Time:     0.01m\n",
      "=>epoch:377/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [377][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.77987 (3.77987)\td_Loss 1.46407 (1.46407)\n",
      "=>NAG Epoch: 377 Error: 3.77986741065979, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:378/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [378][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.77737 (3.77737)\td_Loss 1.46384 (1.46384)\n",
      "=>NAG Epoch: 378 Error: 3.7773687839508057, Time:     0.01m\n",
      "=>epoch:379/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [379][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.77512 (3.77512)\td_Loss 1.46387 (1.46387)\n",
      "=>NAG Epoch: 379 Error: 3.7751200199127197, Time:     0.01m\n",
      "=>epoch:380/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [380][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.77375 (3.77375)\td_Loss 1.46404 (1.46404)\n",
      "=>NAG Epoch: 380 Error: 3.7737479209899902, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_380.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_380.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_380.pkl\n",
      "=>epoch:381/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [381][0/1]\tTime  0.313 ( 0.313)\tData  0.284 ( 0.284)\tLoss 3.77295 (3.77295)\td_Loss 1.46401 (1.46401)\n",
      "=>NAG Epoch: 381 Error: 3.772952079772949, Time:     0.01m\n",
      "=>epoch:382/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [382][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.77130 (3.77130)\td_Loss 1.46391 (1.46391)\n",
      "=>NAG Epoch: 382 Error: 3.7713000774383545, Time:     0.01m\n",
      "=>epoch:383/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [383][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.76932 (3.76932)\td_Loss 1.46398 (1.46398)\n",
      "=>NAG Epoch: 383 Error: 3.76932430267334, Time:     0.01m\n",
      "=>epoch:384/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [384][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 3.76849 (3.76849)\td_Loss 1.46390 (1.46390)\n",
      "=>NAG Epoch: 384 Error: 3.768491268157959, Time:     0.01m\n",
      "=>epoch:385/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [385][0/1]\tTime  0.311 ( 0.311)\tData  0.281 ( 0.281)\tLoss 3.76581 (3.76581)\td_Loss 1.46381 (1.46381)\n",
      "=>NAG Epoch: 385 Error: 3.765812873840332, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_385.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_385.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_385.pkl\n",
      "=>epoch:386/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [386][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.76579 (3.76579)\td_Loss 1.46391 (1.46391)\n",
      "=>NAG Epoch: 386 Error: 3.76579213142395, Time:     0.01m\n",
      "=>epoch:387/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [387][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 3.76407 (3.76407)\td_Loss 1.46380 (1.46380)\n",
      "=>NAG Epoch: 387 Error: 3.764070749282837, Time:     0.01m\n",
      "=>epoch:388/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [388][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.76378 (3.76378)\td_Loss 1.46395 (1.46395)\n",
      "=>NAG Epoch: 388 Error: 3.7637834548950195, Time:     0.01m\n",
      "=>epoch:389/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [389][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.76054 (3.76054)\td_Loss 1.46379 (1.46379)\n",
      "=>NAG Epoch: 389 Error: 3.760537624359131, Time:     0.01m\n",
      "=>epoch:390/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [390][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.75861 (3.75861)\td_Loss 1.46406 (1.46406)\n",
      "=>NAG Epoch: 390 Error: 3.758606195449829, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_390.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_390.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_390.pkl\n",
      "=>epoch:391/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [391][0/1]\tTime  0.293 ( 0.293)\tData  0.262 ( 0.262)\tLoss 3.75662 (3.75662)\td_Loss 1.46394 (1.46394)\n",
      "=>NAG Epoch: 391 Error: 3.7566168308258057, Time:     0.01m\n",
      "=>epoch:392/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [392][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.75644 (3.75644)\td_Loss 1.46388 (1.46388)\n",
      "=>NAG Epoch: 392 Error: 3.756436347961426, Time:     0.01m\n",
      "=>epoch:393/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [393][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.75412 (3.75412)\td_Loss 1.46397 (1.46397)\n",
      "=>NAG Epoch: 393 Error: 3.7541191577911377, Time:     0.01m\n",
      "=>epoch:394/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [394][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.75333 (3.75333)\td_Loss 1.46371 (1.46371)\n",
      "=>NAG Epoch: 394 Error: 3.7533342838287354, Time:     0.01m\n",
      "=>epoch:395/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [395][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.75049 (3.75049)\td_Loss 1.46391 (1.46391)\n",
      "=>NAG Epoch: 395 Error: 3.7504889965057373, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_395.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_395.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_395.pkl\n",
      "=>epoch:396/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [396][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.74988 (3.74988)\td_Loss 1.46389 (1.46389)\n",
      "=>NAG Epoch: 396 Error: 3.7498788833618164, Time:     0.01m\n",
      "=>epoch:397/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [397][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.75008 (3.75008)\td_Loss 1.46379 (1.46379)\n",
      "=>NAG Epoch: 397 Error: 3.750082015991211, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:398/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [398][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 3.74806 (3.74806)\td_Loss 1.46385 (1.46385)\n",
      "=>NAG Epoch: 398 Error: 3.7480578422546387, Time:     0.01m\n",
      "=>epoch:399/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [399][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.74867 (3.74867)\td_Loss 1.46383 (1.46383)\n",
      "=>NAG Epoch: 399 Error: 3.7486729621887207, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:400/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [400][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.74587 (3.74587)\td_Loss 1.46383 (1.46383)\n",
      "=>NAG Epoch: 400 Error: 3.7458724975585938, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_400.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_400.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_400.pkl\n",
      "Show images...\n",
      "=>epoch:401/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [401][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.74405 (3.74405)\td_Loss 1.46380 (1.46380)\n",
      "=>NAG Epoch: 401 Error: 3.7440545558929443, Time:     0.01m\n",
      "=>epoch:402/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [402][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.74225 (3.74225)\td_Loss 1.46384 (1.46384)\n",
      "=>NAG Epoch: 402 Error: 3.7422523498535156, Time:     0.01m\n",
      "=>epoch:403/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [403][0/1]\tTime  0.292 ( 0.292)\tData  0.261 ( 0.261)\tLoss 3.74150 (3.74150)\td_Loss 1.46393 (1.46393)\n",
      "=>NAG Epoch: 403 Error: 3.741504669189453, Time:     0.01m\n",
      "=>epoch:404/750  resolution:32 batch:128, lr3.125000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [404][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 3.74074 (3.74074)\td_Loss 1.46375 (1.46375)\n",
      "=>NAG Epoch: 404 Error: 3.740741014480591, Time:     0.01m\n",
      "=>epoch:405/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [405][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.73724 (3.73724)\td_Loss 1.46385 (1.46385)\n",
      "=>NAG Epoch: 405 Error: 3.737241268157959, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_405.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_405.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_405.pkl\n",
      "=>epoch:406/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [406][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 3.73622 (3.73622)\td_Loss 1.46379 (1.46379)\n",
      "=>NAG Epoch: 406 Error: 3.736215353012085, Time:     0.01m\n",
      "=>epoch:407/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [407][0/1]\tTime  0.308 ( 0.308)\tData  0.278 ( 0.278)\tLoss 3.73579 (3.73579)\td_Loss 1.46386 (1.46386)\n",
      "=>NAG Epoch: 407 Error: 3.735790967941284, Time:     0.01m\n",
      "=>epoch:408/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [408][0/1]\tTime  0.303 ( 0.303)\tData  0.274 ( 0.274)\tLoss 3.73328 (3.73328)\td_Loss 1.46383 (1.46383)\n",
      "=>NAG Epoch: 408 Error: 3.733275890350342, Time:     0.01m\n",
      "=>epoch:409/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [409][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.73346 (3.73346)\td_Loss 1.46376 (1.46376)\n",
      "=>NAG Epoch: 409 Error: 3.7334578037261963, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:410/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [410][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.73136 (3.73136)\td_Loss 1.46384 (1.46384)\n",
      "=>NAG Epoch: 410 Error: 3.7313599586486816, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_410.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_410.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_410.pkl\n",
      "=>epoch:411/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [411][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.72915 (3.72915)\td_Loss 1.46370 (1.46370)\n",
      "=>NAG Epoch: 411 Error: 3.72914981842041, Time:     0.01m\n",
      "=>epoch:412/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [412][0/1]\tTime  0.300 ( 0.300)\tData  0.270 ( 0.270)\tLoss 3.72754 (3.72754)\td_Loss 1.46377 (1.46377)\n",
      "=>NAG Epoch: 412 Error: 3.7275352478027344, Time:     0.01m\n",
      "=>epoch:413/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [413][0/1]\tTime  0.293 ( 0.293)\tData  0.262 ( 0.262)\tLoss 3.72732 (3.72732)\td_Loss 1.46369 (1.46368)\n",
      "=>NAG Epoch: 413 Error: 3.7273154258728027, Time:     0.01m\n",
      "=>epoch:414/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [414][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.72552 (3.72552)\td_Loss 1.46381 (1.46381)\n",
      "=>NAG Epoch: 414 Error: 3.7255218029022217, Time:     0.01m\n",
      "=>epoch:415/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [415][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.72339 (3.72339)\td_Loss 1.46375 (1.46375)\n",
      "=>NAG Epoch: 415 Error: 3.7233948707580566, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_415.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_415.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_415.pkl\n",
      "=>epoch:416/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [416][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.72252 (3.72252)\td_Loss 1.46382 (1.46382)\n",
      "=>NAG Epoch: 416 Error: 3.722519874572754, Time:     0.01m\n",
      "=>epoch:417/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [417][0/1]\tTime  0.310 ( 0.310)\tData  0.280 ( 0.280)\tLoss 3.71936 (3.71936)\td_Loss 1.46375 (1.46375)\n",
      "=>NAG Epoch: 417 Error: 3.71935772895813, Time:     0.01m\n",
      "=>epoch:418/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [418][0/1]\tTime  0.290 ( 0.290)\tData  0.259 ( 0.259)\tLoss 3.71914 (3.71914)\td_Loss 1.46383 (1.46383)\n",
      "=>NAG Epoch: 418 Error: 3.7191433906555176, Time:     0.01m\n",
      "=>epoch:419/750  resolution:32 batch:128, lr3.125000e-05\n",
      "Epoch: [419][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 3.71843 (3.71843)\td_Loss 1.46369 (1.46369)\n",
      "=>NAG Epoch: 419 Error: 3.718433141708374, Time:     0.01m\n",
      "=>epoch:420/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [420][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.71621 (3.71621)\td_Loss 1.46372 (1.46372)\n",
      "=>NAG Epoch: 420 Error: 3.7162091732025146, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_420.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_420.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_420.pkl\n",
      "=>epoch:421/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [421][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.71470 (3.71470)\td_Loss 1.46362 (1.46362)\n",
      "=>NAG Epoch: 421 Error: 3.71469783782959, Time:     0.01m\n",
      "=>epoch:422/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [422][0/1]\tTime  0.306 ( 0.306)\tData  0.275 ( 0.275)\tLoss 3.71404 (3.71404)\td_Loss 1.46359 (1.46359)\n",
      "=>NAG Epoch: 422 Error: 3.7140374183654785, Time:     0.01m\n",
      "=>epoch:423/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [423][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.71277 (3.71277)\td_Loss 1.46368 (1.46368)\n",
      "=>NAG Epoch: 423 Error: 3.712771415710449, Time:     0.01m\n",
      "=>epoch:424/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [424][0/1]\tTime  0.302 ( 0.302)\tData  0.271 ( 0.271)\tLoss 3.71355 (3.71355)\td_Loss 1.46375 (1.46375)\n",
      "=>NAG Epoch: 424 Error: 3.7135462760925293, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:425/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [425][0/1]\tTime  0.308 ( 0.308)\tData  0.277 ( 0.277)\tLoss 3.71065 (3.71065)\td_Loss 1.46367 (1.46367)\n",
      "=>NAG Epoch: 425 Error: 3.71064829826355, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_425.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_425.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_425.pkl\n",
      "=>epoch:426/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [426][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.71015 (3.71015)\td_Loss 1.46363 (1.46363)\n",
      "=>NAG Epoch: 426 Error: 3.710148334503174, Time:     0.01m\n",
      "=>epoch:427/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [427][0/1]\tTime  0.295 ( 0.295)\tData  0.266 ( 0.266)\tLoss 3.70883 (3.70883)\td_Loss 1.46358 (1.46358)\n",
      "=>NAG Epoch: 427 Error: 3.7088332176208496, Time:     0.01m\n",
      "=>epoch:428/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [428][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 3.70831 (3.70831)\td_Loss 1.46359 (1.46359)\n",
      "=>NAG Epoch: 428 Error: 3.7083065509796143, Time:     0.01m\n",
      "=>epoch:429/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [429][0/1]\tTime  0.312 ( 0.312)\tData  0.281 ( 0.281)\tLoss 3.70893 (3.70893)\td_Loss 1.46361 (1.46361)\n",
      "=>NAG Epoch: 429 Error: 3.7089338302612305, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:430/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [430][0/1]\tTime  0.302 ( 0.302)\tData  0.272 ( 0.272)\tLoss 3.70609 (3.70609)\td_Loss 1.46370 (1.46370)\n",
      "=>NAG Epoch: 430 Error: 3.7060911655426025, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_430.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_430.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_430.pkl\n",
      "=>epoch:431/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [431][0/1]\tTime  0.296 ( 0.296)\tData  0.267 ( 0.267)\tLoss 3.70432 (3.70432)\td_Loss 1.46360 (1.46360)\n",
      "=>NAG Epoch: 431 Error: 3.7043192386627197, Time:     0.01m\n",
      "=>epoch:432/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [432][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.70254 (3.70254)\td_Loss 1.46363 (1.46363)\n",
      "=>NAG Epoch: 432 Error: 3.7025365829467773, Time:     0.01m\n",
      "=>epoch:433/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [433][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.70405 (3.70405)\td_Loss 1.46370 (1.46370)\n",
      "=>NAG Epoch: 433 Error: 3.7040481567382812, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:434/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [434][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.70304 (3.70304)\td_Loss 1.46371 (1.46371)\n",
      "=>NAG Epoch: 434 Error: 3.703035831451416, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:435/750  resolution:32 batch:128, lr1.562500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [435][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.70150 (3.70150)\td_Loss 1.46369 (1.46369)\n",
      "=>NAG Epoch: 435 Error: 3.7015023231506348, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_435.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_435.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_435.pkl\n",
      "=>epoch:436/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [436][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 3.69863 (3.69863)\td_Loss 1.46365 (1.46365)\n",
      "=>NAG Epoch: 436 Error: 3.698633909225464, Time:     0.01m\n",
      "=>epoch:437/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [437][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.69972 (3.69972)\td_Loss 1.46359 (1.46359)\n",
      "=>NAG Epoch: 437 Error: 3.6997151374816895, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:438/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [438][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.69948 (3.69948)\td_Loss 1.46353 (1.46353)\n",
      "=>NAG Epoch: 438 Error: 3.6994807720184326, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:439/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [439][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.69665 (3.69665)\td_Loss 1.46353 (1.46353)\n",
      "=>NAG Epoch: 439 Error: 3.696653366088867, Time:     0.01m\n",
      "=>epoch:440/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [440][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.69561 (3.69561)\td_Loss 1.46353 (1.46353)\n",
      "=>NAG Epoch: 440 Error: 3.6956143379211426, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_440.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_440.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_440.pkl\n",
      "=>epoch:441/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [441][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.69407 (3.69407)\td_Loss 1.46354 (1.46354)\n",
      "=>NAG Epoch: 441 Error: 3.694068193435669, Time:     0.01m\n",
      "=>epoch:442/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [442][0/1]\tTime  0.298 ( 0.298)\tData  0.266 ( 0.266)\tLoss 3.69528 (3.69528)\td_Loss 1.46355 (1.46355)\n",
      "=>NAG Epoch: 442 Error: 3.6952788829803467, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:443/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [443][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 3.69433 (3.69433)\td_Loss 1.46360 (1.46360)\n",
      "=>NAG Epoch: 443 Error: 3.69433331489563, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:444/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [444][0/1]\tTime  0.297 ( 0.297)\tData  0.268 ( 0.268)\tLoss 3.69342 (3.69342)\td_Loss 1.46353 (1.46353)\n",
      "=>NAG Epoch: 444 Error: 3.6934170722961426, Time:     0.01m\n",
      "=>epoch:445/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [445][0/1]\tTime  0.296 ( 0.296)\tData  0.264 ( 0.264)\tLoss 3.69188 (3.69188)\td_Loss 1.46351 (1.46351)\n",
      "=>NAG Epoch: 445 Error: 3.6918842792510986, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_445.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_445.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_445.pkl\n",
      "=>epoch:446/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [446][0/1]\tTime  0.317 ( 0.317)\tData  0.285 ( 0.285)\tLoss 3.69099 (3.69099)\td_Loss 1.46347 (1.46347)\n",
      "=>NAG Epoch: 446 Error: 3.6909852027893066, Time:     0.01m\n",
      "=>epoch:447/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [447][0/1]\tTime  0.304 ( 0.304)\tData  0.273 ( 0.273)\tLoss 3.69130 (3.69130)\td_Loss 1.46344 (1.46344)\n",
      "=>NAG Epoch: 447 Error: 3.6912996768951416, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:448/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [448][0/1]\tTime  0.299 ( 0.299)\tData  0.267 ( 0.267)\tLoss 3.68915 (3.68915)\td_Loss 1.46345 (1.46345)\n",
      "=>NAG Epoch: 448 Error: 3.6891517639160156, Time:     0.01m\n",
      "=>epoch:449/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [449][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.68764 (3.68764)\td_Loss 1.46344 (1.46344)\n",
      "=>NAG Epoch: 449 Error: 3.6876442432403564, Time:     0.01m\n",
      "=>epoch:450/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [450][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 3.68473 (3.68473)\td_Loss 1.46349 (1.46349)\n",
      "=>NAG Epoch: 450 Error: 3.68473482131958, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_450.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_450.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_450.pkl\n",
      "Show images...\n",
      "=>epoch:451/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [451][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.68716 (3.68716)\td_Loss 1.46347 (1.46347)\n",
      "=>NAG Epoch: 451 Error: 3.687161922454834, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:452/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [452][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.68567 (3.68567)\td_Loss 1.46362 (1.46362)\n",
      "=>NAG Epoch: 452 Error: 3.6856696605682373, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:453/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [453][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 3.68346 (3.68346)\td_Loss 1.46344 (1.46344)\n",
      "=>NAG Epoch: 453 Error: 3.683459758758545, Time:     0.01m\n",
      "=>epoch:454/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [454][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 3.68309 (3.68309)\td_Loss 1.46357 (1.46357)\n",
      "=>NAG Epoch: 454 Error: 3.6830947399139404, Time:     0.01m\n",
      "=>epoch:455/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [455][0/1]\tTime  0.305 ( 0.305)\tData  0.276 ( 0.276)\tLoss 3.68154 (3.68154)\td_Loss 1.46342 (1.46342)\n",
      "=>NAG Epoch: 455 Error: 3.681537628173828, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_455.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_455.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_455.pkl\n",
      "=>epoch:456/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [456][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.68197 (3.68197)\td_Loss 1.46348 (1.46348)\n",
      "=>NAG Epoch: 456 Error: 3.6819698810577393, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:457/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [457][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 3.68112 (3.68112)\td_Loss 1.46351 (1.46351)\n",
      "=>NAG Epoch: 457 Error: 3.6811158657073975, Time:     0.01m\n",
      "=>epoch:458/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [458][0/1]\tTime  0.299 ( 0.299)\tData  0.267 ( 0.267)\tLoss 3.67901 (3.67901)\td_Loss 1.46357 (1.46357)\n",
      "=>NAG Epoch: 458 Error: 3.6790096759796143, Time:     0.01m\n",
      "=>epoch:459/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [459][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.68032 (3.68032)\td_Loss 1.46346 (1.46346)\n",
      "=>NAG Epoch: 459 Error: 3.680319309234619, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:460/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [460][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 3.67826 (3.67826)\td_Loss 1.46354 (1.46354)\n",
      "=>NAG Epoch: 460 Error: 3.6782636642456055, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_460.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_460.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_460.pkl\n",
      "=>epoch:461/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [461][0/1]\tTime  0.309 ( 0.309)\tData  0.278 ( 0.278)\tLoss 3.67888 (3.67888)\td_Loss 1.46351 (1.46351)\n",
      "=>NAG Epoch: 461 Error: 3.67887544631958, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:462/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [462][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.67517 (3.67517)\td_Loss 1.46342 (1.46342)\n",
      "=>NAG Epoch: 462 Error: 3.675170660018921, Time:     0.01m\n",
      "=>epoch:463/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [463][0/1]\tTime  0.312 ( 0.312)\tData  0.281 ( 0.281)\tLoss 3.67349 (3.67349)\td_Loss 1.46348 (1.46348)\n",
      "=>NAG Epoch: 463 Error: 3.6734893321990967, Time:     0.01m\n",
      "=>epoch:464/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [464][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.67331 (3.67331)\td_Loss 1.46354 (1.46354)\n",
      "=>NAG Epoch: 464 Error: 3.6733145713806152, Time:     0.01m\n",
      "=>epoch:465/750  resolution:32 batch:128, lr1.562500e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [465][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.67273 (3.67273)\td_Loss 1.46351 (1.46351)\n",
      "=>NAG Epoch: 465 Error: 3.6727278232574463, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_465.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_465.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_465.pkl\n",
      "=>epoch:466/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [466][0/1]\tTime  0.302 ( 0.302)\tData  0.272 ( 0.272)\tLoss 3.67226 (3.67226)\td_Loss 1.46336 (1.46336)\n",
      "=>NAG Epoch: 466 Error: 3.6722590923309326, Time:     0.01m\n",
      "=>epoch:467/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [467][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 3.67205 (3.67205)\td_Loss 1.46348 (1.46348)\n",
      "=>NAG Epoch: 467 Error: 3.672053337097168, Time:     0.01m\n",
      "=>epoch:468/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [468][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.66986 (3.66986)\td_Loss 1.46335 (1.46335)\n",
      "=>NAG Epoch: 468 Error: 3.669860363006592, Time:     0.01m\n",
      "=>epoch:469/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [469][0/1]\tTime  0.306 ( 0.306)\tData  0.275 ( 0.275)\tLoss 3.66946 (3.66946)\td_Loss 1.46355 (1.46355)\n",
      "=>NAG Epoch: 469 Error: 3.669457197189331, Time:     0.01m\n",
      "=>epoch:470/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [470][0/1]\tTime  0.304 ( 0.304)\tData  0.272 ( 0.272)\tLoss 3.67125 (3.67125)\td_Loss 1.46338 (1.46338)\n",
      "=>NAG Epoch: 470 Error: 3.6712474822998047, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:471/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [471][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.66865 (3.66865)\td_Loss 1.46338 (1.46338)\n",
      "=>NAG Epoch: 471 Error: 3.668649911880493, Time:     0.01m\n",
      "=>epoch:472/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [472][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.66629 (3.66629)\td_Loss 1.46336 (1.46336)\n",
      "=>NAG Epoch: 472 Error: 3.666288137435913, Time:     0.01m\n",
      "=>epoch:473/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [473][0/1]\tTime  0.299 ( 0.299)\tData  0.270 ( 0.270)\tLoss 3.66666 (3.66666)\td_Loss 1.46349 (1.46349)\n",
      "=>NAG Epoch: 473 Error: 3.6666581630706787, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:474/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [474][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.66455 (3.66455)\td_Loss 1.46344 (1.46344)\n",
      "=>NAG Epoch: 474 Error: 3.6645500659942627, Time:     0.01m\n",
      "=>epoch:475/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [475][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.66585 (3.66585)\td_Loss 1.46338 (1.46338)\n",
      "=>NAG Epoch: 475 Error: 3.6658496856689453, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:476/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [476][0/1]\tTime  0.305 ( 0.305)\tData  0.274 ( 0.274)\tLoss 3.66512 (3.66512)\td_Loss 1.46349 (1.46349)\n",
      "=>NAG Epoch: 476 Error: 3.6651151180267334, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:477/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [477][0/1]\tTime  0.315 ( 0.315)\tData  0.283 ( 0.283)\tLoss 3.66276 (3.66276)\td_Loss 1.46332 (1.46332)\n",
      "=>NAG Epoch: 477 Error: 3.662761688232422, Time:     0.01m\n",
      "=>epoch:478/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [478][0/1]\tTime  0.307 ( 0.307)\tData  0.276 ( 0.276)\tLoss 3.66192 (3.66192)\td_Loss 1.46339 (1.46339)\n",
      "=>NAG Epoch: 478 Error: 3.6619157791137695, Time:     0.01m\n",
      "=>epoch:479/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [479][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 3.65997 (3.65997)\td_Loss 1.46340 (1.46340)\n",
      "=>NAG Epoch: 479 Error: 3.6599717140197754, Time:     0.01m\n",
      "=>epoch:480/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [480][0/1]\tTime  0.309 ( 0.309)\tData  0.279 ( 0.279)\tLoss 3.66053 (3.66053)\td_Loss 1.46342 (1.46342)\n",
      "=>NAG Epoch: 480 Error: 3.660531759262085, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:481/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [481][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.65741 (3.65741)\td_Loss 1.46334 (1.46334)\n",
      "=>NAG Epoch: 481 Error: 3.65740966796875, Time:     0.01m\n",
      "=>epoch:482/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [482][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.65797 (3.65797)\td_Loss 1.46333 (1.46333)\n",
      "=>NAG Epoch: 482 Error: 3.657973289489746, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:483/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [483][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.65709 (3.65709)\td_Loss 1.46347 (1.46347)\n",
      "=>NAG Epoch: 483 Error: 3.6570873260498047, Time:     0.01m\n",
      "=>epoch:484/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [484][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.65724 (3.65724)\td_Loss 1.46344 (1.46344)\n",
      "=>NAG Epoch: 484 Error: 3.6572351455688477, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:485/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [485][0/1]\tTime  0.292 ( 0.292)\tData  0.261 ( 0.261)\tLoss 3.65617 (3.65617)\td_Loss 1.46342 (1.46342)\n",
      "=>NAG Epoch: 485 Error: 3.6561708450317383, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_485.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_485.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_485.pkl\n",
      "=>epoch:486/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [486][0/1]\tTime  0.290 ( 0.290)\tData  0.259 ( 0.259)\tLoss 3.65578 (3.65578)\td_Loss 1.46342 (1.46342)\n",
      "=>NAG Epoch: 486 Error: 3.65578293800354, Time:     0.01m\n",
      "=>epoch:487/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [487][0/1]\tTime  0.300 ( 0.300)\tData  0.271 ( 0.271)\tLoss 3.65518 (3.65518)\td_Loss 1.46333 (1.46333)\n",
      "=>NAG Epoch: 487 Error: 3.6551811695098877, Time:     0.01m\n",
      "=>epoch:488/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [488][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.65277 (3.65277)\td_Loss 1.46341 (1.46341)\n",
      "=>NAG Epoch: 488 Error: 3.652769088745117, Time:     0.01m\n",
      "=>epoch:489/750  resolution:32 batch:128, lr1.562500e-05\n",
      "Epoch: [489][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.65226 (3.65226)\td_Loss 1.46336 (1.46336)\n",
      "=>NAG Epoch: 489 Error: 3.652261972427368, Time:     0.01m\n",
      "=>epoch:490/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [490][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.65158 (3.65158)\td_Loss 1.46338 (1.46338)\n",
      "=>NAG Epoch: 490 Error: 3.6515815258026123, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_490.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_490.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_490.pkl\n",
      "=>epoch:491/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [491][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.65040 (3.65040)\td_Loss 1.46336 (1.46336)\n",
      "=>NAG Epoch: 491 Error: 3.6504018306732178, Time:     0.01m\n",
      "=>epoch:492/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [492][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.65105 (3.65105)\td_Loss 1.46328 (1.46328)\n",
      "=>NAG Epoch: 492 Error: 3.651054859161377, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:493/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [493][0/1]\tTime  0.286 ( 0.286)\tData  0.256 ( 0.256)\tLoss 3.65209 (3.65209)\td_Loss 1.46338 (1.46338)\n",
      "=>NAG Epoch: 493 Error: 3.6520867347717285, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:494/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [494][0/1]\tTime  0.287 ( 0.287)\tData  0.258 ( 0.258)\tLoss 3.65119 (3.65119)\td_Loss 1.46329 (1.46329)\n",
      "=>NAG Epoch: 494 Error: 3.651193141937256, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:495/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [495][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.64734 (3.64734)\td_Loss 1.46324 (1.46324)\n",
      "=>NAG Epoch: 495 Error: 3.6473357677459717, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_495.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_495.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_495.pkl\n",
      "=>epoch:496/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [496][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 3.64575 (3.64575)\td_Loss 1.46331 (1.46331)\n",
      "=>NAG Epoch: 496 Error: 3.645750045776367, Time:     0.01m\n",
      "=>epoch:497/750  resolution:32 batch:128, lr7.812500e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [497][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.64712 (3.64712)\td_Loss 1.46328 (1.46328)\n",
      "=>NAG Epoch: 497 Error: 3.6471171379089355, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:498/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [498][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.64733 (3.64733)\td_Loss 1.46324 (1.46324)\n",
      "=>NAG Epoch: 498 Error: 3.6473255157470703, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:499/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [499][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 3.64619 (3.64619)\td_Loss 1.46330 (1.46330)\n",
      "=>NAG Epoch: 499 Error: 3.646191358566284, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:500/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [500][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.64407 (3.64407)\td_Loss 1.46332 (1.46332)\n",
      "=>NAG Epoch: 500 Error: 3.6440749168395996, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_500.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_500.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_500.pkl\n",
      "Show images...\n",
      "=>epoch:501/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [501][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.64421 (3.64421)\td_Loss 1.46329 (1.46329)\n",
      "=>NAG Epoch: 501 Error: 3.6442108154296875, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:502/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [502][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.64301 (3.64301)\td_Loss 1.46332 (1.46332)\n",
      "=>NAG Epoch: 502 Error: 3.6430068016052246, Time:     0.01m\n",
      "=>epoch:503/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [503][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 3.64252 (3.64252)\td_Loss 1.46326 (1.46326)\n",
      "=>NAG Epoch: 503 Error: 3.6425228118896484, Time:     0.01m\n",
      "=>epoch:504/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [504][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.64363 (3.64363)\td_Loss 1.46320 (1.46320)\n",
      "=>NAG Epoch: 504 Error: 3.6436281204223633, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:505/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [505][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.64203 (3.64203)\td_Loss 1.46323 (1.46323)\n",
      "=>NAG Epoch: 505 Error: 3.642031192779541, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_505.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_505.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_505.pkl\n",
      "=>epoch:506/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [506][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.64220 (3.64220)\td_Loss 1.46336 (1.46336)\n",
      "=>NAG Epoch: 506 Error: 3.6422042846679688, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:507/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [507][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.64136 (3.64136)\td_Loss 1.46315 (1.46315)\n",
      "=>NAG Epoch: 507 Error: 3.641357898712158, Time:     0.01m\n",
      "=>epoch:508/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [508][0/1]\tTime  0.300 ( 0.300)\tData  0.268 ( 0.268)\tLoss 3.64332 (3.64332)\td_Loss 1.46325 (1.46325)\n",
      "=>NAG Epoch: 508 Error: 3.643317461013794, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:509/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [509][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 3.64081 (3.64081)\td_Loss 1.46316 (1.46316)\n",
      "=>NAG Epoch: 509 Error: 3.640812873840332, Time:     0.01m\n",
      "=>epoch:510/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [510][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 3.64051 (3.64051)\td_Loss 1.46319 (1.46319)\n",
      "=>NAG Epoch: 510 Error: 3.640511989593506, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_510.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_510.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_510.pkl\n",
      "=>epoch:511/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [511][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.63897 (3.63897)\td_Loss 1.46327 (1.46327)\n",
      "=>NAG Epoch: 511 Error: 3.638972759246826, Time:     0.01m\n",
      "=>epoch:512/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [512][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.64031 (3.64031)\td_Loss 1.46314 (1.46314)\n",
      "=>NAG Epoch: 512 Error: 3.6403121948242188, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:513/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [513][0/1]\tTime  0.305 ( 0.305)\tData  0.274 ( 0.274)\tLoss 3.63892 (3.63892)\td_Loss 1.46320 (1.46320)\n",
      "=>NAG Epoch: 513 Error: 3.6389212608337402, Time:     0.01m\n",
      "=>epoch:514/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [514][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 3.63843 (3.63843)\td_Loss 1.46329 (1.46329)\n",
      "=>NAG Epoch: 514 Error: 3.638428211212158, Time:     0.01m\n",
      "=>epoch:515/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [515][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.63724 (3.63724)\td_Loss 1.46326 (1.46326)\n",
      "=>NAG Epoch: 515 Error: 3.6372363567352295, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_515.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_515.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_515.pkl\n",
      "=>epoch:516/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [516][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.63659 (3.63659)\td_Loss 1.46318 (1.46318)\n",
      "=>NAG Epoch: 516 Error: 3.636586904525757, Time:     0.01m\n",
      "=>epoch:517/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [517][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.63532 (3.63532)\td_Loss 1.46321 (1.46321)\n",
      "=>NAG Epoch: 517 Error: 3.635315418243408, Time:     0.01m\n",
      "=>epoch:518/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [518][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.63778 (3.63778)\td_Loss 1.46317 (1.46317)\n",
      "=>NAG Epoch: 518 Error: 3.637782573699951, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:519/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [519][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.63571 (3.63571)\td_Loss 1.46326 (1.46326)\n",
      "=>NAG Epoch: 519 Error: 3.6357128620147705, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:520/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [520][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.63570 (3.63570)\td_Loss 1.46317 (1.46317)\n",
      "=>NAG Epoch: 520 Error: 3.635699987411499, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:521/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [521][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.63604 (3.63604)\td_Loss 1.46314 (1.46314)\n",
      "=>NAG Epoch: 521 Error: 3.6360440254211426, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:522/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [522][0/1]\tTime  0.295 ( 0.295)\tData  0.266 ( 0.266)\tLoss 3.63305 (3.63305)\td_Loss 1.46312 (1.46312)\n",
      "=>NAG Epoch: 522 Error: 3.633047103881836, Time:     0.01m\n",
      "=>epoch:523/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [523][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.63435 (3.63435)\td_Loss 1.46320 (1.46320)\n",
      "=>NAG Epoch: 523 Error: 3.634345769882202, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:524/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [524][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.63244 (3.63244)\td_Loss 1.46314 (1.46314)\n",
      "=>NAG Epoch: 524 Error: 3.6324386596679688, Time:     0.01m\n",
      "=>epoch:525/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [525][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.63281 (3.63281)\td_Loss 1.46315 (1.46315)\n",
      "=>NAG Epoch: 525 Error: 3.632814884185791, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:526/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [526][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.63091 (3.63091)\td_Loss 1.46304 (1.46304)\n",
      "=>NAG Epoch: 526 Error: 3.6309056282043457, Time:     0.01m\n",
      "=>epoch:527/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [527][0/1]\tTime  0.291 ( 0.291)\tData  0.260 ( 0.260)\tLoss 3.63274 (3.63274)\td_Loss 1.46311 (1.46311)\n",
      "=>NAG Epoch: 527 Error: 3.6327414512634277, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:528/750  resolution:32 batch:128, lr7.812500e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [528][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 3.63132 (3.63132)\td_Loss 1.46316 (1.46316)\n",
      "=>NAG Epoch: 528 Error: 3.6313247680664062, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:529/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [529][0/1]\tTime  0.291 ( 0.291)\tData  0.260 ( 0.260)\tLoss 3.63063 (3.63063)\td_Loss 1.46313 (1.46313)\n",
      "=>NAG Epoch: 529 Error: 3.6306283473968506, Time:     0.01m\n",
      "=>epoch:530/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [530][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.62941 (3.62941)\td_Loss 1.46315 (1.46315)\n",
      "=>NAG Epoch: 530 Error: 3.629409074783325, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_530.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_530.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_530.pkl\n",
      "=>epoch:531/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [531][0/1]\tTime  0.286 ( 0.286)\tData  0.256 ( 0.256)\tLoss 3.62901 (3.62901)\td_Loss 1.46319 (1.46319)\n",
      "=>NAG Epoch: 531 Error: 3.6290125846862793, Time:     0.01m\n",
      "=>epoch:532/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [532][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.62557 (3.62557)\td_Loss 1.46300 (1.46300)\n",
      "=>NAG Epoch: 532 Error: 3.6255669593811035, Time:     0.01m\n",
      "=>epoch:533/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [533][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.62967 (3.62967)\td_Loss 1.46304 (1.46304)\n",
      "=>NAG Epoch: 533 Error: 3.6296658515930176, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:534/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [534][0/1]\tTime  0.290 ( 0.290)\tData  0.258 ( 0.258)\tLoss 3.62751 (3.62751)\td_Loss 1.46302 (1.46302)\n",
      "=>NAG Epoch: 534 Error: 3.627507209777832, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:535/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [535][0/1]\tTime  0.302 ( 0.302)\tData  0.271 ( 0.271)\tLoss 3.62810 (3.62810)\td_Loss 1.46310 (1.46310)\n",
      "=>NAG Epoch: 535 Error: 3.6281025409698486, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:536/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [536][0/1]\tTime  0.303 ( 0.303)\tData  0.272 ( 0.272)\tLoss 3.62518 (3.62518)\td_Loss 1.46304 (1.46304)\n",
      "=>NAG Epoch: 536 Error: 3.6251792907714844, Time:     0.01m\n",
      "=>epoch:537/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [537][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.62611 (3.62611)\td_Loss 1.46304 (1.46304)\n",
      "=>NAG Epoch: 537 Error: 3.6261072158813477, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:538/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [538][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.62478 (3.62478)\td_Loss 1.46309 (1.46309)\n",
      "=>NAG Epoch: 538 Error: 3.6247780323028564, Time:     0.01m\n",
      "=>epoch:539/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [539][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.62416 (3.62416)\td_Loss 1.46308 (1.46308)\n",
      "=>NAG Epoch: 539 Error: 3.624157428741455, Time:     0.01m\n",
      "=>epoch:540/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [540][0/1]\tTime  0.302 ( 0.302)\tData  0.272 ( 0.272)\tLoss 3.62345 (3.62345)\td_Loss 1.46312 (1.46312)\n",
      "=>NAG Epoch: 540 Error: 3.6234512329101562, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_540.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_540.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_540.pkl\n",
      "=>epoch:541/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [541][0/1]\tTime  0.306 ( 0.306)\tData  0.276 ( 0.276)\tLoss 3.62344 (3.62344)\td_Loss 1.46310 (1.46310)\n",
      "=>NAG Epoch: 541 Error: 3.6234376430511475, Time:     0.01m\n",
      "=>epoch:542/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [542][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.62183 (3.62183)\td_Loss 1.46301 (1.46301)\n",
      "=>NAG Epoch: 542 Error: 3.6218302249908447, Time:     0.01m\n",
      "=>epoch:543/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [543][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.62326 (3.62326)\td_Loss 1.46312 (1.46312)\n",
      "=>NAG Epoch: 543 Error: 3.623262643814087, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:544/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [544][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 3.62326 (3.62326)\td_Loss 1.46308 (1.46308)\n",
      "=>NAG Epoch: 544 Error: 3.6232614517211914, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:545/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [545][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.62321 (3.62321)\td_Loss 1.46303 (1.46303)\n",
      "=>NAG Epoch: 545 Error: 3.6232144832611084, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:546/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [546][0/1]\tTime  0.302 ( 0.302)\tData  0.271 ( 0.271)\tLoss 3.62240 (3.62240)\td_Loss 1.46300 (1.46300)\n",
      "=>NAG Epoch: 546 Error: 3.6224045753479004, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:547/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [547][0/1]\tTime  0.296 ( 0.296)\tData  0.264 ( 0.264)\tLoss 3.62045 (3.62045)\td_Loss 1.46302 (1.46302)\n",
      "=>NAG Epoch: 547 Error: 3.6204466819763184, Time:     0.01m\n",
      "=>epoch:548/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [548][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 3.62083 (3.62083)\td_Loss 1.46304 (1.46304)\n",
      "=>NAG Epoch: 548 Error: 3.620828628540039, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:549/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [549][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.61887 (3.61887)\td_Loss 1.46307 (1.46307)\n",
      "=>NAG Epoch: 549 Error: 3.618870735168457, Time:     0.01m\n",
      "=>epoch:550/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [550][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.61970 (3.61970)\td_Loss 1.46306 (1.46306)\n",
      "=>NAG Epoch: 550 Error: 3.6196985244750977, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "Show images...\n",
      "=>epoch:551/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [551][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.61858 (3.61858)\td_Loss 1.46299 (1.46299)\n",
      "=>NAG Epoch: 551 Error: 3.618577003479004, Time:     0.01m\n",
      "=>epoch:552/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [552][0/1]\tTime  0.300 ( 0.300)\tData  0.271 ( 0.271)\tLoss 3.61665 (3.61665)\td_Loss 1.46305 (1.46305)\n",
      "=>NAG Epoch: 552 Error: 3.616649627685547, Time:     0.01m\n",
      "=>epoch:553/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [553][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.61851 (3.61851)\td_Loss 1.46303 (1.46303)\n",
      "=>NAG Epoch: 553 Error: 3.6185076236724854, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:554/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [554][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.61734 (3.61734)\td_Loss 1.46299 (1.46299)\n",
      "=>NAG Epoch: 554 Error: 3.617335557937622, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:555/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [555][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 3.61636 (3.61636)\td_Loss 1.46306 (1.46306)\n",
      "=>NAG Epoch: 555 Error: 3.6163644790649414, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_555.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_555.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_555.pkl\n",
      "=>epoch:556/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [556][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.61612 (3.61612)\td_Loss 1.46309 (1.46309)\n",
      "=>NAG Epoch: 556 Error: 3.616119623184204, Time:     0.01m\n",
      "=>epoch:557/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [557][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.61501 (3.61501)\td_Loss 1.46300 (1.46300)\n",
      "=>NAG Epoch: 557 Error: 3.61501407623291, Time:     0.01m\n",
      "=>epoch:558/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [558][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.61634 (3.61634)\td_Loss 1.46302 (1.46302)\n",
      "=>NAG Epoch: 558 Error: 3.6163430213928223, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:559/750  resolution:32 batch:128, lr7.812500e-06\n",
      "Epoch: [559][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.61545 (3.61545)\td_Loss 1.46304 (1.46304)\n",
      "=>NAG Epoch: 559 Error: 3.6154487133026123, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:560/750  resolution:32 batch:128, lr3.906250e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [560][0/1]\tTime  0.305 ( 0.305)\tData  0.274 ( 0.274)\tLoss 3.61364 (3.61364)\td_Loss 1.46303 (1.46303)\n",
      "=>NAG Epoch: 560 Error: 3.613635540008545, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_560.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_560.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_560.pkl\n",
      "=>epoch:561/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [561][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.61360 (3.61360)\td_Loss 1.46297 (1.46297)\n",
      "=>NAG Epoch: 561 Error: 3.613603353500366, Time:     0.01m\n",
      "=>epoch:562/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [562][0/1]\tTime  0.301 ( 0.301)\tData  0.270 ( 0.270)\tLoss 3.61384 (3.61384)\td_Loss 1.46295 (1.46295)\n",
      "=>NAG Epoch: 562 Error: 3.6138358116149902, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:563/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [563][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.61189 (3.61189)\td_Loss 1.46294 (1.46294)\n",
      "=>NAG Epoch: 563 Error: 3.611891746520996, Time:     0.01m\n",
      "=>epoch:564/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [564][0/1]\tTime  0.297 ( 0.297)\tData  0.268 ( 0.268)\tLoss 3.61377 (3.61377)\td_Loss 1.46298 (1.46298)\n",
      "=>NAG Epoch: 564 Error: 3.6137728691101074, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:565/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [565][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 3.61245 (3.61245)\td_Loss 1.46299 (1.46299)\n",
      "=>NAG Epoch: 565 Error: 3.6124494075775146, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:566/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [566][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.61236 (3.61236)\td_Loss 1.46293 (1.46293)\n",
      "=>NAG Epoch: 566 Error: 3.6123576164245605, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:567/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [567][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.61147 (3.61147)\td_Loss 1.46290 (1.46290)\n",
      "=>NAG Epoch: 567 Error: 3.611468553543091, Time:     0.01m\n",
      "=>epoch:568/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [568][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.61206 (3.61206)\td_Loss 1.46291 (1.46291)\n",
      "=>NAG Epoch: 568 Error: 3.612057685852051, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:569/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [569][0/1]\tTime  0.302 ( 0.302)\tData  0.273 ( 0.273)\tLoss 3.61106 (3.61106)\td_Loss 1.46293 (1.46293)\n",
      "=>NAG Epoch: 569 Error: 3.611056089401245, Time:     0.01m\n",
      "=>epoch:570/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [570][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.61119 (3.61119)\td_Loss 1.46299 (1.46299)\n",
      "=>NAG Epoch: 570 Error: 3.6111929416656494, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:571/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [571][0/1]\tTime  0.290 ( 0.290)\tData  0.259 ( 0.259)\tLoss 3.61129 (3.61129)\td_Loss 1.46286 (1.46286)\n",
      "=>NAG Epoch: 571 Error: 3.6112875938415527, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:572/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [572][0/1]\tTime  0.286 ( 0.286)\tData  0.256 ( 0.256)\tLoss 3.61217 (3.61217)\td_Loss 1.46289 (1.46289)\n",
      "=>NAG Epoch: 572 Error: 3.612173318862915, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:573/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [573][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.61064 (3.61064)\td_Loss 1.46294 (1.46294)\n",
      "=>NAG Epoch: 573 Error: 3.6106367111206055, Time:     0.01m\n",
      "=>epoch:574/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [574][0/1]\tTime  0.305 ( 0.305)\tData  0.275 ( 0.275)\tLoss 3.61119 (3.61119)\td_Loss 1.46297 (1.46297)\n",
      "=>NAG Epoch: 574 Error: 3.6111927032470703, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:575/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [575][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.60940 (3.60940)\td_Loss 1.46287 (1.46287)\n",
      "=>NAG Epoch: 575 Error: 3.6094019412994385, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_575.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_575.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_575.pkl\n",
      "=>epoch:576/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [576][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.61159 (3.61159)\td_Loss 1.46285 (1.46285)\n",
      "=>NAG Epoch: 576 Error: 3.611593246459961, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:577/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [577][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.60976 (3.60976)\td_Loss 1.46292 (1.46292)\n",
      "=>NAG Epoch: 577 Error: 3.609755754470825, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:578/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [578][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.60963 (3.60963)\td_Loss 1.46288 (1.46288)\n",
      "=>NAG Epoch: 578 Error: 3.6096296310424805, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:579/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [579][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.60996 (3.60996)\td_Loss 1.46284 (1.46284)\n",
      "=>NAG Epoch: 579 Error: 3.609961986541748, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:580/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [580][0/1]\tTime  0.306 ( 0.306)\tData  0.276 ( 0.276)\tLoss 3.60764 (3.60764)\td_Loss 1.46283 (1.46283)\n",
      "=>NAG Epoch: 580 Error: 3.607635736465454, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_580.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_580.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_580.pkl\n",
      "=>epoch:581/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [581][0/1]\tTime  0.298 ( 0.298)\tData  0.266 ( 0.266)\tLoss 3.60728 (3.60728)\td_Loss 1.46284 (1.46284)\n",
      "=>NAG Epoch: 581 Error: 3.6072793006896973, Time:     0.01m\n",
      "=>epoch:582/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [582][0/1]\tTime  0.311 ( 0.311)\tData  0.276 ( 0.276)\tLoss 3.60835 (3.60835)\td_Loss 1.46283 (1.46283)\n",
      "=>NAG Epoch: 582 Error: 3.608346462249756, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:583/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [583][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.60614 (3.60614)\td_Loss 1.46283 (1.46283)\n",
      "=>NAG Epoch: 583 Error: 3.60614013671875, Time:     0.01m\n",
      "=>epoch:584/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [584][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.60734 (3.60734)\td_Loss 1.46277 (1.46277)\n",
      "=>NAG Epoch: 584 Error: 3.607339859008789, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:585/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [585][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.60688 (3.60688)\td_Loss 1.46284 (1.46284)\n",
      "=>NAG Epoch: 585 Error: 3.606881856918335, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:586/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [586][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.60626 (3.60626)\td_Loss 1.46281 (1.46281)\n",
      "=>NAG Epoch: 586 Error: 3.6062607765197754, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:587/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [587][0/1]\tTime  0.314 ( 0.314)\tData  0.283 ( 0.283)\tLoss 3.60799 (3.60799)\td_Loss 1.46285 (1.46285)\n",
      "=>NAG Epoch: 587 Error: 3.607985496520996, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:588/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [588][0/1]\tTime  0.292 ( 0.292)\tData  0.263 ( 0.263)\tLoss 3.60849 (3.60849)\td_Loss 1.46289 (1.46289)\n",
      "=>NAG Epoch: 588 Error: 3.608487129211426, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:589/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [589][0/1]\tTime  0.316 ( 0.316)\tData  0.287 ( 0.287)\tLoss 3.60520 (3.60520)\td_Loss 1.46281 (1.46281)\n",
      "=>NAG Epoch: 589 Error: 3.6051976680755615, Time:     0.01m\n",
      "=>epoch:590/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [590][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.60648 (3.60648)\td_Loss 1.46291 (1.46291)\n",
      "=>NAG Epoch: 590 Error: 3.6064839363098145, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:591/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [591][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.60556 (3.60556)\td_Loss 1.46278 (1.46278)\n",
      "=>NAG Epoch: 591 Error: 3.6055612564086914, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:592/750  resolution:32 batch:128, lr3.906250e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [592][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.60584 (3.60584)\td_Loss 1.46277 (1.46277)\n",
      "=>NAG Epoch: 592 Error: 3.6058402061462402, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:593/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [593][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.60599 (3.60599)\td_Loss 1.46284 (1.46284)\n",
      "=>NAG Epoch: 593 Error: 3.605985403060913, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:594/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [594][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 3.60406 (3.60406)\td_Loss 1.46287 (1.46287)\n",
      "=>NAG Epoch: 594 Error: 3.604062795639038, Time:     0.01m\n",
      "=>epoch:595/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [595][0/1]\tTime  0.300 ( 0.300)\tData  0.270 ( 0.270)\tLoss 3.60455 (3.60455)\td_Loss 1.46281 (1.46281)\n",
      "=>NAG Epoch: 595 Error: 3.6045451164245605, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:596/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [596][0/1]\tTime  0.298 ( 0.298)\tData  0.269 ( 0.269)\tLoss 3.60475 (3.60475)\td_Loss 1.46270 (1.46270)\n",
      "=>NAG Epoch: 596 Error: 3.604748487472534, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:597/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [597][0/1]\tTime  0.299 ( 0.299)\tData  0.270 ( 0.270)\tLoss 3.60300 (3.60300)\td_Loss 1.46271 (1.46271)\n",
      "=>NAG Epoch: 597 Error: 3.6030006408691406, Time:     0.01m\n",
      "=>epoch:598/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [598][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.60431 (3.60431)\td_Loss 1.46279 (1.46279)\n",
      "=>NAG Epoch: 598 Error: 3.6043059825897217, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:599/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [599][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.60341 (3.60341)\td_Loss 1.46272 (1.46272)\n",
      "=>NAG Epoch: 599 Error: 3.6034116744995117, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:600/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [600][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.60246 (3.60246)\td_Loss 1.46273 (1.46273)\n",
      "=>NAG Epoch: 600 Error: 3.6024627685546875, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_600.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_600.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_600.pkl\n",
      "Show images...\n",
      "=>epoch:601/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [601][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.60281 (3.60281)\td_Loss 1.46279 (1.46279)\n",
      "=>NAG Epoch: 601 Error: 3.6028084754943848, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:602/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [602][0/1]\tTime  0.308 ( 0.308)\tData  0.278 ( 0.278)\tLoss 3.60243 (3.60243)\td_Loss 1.46273 (1.46273)\n",
      "=>NAG Epoch: 602 Error: 3.602426767349243, Time:     0.01m\n",
      "=>epoch:603/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [603][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.60357 (3.60357)\td_Loss 1.46276 (1.46276)\n",
      "=>NAG Epoch: 603 Error: 3.6035728454589844, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:604/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [604][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.60125 (3.60125)\td_Loss 1.46280 (1.46280)\n",
      "=>NAG Epoch: 604 Error: 3.6012518405914307, Time:     0.01m\n",
      "=>epoch:605/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [605][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.60273 (3.60273)\td_Loss 1.46278 (1.46278)\n",
      "=>NAG Epoch: 605 Error: 3.6027283668518066, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:606/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [606][0/1]\tTime  0.308 ( 0.308)\tData  0.277 ( 0.277)\tLoss 3.60313 (3.60313)\td_Loss 1.46270 (1.46270)\n",
      "=>NAG Epoch: 606 Error: 3.6031341552734375, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:607/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [607][0/1]\tTime  0.298 ( 0.298)\tData  0.266 ( 0.266)\tLoss 3.59881 (3.59881)\td_Loss 1.46274 (1.46274)\n",
      "=>NAG Epoch: 607 Error: 3.5988054275512695, Time:     0.01m\n",
      "=>epoch:608/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [608][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.60035 (3.60035)\td_Loss 1.46274 (1.46274)\n",
      "=>NAG Epoch: 608 Error: 3.600346088409424, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:609/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [609][0/1]\tTime  0.311 ( 0.311)\tData  0.280 ( 0.280)\tLoss 3.59925 (3.59925)\td_Loss 1.46273 (1.46273)\n",
      "=>NAG Epoch: 609 Error: 3.5992486476898193, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:610/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [610][0/1]\tTime  0.293 ( 0.293)\tData  0.262 ( 0.262)\tLoss 3.60133 (3.60133)\td_Loss 1.46280 (1.46280)\n",
      "=>NAG Epoch: 610 Error: 3.601329803466797, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:611/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [611][0/1]\tTime  0.295 ( 0.295)\tData  0.263 ( 0.263)\tLoss 3.59961 (3.59961)\td_Loss 1.46268 (1.46268)\n",
      "=>NAG Epoch: 611 Error: 3.599606513977051, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:612/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [612][0/1]\tTime  0.308 ( 0.308)\tData  0.276 ( 0.276)\tLoss 3.59932 (3.59932)\td_Loss 1.46267 (1.46267)\n",
      "=>NAG Epoch: 612 Error: 3.599320888519287, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:613/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [613][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 3.59937 (3.59937)\td_Loss 1.46269 (1.46269)\n",
      "=>NAG Epoch: 613 Error: 3.5993728637695312, Time:     0.01m\n",
      "=>consecutive_loss: 6\n",
      "=>epoch:614/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [614][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 3.59845 (3.59845)\td_Loss 1.46266 (1.46266)\n",
      "=>NAG Epoch: 614 Error: 3.598452568054199, Time:     0.01m\n",
      "=>epoch:615/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [615][0/1]\tTime  0.306 ( 0.306)\tData  0.276 ( 0.276)\tLoss 3.59960 (3.59960)\td_Loss 1.46271 (1.46271)\n",
      "=>NAG Epoch: 615 Error: 3.5995981693267822, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:616/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [616][0/1]\tTime  0.318 ( 0.318)\tData  0.287 ( 0.287)\tLoss 3.59935 (3.59935)\td_Loss 1.46280 (1.46280)\n",
      "=>NAG Epoch: 616 Error: 3.5993494987487793, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:617/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [617][0/1]\tTime  0.315 ( 0.315)\tData  0.285 ( 0.285)\tLoss 3.59935 (3.59935)\td_Loss 1.46268 (1.46268)\n",
      "=>NAG Epoch: 617 Error: 3.5993521213531494, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:618/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [618][0/1]\tTime  0.300 ( 0.300)\tData  0.269 ( 0.269)\tLoss 3.59771 (3.59771)\td_Loss 1.46268 (1.46268)\n",
      "=>NAG Epoch: 618 Error: 3.5977115631103516, Time:     0.01m\n",
      "=>epoch:619/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [619][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 3.59801 (3.59801)\td_Loss 1.46269 (1.46269)\n",
      "=>NAG Epoch: 619 Error: 3.5980138778686523, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:620/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [620][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.59821 (3.59821)\td_Loss 1.46267 (1.46267)\n",
      "=>NAG Epoch: 620 Error: 3.5982134342193604, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:621/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [621][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.59979 (3.59979)\td_Loss 1.46273 (1.46273)\n",
      "=>NAG Epoch: 621 Error: 3.59979248046875, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:622/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [622][0/1]\tTime  0.301 ( 0.301)\tData  0.269 ( 0.269)\tLoss 3.59701 (3.59701)\td_Loss 1.46272 (1.46272)\n",
      "=>NAG Epoch: 622 Error: 3.59700870513916, Time:     0.01m\n",
      "=>epoch:623/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [623][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.59679 (3.59679)\td_Loss 1.46268 (1.46268)\n",
      "=>NAG Epoch: 623 Error: 3.596790313720703, Time:     0.01m\n",
      "=>epoch:624/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [624][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 3.59775 (3.59775)\td_Loss 1.46270 (1.46270)\n",
      "=>NAG Epoch: 624 Error: 3.597752094268799, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:625/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [625][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.59693 (3.59693)\td_Loss 1.46261 (1.46261)\n",
      "=>NAG Epoch: 625 Error: 3.5969276428222656, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:626/750  resolution:32 batch:128, lr3.906250e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [626][0/1]\tTime  0.300 ( 0.300)\tData  0.270 ( 0.270)\tLoss 3.59499 (3.59499)\td_Loss 1.46268 (1.46268)\n",
      "=>NAG Epoch: 626 Error: 3.5949912071228027, Time:     0.01m\n",
      "=>epoch:627/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [627][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.59770 (3.59770)\td_Loss 1.46261 (1.46261)\n",
      "=>NAG Epoch: 627 Error: 3.5977025032043457, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:628/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [628][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.59483 (3.59483)\td_Loss 1.46274 (1.46274)\n",
      "=>NAG Epoch: 628 Error: 3.5948326587677, Time:     0.01m\n",
      "=>epoch:629/750  resolution:32 batch:128, lr3.906250e-06\n",
      "Epoch: [629][0/1]\tTime  0.302 ( 0.302)\tData  0.270 ( 0.270)\tLoss 3.59701 (3.59701)\td_Loss 1.46262 (1.46262)\n",
      "=>NAG Epoch: 629 Error: 3.597005844116211, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:630/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [630][0/1]\tTime  0.310 ( 0.310)\tData  0.280 ( 0.280)\tLoss 3.59314 (3.59314)\td_Loss 1.46263 (1.46263)\n",
      "=>NAG Epoch: 630 Error: 3.5931384563446045, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_630.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_630.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_630.pkl\n",
      "=>epoch:631/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [631][0/1]\tTime  0.304 ( 0.304)\tData  0.273 ( 0.273)\tLoss 3.59569 (3.59569)\td_Loss 1.46259 (1.46259)\n",
      "=>NAG Epoch: 631 Error: 3.5956904888153076, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:632/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [632][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 3.59682 (3.59682)\td_Loss 1.46262 (1.46262)\n",
      "=>NAG Epoch: 632 Error: 3.596818447113037, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:633/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [633][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 3.59456 (3.59456)\td_Loss 1.46264 (1.46264)\n",
      "=>NAG Epoch: 633 Error: 3.5945558547973633, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:634/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [634][0/1]\tTime  0.307 ( 0.307)\tData  0.276 ( 0.276)\tLoss 3.59364 (3.59364)\td_Loss 1.46260 (1.46260)\n",
      "=>NAG Epoch: 634 Error: 3.5936381816864014, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:635/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [635][0/1]\tTime  0.297 ( 0.297)\tData  0.267 ( 0.267)\tLoss 3.59511 (3.59511)\td_Loss 1.46266 (1.46266)\n",
      "=>NAG Epoch: 635 Error: 3.595107078552246, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:636/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [636][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.59393 (3.59393)\td_Loss 1.46264 (1.46264)\n",
      "=>NAG Epoch: 636 Error: 3.5939297676086426, Time:     0.01m\n",
      "=>consecutive_loss: 6\n",
      "=>epoch:637/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [637][0/1]\tTime  0.307 ( 0.307)\tData  0.278 ( 0.278)\tLoss 3.59602 (3.59602)\td_Loss 1.46257 (1.46257)\n",
      "=>NAG Epoch: 637 Error: 3.596022844314575, Time:     0.01m\n",
      "=>consecutive_loss: 7\n",
      "=>epoch:638/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [638][0/1]\tTime  0.319 ( 0.319)\tData  0.286 ( 0.286)\tLoss 3.59506 (3.59506)\td_Loss 1.46264 (1.46264)\n",
      "=>NAG Epoch: 638 Error: 3.595057964324951, Time:     0.01m\n",
      "=>consecutive_loss: 8\n",
      "=>epoch:639/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [639][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.59551 (3.59551)\td_Loss 1.46264 (1.46264)\n",
      "=>NAG Epoch: 639 Error: 3.5955088138580322, Time:     0.01m\n",
      "=>consecutive_loss: 9\n",
      "=>epoch:640/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [640][0/1]\tTime  0.306 ( 0.306)\tData  0.275 ( 0.275)\tLoss 3.59395 (3.59395)\td_Loss 1.46256 (1.46256)\n",
      "=>NAG Epoch: 640 Error: 3.593945264816284, Time:     0.01m\n",
      "=>consecutive_loss: 10\n",
      "=>epoch:641/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [641][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 3.59453 (3.59453)\td_Loss 1.46259 (1.46259)\n",
      "=>NAG Epoch: 641 Error: 3.5945346355438232, Time:     0.01m\n",
      "=>consecutive_loss: 11\n",
      "=>epoch:642/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [642][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.59285 (3.59285)\td_Loss 1.46256 (1.46256)\n",
      "=>NAG Epoch: 642 Error: 3.5928516387939453, Time:     0.01m\n",
      "=>epoch:643/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [643][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.59416 (3.59416)\td_Loss 1.46257 (1.46257)\n",
      "=>NAG Epoch: 643 Error: 3.5941641330718994, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:644/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [644][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.59423 (3.59423)\td_Loss 1.46262 (1.46262)\n",
      "=>NAG Epoch: 644 Error: 3.5942256450653076, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:645/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [645][0/1]\tTime  0.308 ( 0.308)\tData  0.277 ( 0.277)\tLoss 3.59370 (3.59370)\td_Loss 1.46257 (1.46257)\n",
      "=>NAG Epoch: 645 Error: 3.59370493888855, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:646/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [646][0/1]\tTime  0.304 ( 0.304)\tData  0.274 ( 0.274)\tLoss 3.59386 (3.59386)\td_Loss 1.46260 (1.46260)\n",
      "=>NAG Epoch: 646 Error: 3.593857765197754, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:647/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [647][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.59252 (3.59252)\td_Loss 1.46255 (1.46255)\n",
      "=>NAG Epoch: 647 Error: 3.5925228595733643, Time:     0.01m\n",
      "=>epoch:648/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [648][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.59346 (3.59346)\td_Loss 1.46260 (1.46260)\n",
      "=>NAG Epoch: 648 Error: 3.5934557914733887, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:649/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [649][0/1]\tTime  0.288 ( 0.288)\tData  0.258 ( 0.258)\tLoss 3.59081 (3.59081)\td_Loss 1.46253 (1.46253)\n",
      "=>NAG Epoch: 649 Error: 3.590808391571045, Time:     0.01m\n",
      "=>epoch:650/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [650][0/1]\tTime  0.305 ( 0.305)\tData  0.275 ( 0.275)\tLoss 3.59180 (3.59180)\td_Loss 1.46257 (1.46257)\n",
      "=>NAG Epoch: 650 Error: 3.591803550720215, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "Show images...\n",
      "=>epoch:651/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [651][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.59508 (3.59508)\td_Loss 1.46256 (1.46256)\n",
      "=>NAG Epoch: 651 Error: 3.595082998275757, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:652/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [652][0/1]\tTime  0.295 ( 0.295)\tData  0.266 ( 0.266)\tLoss 3.59299 (3.59299)\td_Loss 1.46248 (1.46248)\n",
      "=>NAG Epoch: 652 Error: 3.5929880142211914, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:653/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [653][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 3.59188 (3.59188)\td_Loss 1.46252 (1.46252)\n",
      "=>NAG Epoch: 653 Error: 3.5918796062469482, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:654/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [654][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.59256 (3.59256)\td_Loss 1.46258 (1.46258)\n",
      "=>NAG Epoch: 654 Error: 3.592559814453125, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:655/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [655][0/1]\tTime  0.288 ( 0.288)\tData  0.259 ( 0.259)\tLoss 3.59314 (3.59314)\td_Loss 1.46254 (1.46254)\n",
      "=>NAG Epoch: 655 Error: 3.5931379795074463, Time:     0.01m\n",
      "=>consecutive_loss: 6\n",
      "=>epoch:656/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [656][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.59167 (3.59167)\td_Loss 1.46253 (1.46253)\n",
      "=>NAG Epoch: 656 Error: 3.591674327850342, Time:     0.01m\n",
      "=>consecutive_loss: 7\n",
      "=>epoch:657/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [657][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.59356 (3.59356)\td_Loss 1.46248 (1.46248)\n",
      "=>NAG Epoch: 657 Error: 3.593564748764038, Time:     0.01m\n",
      "=>consecutive_loss: 8\n",
      "=>epoch:658/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [658][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.59280 (3.59280)\td_Loss 1.46248 (1.46248)\n",
      "=>NAG Epoch: 658 Error: 3.5927958488464355, Time:     0.01m\n",
      "=>consecutive_loss: 9\n",
      "=>epoch:659/750  resolution:32 batch:128, lr1.953125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [659][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.59238 (3.59238)\td_Loss 1.46248 (1.46248)\n",
      "=>NAG Epoch: 659 Error: 3.5923776626586914, Time:     0.01m\n",
      "=>consecutive_loss: 10\n",
      "=>epoch:660/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [660][0/1]\tTime  0.306 ( 0.306)\tData  0.274 ( 0.274)\tLoss 3.59066 (3.59066)\td_Loss 1.46248 (1.46248)\n",
      "=>NAG Epoch: 660 Error: 3.5906574726104736, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_660.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_660.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_660.pkl\n",
      "=>epoch:661/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [661][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.58993 (3.58993)\td_Loss 1.46253 (1.46253)\n",
      "=>NAG Epoch: 661 Error: 3.5899322032928467, Time:     0.01m\n",
      "=>epoch:662/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [662][0/1]\tTime  0.313 ( 0.313)\tData  0.283 ( 0.283)\tLoss 3.59125 (3.59125)\td_Loss 1.46254 (1.46254)\n",
      "=>NAG Epoch: 662 Error: 3.591248035430908, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:663/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [663][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 3.59031 (3.59031)\td_Loss 1.46245 (1.46245)\n",
      "=>NAG Epoch: 663 Error: 3.5903096199035645, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:664/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [664][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.59079 (3.59079)\td_Loss 1.46252 (1.46252)\n",
      "=>NAG Epoch: 664 Error: 3.5907857418060303, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:665/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [665][0/1]\tTime  0.301 ( 0.301)\tData  0.270 ( 0.270)\tLoss 3.58986 (3.58986)\td_Loss 1.46246 (1.46246)\n",
      "=>NAG Epoch: 665 Error: 3.5898571014404297, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_665.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_665.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_665.pkl\n",
      "=>epoch:666/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [666][0/1]\tTime  0.306 ( 0.306)\tData  0.276 ( 0.276)\tLoss 3.59006 (3.59006)\td_Loss 1.46250 (1.46250)\n",
      "=>NAG Epoch: 666 Error: 3.5900590419769287, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:667/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [667][0/1]\tTime  0.305 ( 0.305)\tData  0.274 ( 0.274)\tLoss 3.59029 (3.59029)\td_Loss 1.46250 (1.46250)\n",
      "=>NAG Epoch: 667 Error: 3.59029221534729, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:668/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [668][0/1]\tTime  0.334 ( 0.334)\tData  0.303 ( 0.303)\tLoss 3.59085 (3.59085)\td_Loss 1.46249 (1.46249)\n",
      "=>NAG Epoch: 668 Error: 3.5908451080322266, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:669/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [669][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.59028 (3.59028)\td_Loss 1.46242 (1.46242)\n",
      "=>NAG Epoch: 669 Error: 3.5902786254882812, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:670/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [670][0/1]\tTime  0.302 ( 0.302)\tData  0.272 ( 0.272)\tLoss 3.58938 (3.58938)\td_Loss 1.46245 (1.46245)\n",
      "=>NAG Epoch: 670 Error: 3.5893778800964355, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_670.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_670.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_670.pkl\n",
      "=>epoch:671/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [671][0/1]\tTime  0.298 ( 0.298)\tData  0.266 ( 0.266)\tLoss 3.59025 (3.59025)\td_Loss 1.46251 (1.46251)\n",
      "=>NAG Epoch: 671 Error: 3.5902481079101562, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:672/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [672][0/1]\tTime  0.349 ( 0.349)\tData  0.316 ( 0.316)\tLoss 3.59004 (3.59004)\td_Loss 1.46248 (1.46248)\n",
      "=>NAG Epoch: 672 Error: 3.5900397300720215, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:673/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [673][0/1]\tTime  0.338 ( 0.338)\tData  0.308 ( 0.308)\tLoss 3.58908 (3.58908)\td_Loss 1.46240 (1.46240)\n",
      "=>NAG Epoch: 673 Error: 3.5890755653381348, Time:     0.01m\n",
      "=>epoch:674/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [674][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.59150 (3.59150)\td_Loss 1.46244 (1.46244)\n",
      "=>NAG Epoch: 674 Error: 3.591503620147705, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:675/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [675][0/1]\tTime  0.316 ( 0.316)\tData  0.285 ( 0.285)\tLoss 3.59043 (3.59043)\td_Loss 1.46245 (1.46245)\n",
      "=>NAG Epoch: 675 Error: 3.590428352355957, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:676/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [676][0/1]\tTime  0.301 ( 0.301)\tData  0.270 ( 0.270)\tLoss 3.58998 (3.58998)\td_Loss 1.46247 (1.46247)\n",
      "=>NAG Epoch: 676 Error: 3.589984178543091, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:677/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [677][0/1]\tTime  0.304 ( 0.304)\tData  0.272 ( 0.272)\tLoss 3.58803 (3.58803)\td_Loss 1.46244 (1.46244)\n",
      "=>NAG Epoch: 677 Error: 3.58803129196167, Time:     0.01m\n",
      "=>epoch:678/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [678][0/1]\tTime  0.299 ( 0.299)\tData  0.268 ( 0.268)\tLoss 3.58863 (3.58863)\td_Loss 1.46241 (1.46241)\n",
      "=>NAG Epoch: 678 Error: 3.588625907897949, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:679/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [679][0/1]\tTime  0.298 ( 0.298)\tData  0.267 ( 0.267)\tLoss 3.58786 (3.58786)\td_Loss 1.46239 (1.46239)\n",
      "=>NAG Epoch: 679 Error: 3.5878562927246094, Time:     0.01m\n",
      "=>epoch:680/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [680][0/1]\tTime  0.297 ( 0.297)\tData  0.266 ( 0.266)\tLoss 3.58891 (3.58891)\td_Loss 1.46250 (1.46250)\n",
      "=>NAG Epoch: 680 Error: 3.5889132022857666, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:681/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [681][0/1]\tTime  0.316 ( 0.316)\tData  0.285 ( 0.285)\tLoss 3.58825 (3.58825)\td_Loss 1.46240 (1.46240)\n",
      "=>NAG Epoch: 681 Error: 3.588254451751709, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:682/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [682][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.58977 (3.58977)\td_Loss 1.46245 (1.46245)\n",
      "=>NAG Epoch: 682 Error: 3.5897741317749023, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:683/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [683][0/1]\tTime  0.309 ( 0.309)\tData  0.277 ( 0.277)\tLoss 3.58861 (3.58861)\td_Loss 1.46241 (1.46241)\n",
      "=>NAG Epoch: 683 Error: 3.5886077880859375, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:684/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [684][0/1]\tTime  0.299 ( 0.299)\tData  0.269 ( 0.269)\tLoss 3.58942 (3.58942)\td_Loss 1.46242 (1.46242)\n",
      "=>NAG Epoch: 684 Error: 3.5894217491149902, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:685/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [685][0/1]\tTime  0.295 ( 0.295)\tData  0.264 ( 0.264)\tLoss 3.58733 (3.58733)\td_Loss 1.46241 (1.46241)\n",
      "=>NAG Epoch: 685 Error: 3.5873260498046875, Time:     0.01m\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netZ_nag_685.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netG_nag_685.pkl\n",
      "Save checkpoints...! runs/nets_tester.py_cifar100_test_run/netD_nag_685.pkl\n",
      "=>epoch:686/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [686][0/1]\tTime  0.296 ( 0.296)\tData  0.265 ( 0.265)\tLoss 3.58829 (3.58829)\td_Loss 1.46240 (1.46240)\n",
      "=>NAG Epoch: 686 Error: 3.5882911682128906, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:687/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [687][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.58717 (3.58717)\td_Loss 1.46247 (1.46247)\n",
      "=>NAG Epoch: 687 Error: 3.5871706008911133, Time:     0.01m\n",
      "=>epoch:688/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [688][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.58639 (3.58639)\td_Loss 1.46238 (1.46238)\n",
      "=>NAG Epoch: 688 Error: 3.5863945484161377, Time:     0.01m\n",
      "=>epoch:689/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [689][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.59010 (3.59010)\td_Loss 1.46241 (1.46241)\n",
      "=>NAG Epoch: 689 Error: 3.590102434158325, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:690/750  resolution:32 batch:128, lr1.953125e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [690][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.58800 (3.58800)\td_Loss 1.46243 (1.46243)\n",
      "=>NAG Epoch: 690 Error: 3.5879971981048584, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:691/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [691][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.58690 (3.58690)\td_Loss 1.46243 (1.46243)\n",
      "=>NAG Epoch: 691 Error: 3.586901903152466, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:692/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [692][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.58552 (3.58552)\td_Loss 1.46244 (1.46244)\n",
      "=>NAG Epoch: 692 Error: 3.585519552230835, Time:     0.01m\n",
      "=>epoch:693/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [693][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.58700 (3.58700)\td_Loss 1.46235 (1.46235)\n",
      "=>NAG Epoch: 693 Error: 3.58699893951416, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:694/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [694][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.58712 (3.58712)\td_Loss 1.46233 (1.46233)\n",
      "=>NAG Epoch: 694 Error: 3.5871167182922363, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:695/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [695][0/1]\tTime  0.340 ( 0.340)\tData  0.310 ( 0.310)\tLoss 3.58676 (3.58676)\td_Loss 1.46237 (1.46237)\n",
      "=>NAG Epoch: 695 Error: 3.5867621898651123, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:696/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [696][0/1]\tTime  0.305 ( 0.305)\tData  0.275 ( 0.275)\tLoss 3.58549 (3.58549)\td_Loss 1.46234 (1.46234)\n",
      "=>NAG Epoch: 696 Error: 3.5854909420013428, Time:     0.01m\n",
      "=>epoch:697/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [697][0/1]\tTime  0.330 ( 0.330)\tData  0.301 ( 0.301)\tLoss 3.58613 (3.58613)\td_Loss 1.46237 (1.46237)\n",
      "=>NAG Epoch: 697 Error: 3.5861330032348633, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:698/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [698][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.58920 (3.58920)\td_Loss 1.46232 (1.46232)\n",
      "=>NAG Epoch: 698 Error: 3.5891995429992676, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:699/750  resolution:32 batch:128, lr1.953125e-06\n",
      "Epoch: [699][0/1]\tTime  0.321 ( 0.321)\tData  0.291 ( 0.291)\tLoss 3.58521 (3.58521)\td_Loss 1.46235 (1.46235)\n",
      "=>NAG Epoch: 699 Error: 3.585206985473633, Time:     0.01m\n",
      "=>epoch:700/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [700][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.58641 (3.58641)\td_Loss 1.46234 (1.46234)\n",
      "=>NAG Epoch: 700 Error: 3.586411714553833, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "Show images...\n",
      "=>epoch:701/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [701][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.58723 (3.58723)\td_Loss 1.46242 (1.46242)\n",
      "=>NAG Epoch: 701 Error: 3.5872321128845215, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:702/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [702][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.58436 (3.58436)\td_Loss 1.46230 (1.46230)\n",
      "=>NAG Epoch: 702 Error: 3.5843639373779297, Time:     0.01m\n",
      "=>epoch:703/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [703][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.58590 (3.58590)\td_Loss 1.46236 (1.46236)\n",
      "=>NAG Epoch: 703 Error: 3.5858969688415527, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:704/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [704][0/1]\tTime  0.290 ( 0.290)\tData  0.259 ( 0.259)\tLoss 3.58585 (3.58585)\td_Loss 1.46239 (1.46239)\n",
      "=>NAG Epoch: 704 Error: 3.5858469009399414, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:705/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [705][0/1]\tTime  0.286 ( 0.286)\tData  0.257 ( 0.257)\tLoss 3.58557 (3.58557)\td_Loss 1.46238 (1.46238)\n",
      "=>NAG Epoch: 705 Error: 3.5855705738067627, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:706/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [706][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.58749 (3.58749)\td_Loss 1.46237 (1.46237)\n",
      "=>NAG Epoch: 706 Error: 3.587491512298584, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:707/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [707][0/1]\tTime  0.289 ( 0.289)\tData  0.258 ( 0.258)\tLoss 3.58624 (3.58624)\td_Loss 1.46235 (1.46235)\n",
      "=>NAG Epoch: 707 Error: 3.5862438678741455, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:708/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [708][0/1]\tTime  0.290 ( 0.290)\tData  0.261 ( 0.261)\tLoss 3.58561 (3.58561)\td_Loss 1.46229 (1.46229)\n",
      "=>NAG Epoch: 708 Error: 3.5856082439422607, Time:     0.01m\n",
      "=>consecutive_loss: 6\n",
      "=>epoch:709/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [709][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.58541 (3.58541)\td_Loss 1.46237 (1.46237)\n",
      "=>NAG Epoch: 709 Error: 3.585414409637451, Time:     0.01m\n",
      "=>consecutive_loss: 7\n",
      "=>epoch:710/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [710][0/1]\tTime  0.309 ( 0.309)\tData  0.279 ( 0.279)\tLoss 3.58454 (3.58454)\td_Loss 1.46230 (1.46230)\n",
      "=>NAG Epoch: 710 Error: 3.5845396518707275, Time:     0.01m\n",
      "=>consecutive_loss: 8\n",
      "=>epoch:711/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [711][0/1]\tTime  0.294 ( 0.294)\tData  0.263 ( 0.263)\tLoss 3.58558 (3.58558)\td_Loss 1.46237 (1.46237)\n",
      "=>NAG Epoch: 711 Error: 3.585578441619873, Time:     0.01m\n",
      "=>consecutive_loss: 9\n",
      "=>epoch:712/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [712][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.58639 (3.58639)\td_Loss 1.46229 (1.46229)\n",
      "=>NAG Epoch: 712 Error: 3.5863876342773438, Time:     0.01m\n",
      "=>consecutive_loss: 10\n",
      "=>epoch:713/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [713][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.58536 (3.58536)\td_Loss 1.46226 (1.46226)\n",
      "=>NAG Epoch: 713 Error: 3.585358142852783, Time:     0.01m\n",
      "=>consecutive_loss: 11\n",
      "=>epoch:714/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [714][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.58232 (3.58232)\td_Loss 1.46233 (1.46233)\n",
      "=>NAG Epoch: 714 Error: 3.5823171138763428, Time:     0.01m\n",
      "=>epoch:715/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [715][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.58610 (3.58610)\td_Loss 1.46237 (1.46237)\n",
      "=>NAG Epoch: 715 Error: 3.586097240447998, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:716/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [716][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.58576 (3.58576)\td_Loss 1.46236 (1.46236)\n",
      "=>NAG Epoch: 716 Error: 3.5857601165771484, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:717/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [717][0/1]\tTime  0.310 ( 0.310)\tData  0.280 ( 0.280)\tLoss 3.58443 (3.58443)\td_Loss 1.46236 (1.46236)\n",
      "=>NAG Epoch: 717 Error: 3.5844340324401855, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:718/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [718][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.58423 (3.58423)\td_Loss 1.46234 (1.46234)\n",
      "=>NAG Epoch: 718 Error: 3.584233283996582, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:719/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [719][0/1]\tTime  0.298 ( 0.298)\tData  0.268 ( 0.268)\tLoss 3.58483 (3.58483)\td_Loss 1.46231 (1.46231)\n",
      "=>NAG Epoch: 719 Error: 3.584826946258545, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:720/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [720][0/1]\tTime  0.294 ( 0.294)\tData  0.264 ( 0.264)\tLoss 3.58508 (3.58508)\td_Loss 1.46234 (1.46234)\n",
      "=>NAG Epoch: 720 Error: 3.5850820541381836, Time:     0.01m\n",
      "=>consecutive_loss: 6\n",
      "=>epoch:721/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [721][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.58416 (3.58416)\td_Loss 1.46233 (1.46233)\n",
      "=>NAG Epoch: 721 Error: 3.584163188934326, Time:     0.01m\n",
      "=>consecutive_loss: 7\n",
      "=>epoch:722/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [722][0/1]\tTime  0.291 ( 0.291)\tData  0.262 ( 0.262)\tLoss 3.58627 (3.58627)\td_Loss 1.46229 (1.46229)\n",
      "=>NAG Epoch: 722 Error: 3.5862667560577393, Time:     0.01m\n",
      "=>consecutive_loss: 8\n",
      "=>epoch:723/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [723][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.58641 (3.58641)\td_Loss 1.46223 (1.46223)\n",
      "=>NAG Epoch: 723 Error: 3.5864081382751465, Time:     0.01m\n",
      "=>consecutive_loss: 9\n",
      "=>epoch:724/750  resolution:32 batch:128, lr9.765625e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [724][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.58417 (3.58417)\td_Loss 1.46233 (1.46233)\n",
      "=>NAG Epoch: 724 Error: 3.5841710567474365, Time:     0.01m\n",
      "=>consecutive_loss: 10\n",
      "=>epoch:725/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [725][0/1]\tTime  0.289 ( 0.289)\tData  0.260 ( 0.260)\tLoss 3.58429 (3.58429)\td_Loss 1.46228 (1.46228)\n",
      "=>NAG Epoch: 725 Error: 3.5842902660369873, Time:     0.01m\n",
      "=>consecutive_loss: 11\n",
      "=>epoch:726/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [726][0/1]\tTime  0.290 ( 0.290)\tData  0.260 ( 0.260)\tLoss 3.58444 (3.58444)\td_Loss 1.46227 (1.46227)\n",
      "=>NAG Epoch: 726 Error: 3.5844411849975586, Time:     0.01m\n",
      "=>consecutive_loss: 12\n",
      "=>epoch:727/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [727][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.58311 (3.58311)\td_Loss 1.46227 (1.46227)\n",
      "=>NAG Epoch: 727 Error: 3.583106517791748, Time:     0.01m\n",
      "=>consecutive_loss: 13\n",
      "=>epoch:728/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [728][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.58471 (3.58471)\td_Loss 1.46225 (1.46225)\n",
      "=>NAG Epoch: 728 Error: 3.584711790084839, Time:     0.01m\n",
      "=>consecutive_loss: 14\n",
      "=>epoch:729/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [729][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.58406 (3.58406)\td_Loss 1.46226 (1.46226)\n",
      "=>NAG Epoch: 729 Error: 3.5840585231781006, Time:     0.01m\n",
      "=>consecutive_loss: 15\n",
      "=>epoch:730/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [730][0/1]\tTime  0.287 ( 0.287)\tData  0.257 ( 0.257)\tLoss 3.58511 (3.58511)\td_Loss 1.46229 (1.46229)\n",
      "=>NAG Epoch: 730 Error: 3.585109233856201, Time:     0.01m\n",
      "=>consecutive_loss: 16\n",
      "=>epoch:731/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [731][0/1]\tTime  0.295 ( 0.295)\tData  0.266 ( 0.266)\tLoss 3.58529 (3.58529)\td_Loss 1.46224 (1.46224)\n",
      "=>NAG Epoch: 731 Error: 3.5852859020233154, Time:     0.01m\n",
      "=>consecutive_loss: 17\n",
      "=>epoch:732/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [732][0/1]\tTime  0.293 ( 0.293)\tData  0.264 ( 0.264)\tLoss 3.58341 (3.58341)\td_Loss 1.46231 (1.46231)\n",
      "=>NAG Epoch: 732 Error: 3.5834109783172607, Time:     0.01m\n",
      "=>consecutive_loss: 18\n",
      "=>epoch:733/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [733][0/1]\tTime  0.289 ( 0.289)\tData  0.259 ( 0.259)\tLoss 3.58230 (3.58230)\td_Loss 1.46229 (1.46229)\n",
      "=>NAG Epoch: 733 Error: 3.58229660987854, Time:     0.01m\n",
      "=>epoch:734/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [734][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.58519 (3.58519)\td_Loss 1.46227 (1.46227)\n",
      "=>NAG Epoch: 734 Error: 3.585193157196045, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:735/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [735][0/1]\tTime  0.303 ( 0.303)\tData  0.273 ( 0.273)\tLoss 3.58499 (3.58499)\td_Loss 1.46223 (1.46223)\n",
      "=>NAG Epoch: 735 Error: 3.584989070892334, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:736/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [736][0/1]\tTime  0.296 ( 0.296)\tData  0.266 ( 0.266)\tLoss 3.58262 (3.58262)\td_Loss 1.46221 (1.46221)\n",
      "=>NAG Epoch: 736 Error: 3.582624912261963, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:737/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [737][0/1]\tTime  0.294 ( 0.294)\tData  0.265 ( 0.265)\tLoss 3.58408 (3.58408)\td_Loss 1.46222 (1.46222)\n",
      "=>NAG Epoch: 737 Error: 3.584076166152954, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:738/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [738][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.58287 (3.58287)\td_Loss 1.46221 (1.46221)\n",
      "=>NAG Epoch: 738 Error: 3.582871437072754, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:739/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [739][0/1]\tTime  0.315 ( 0.315)\tData  0.283 ( 0.283)\tLoss 3.58197 (3.58197)\td_Loss 1.46222 (1.46222)\n",
      "=>NAG Epoch: 739 Error: 3.581973075866699, Time:     0.01m\n",
      "=>epoch:740/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [740][0/1]\tTime  0.292 ( 0.292)\tData  0.262 ( 0.262)\tLoss 3.58288 (3.58288)\td_Loss 1.46225 (1.46225)\n",
      "=>NAG Epoch: 740 Error: 3.582879066467285, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:741/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [741][0/1]\tTime  0.308 ( 0.308)\tData  0.278 ( 0.278)\tLoss 3.58355 (3.58355)\td_Loss 1.46223 (1.46223)\n",
      "=>NAG Epoch: 741 Error: 3.583547592163086, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:742/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [742][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.58129 (3.58129)\td_Loss 1.46224 (1.46224)\n",
      "=>NAG Epoch: 742 Error: 3.5812933444976807, Time:     0.01m\n",
      "=>epoch:743/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [743][0/1]\tTime  0.291 ( 0.291)\tData  0.261 ( 0.261)\tLoss 3.58322 (3.58322)\td_Loss 1.46226 (1.46226)\n",
      "=>NAG Epoch: 743 Error: 3.5832178592681885, Time:     0.01m\n",
      "=>consecutive_loss: 1\n",
      "=>epoch:744/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [744][0/1]\tTime  0.322 ( 0.322)\tData  0.288 ( 0.288)\tLoss 3.58434 (3.58434)\td_Loss 1.46221 (1.46221)\n",
      "=>NAG Epoch: 744 Error: 3.5843353271484375, Time:     0.01m\n",
      "=>consecutive_loss: 2\n",
      "=>epoch:745/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [745][0/1]\tTime  0.310 ( 0.310)\tData  0.280 ( 0.280)\tLoss 3.58414 (3.58414)\td_Loss 1.46216 (1.46216)\n",
      "=>NAG Epoch: 745 Error: 3.584141969680786, Time:     0.01m\n",
      "=>consecutive_loss: 3\n",
      "=>epoch:746/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [746][0/1]\tTime  0.310 ( 0.310)\tData  0.279 ( 0.279)\tLoss 3.58149 (3.58149)\td_Loss 1.46220 (1.46220)\n",
      "=>NAG Epoch: 746 Error: 3.581491231918335, Time:     0.01m\n",
      "=>consecutive_loss: 4\n",
      "=>epoch:747/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [747][0/1]\tTime  0.293 ( 0.293)\tData  0.263 ( 0.263)\tLoss 3.58233 (3.58233)\td_Loss 1.46222 (1.46222)\n",
      "=>NAG Epoch: 747 Error: 3.582331418991089, Time:     0.01m\n",
      "=>consecutive_loss: 5\n",
      "=>epoch:748/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [748][0/1]\tTime  0.301 ( 0.301)\tData  0.271 ( 0.271)\tLoss 3.58165 (3.58165)\td_Loss 1.46225 (1.46225)\n",
      "=>NAG Epoch: 748 Error: 3.5816526412963867, Time:     0.01m\n",
      "=>consecutive_loss: 6\n",
      "=>epoch:749/750  resolution:32 batch:128, lr9.765625e-07\n",
      "Epoch: [749][0/1]\tTime  0.295 ( 0.295)\tData  0.265 ( 0.265)\tLoss 3.58196 (3.58196)\td_Loss 1.46228 (1.46228)\n",
      "=>NAG Epoch: 749 Error: 3.581956386566162, Time:     0.01m\n",
      "=>consecutive_loss: 7\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "OPTIM = \"Adam\"\n",
    "MODEL = \"WideResNet28\"\n",
    "EPOCH_NUM = 2000\n",
    "TRAIN_SAMPLE_NUM = 100\n",
    "VAL_SAMPLE_NUM = 2000\n",
    "BATCH_SIZE = 128\n",
    "VALIDATION_SET_NUM = 1\n",
    "AUGMENT = True\n",
    "VAL_DISPLAY_DIVISOR = 25\n",
    "CIFAR_TRAIN = True\n",
    "REPLACE_PROB = 0.05\n",
    "SEED = None\n",
    "\n",
    "#cifar-10:\n",
    "#mean = (0.4914, 0.4822, 0.4465)\n",
    "#std = (0.247, 0.243, 0.261)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
    "                                  std=[0.247, 0.243, 0.261])\n",
    "\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                   std=[0.229, 0.224, 0.225])\n",
    "if AUGMENT:\n",
    "    dataAugmentation = [ \n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        AutoAugment(),\n",
    "        Cutout()\n",
    "    ]\n",
    "    augment = \"Crop,Flip,AutoAugment,Cutout\"\n",
    "else: \n",
    "    dataAugmentation = []\n",
    "    augment = \"Nothing\"\n",
    "\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose(dataAugmentation + [transforms.ToTensor(), normalize]) \n",
    "transform_val = transforms.Compose([transforms.ToTensor(), normalize]) #careful to keep this one same\n",
    "\n",
    "glico_train = datasets.CIFAR10(root='.',train=CIFAR_TRAIN, download=True)\n",
    "cifar_train = datasets.CIFAR10(root='.',train=CIFAR_TRAIN, transform=transform_train, download=True)\n",
    "cifar_val = datasets.CIFAR10(root='.',train=CIFAR_TRAIN, transform=transform_val, download=True)\n",
    "\n",
    "ss = SmallSampleController(numClasses=10,trainSampleNum=TRAIN_SAMPLE_NUM, # abstract the data-loading procedure\n",
    "                           valSampleNum=VAL_SAMPLE_NUM, batchSize=BATCH_SIZE, \n",
    "                           multiplier=VALIDATION_SET_NUM, trainDataset=cifar_train, \n",
    "                           valDataset=cifar_val)\n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data, valSets, seed = ss.generateNewSet(device,valMultiplier = VALIDATION_SET_NUM) #Sample from datasets\n",
    "\n",
    "\n",
    "train_labeled_dataset = Subset(glico_train, ss.trainSampler.indexes[0]) #get the same subset without transform\n",
    "nagTrainer = runGlico(train_labeled_dataset=train_labeled_dataset, classes=10,epochs=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import interpolate\n",
    "importlib.reload(interpolate)\n",
    "import interpolate\n",
    "from interpolate import interpolate_points\n",
    "\n",
    "\n",
    "def getGenImage(z1,z2,gen,steps,codeSize):\n",
    "    interp = interpolate_points(z1,z2,n_steps=steps, slerp=True, print_mode=False)\n",
    "    code = torch.cuda.FloatTensor(steps, codeSize).normal_(0, 0.15)\n",
    "    im = gen(interp,code)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import itertools\n",
    "class GlicoLoader:\n",
    "    \n",
    "    def getInterpolations(self):\n",
    "        interps = [[x for x in itertools.combinations(self.netZ.label2idx[y], 2)] for y in range(10)]\n",
    "        self.interps = {}\n",
    "        for i,combinations in enumerate(interps):\n",
    "            zvecs = self.netZ(torch.tensor(combinations).cuda())\n",
    "            temp = []\n",
    "            for idx in range(zvecs.size(0)):\n",
    "                z1 = zvecs[idx,0,:]\n",
    "                z2 = zvecs[idx,1,:]\n",
    "                gen = getGenImage(z1,z2,self.netG,steps=self.steps,codeSize= self.nag.code_size)\n",
    "                temp.append(gen.detach())\n",
    "                \n",
    "            self.interps[i] = torch.cat(temp,dim=0)\n",
    "            \n",
    "        \n",
    "    def __init__(self,nagTrainer,steps):\n",
    "        self.nagTrainer = nagTrainer\n",
    "        self.nag = nagTrainer.nag\n",
    "        self.netZ = self.nag.netZ\n",
    "        self.netG = self.nag.netG\n",
    "        self.steps = steps\n",
    "        self.getInterpolations()\n",
    "        \n",
    "        self.indices = [0 for x in range(10)]\n",
    "        a = self.interps[0].size(0)\n",
    "        prng = RandomState(int(time.time()))\n",
    "        self.indexers = [list(prng.permutation(np.arange(0,a))) for x in range(10)]\n",
    "        \n",
    "        \n",
    "    def sample(self,classNum):\n",
    "        if self.interps[0].size(0) == self.indices[classNum]:\n",
    "            self.indices[classNum] = 0\n",
    "            prng = RandomState(int(time.time()))\n",
    "            self.indexers[classNum] = list(prng.permutation(np.arange(0,self.interps[0].size(0))))\n",
    "            \n",
    "        temp = self.interps[classNum][self.indexers[classNum][self.indices[classNum]],:,:,:]\n",
    "            \n",
    "        return temp\n",
    "    \n",
    "    def replaceBatch(self,batch,targets,replaceProb):\n",
    "        for x in range(batch.size(0)):\n",
    "            prob = np.random.rand()\n",
    "            if prob < replaceProb:\n",
    "                batch[x,:,:,:] = self.sample(targets[x].item())\n",
    "            else:\n",
    "                pass\n",
    "        return batch\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "glicoLoader = GlicoLoader(nagTrainer,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "c_to_idx = {\"airplane\" : 0,\n",
    "\"automobile\" : 1,\n",
    "\"bird\" : 2,\n",
    "\"cat\" : 3,\n",
    "\"deer\" : 4,\n",
    "\"dog\" : 5,\n",
    "\"frog\" : 6,\n",
    "\"horse\" : 7,\n",
    "\"ship\" : 8,\n",
    "\"truck\" : 9}\n",
    "\n",
    "# idx_to_c =  {v:k for k,v in c_to_idx.items()}\n",
    "# save = True\n",
    "# matplotlib.use( 'agg' )\n",
    "\n",
    "# for _ in range(5):\n",
    "#     for class_ in range(10):\n",
    "#         gen = glicoLoader.sample(classNum=class_)\n",
    "#         plt.imshow(gen.cpu().permute(1, 2, 0))\n",
    "#         plt.axis(\"off\")\n",
    "#         if save: \n",
    "#             plt.savefig(os.path.join(\"{}{}.pdf\".format(idx_to_c[class_],_)),\n",
    "#                 bbox_inches=\"tight\",pad_inches=0)\n",
    "        \n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " => Total trainable parameters: 36.48M\n",
      "Begin Train for 2000 epochs\n",
      "Train Epoch: 1 [acc: 7%]\tLoss: 2.310721\n",
      "Train Epoch: 2 [acc: 13%]\tLoss: 2.516140\n",
      "Train Epoch: 3 [acc: 13%]\tLoss: 2.499593\n",
      "Train Epoch: 4 [acc: 13%]\tLoss: 2.367805\n",
      "Train Epoch: 5 [acc: 18%]\tLoss: 2.383141\n",
      "Train Epoch: 6 [acc: 17%]\tLoss: 2.221243\n",
      "Train Epoch: 7 [acc: 19%]\tLoss: 2.216757\n",
      "Train Epoch: 8 [acc: 24%]\tLoss: 2.215537\n",
      "Train Epoch: 9 [acc: 17%]\tLoss: 2.174945\n",
      "Train Epoch: 10 [acc: 15%]\tLoss: 2.187501\n",
      "Train Epoch: 11 [acc: 18%]\tLoss: 2.144031\n",
      "Train Epoch: 12 [acc: 23%]\tLoss: 2.054556\n",
      "Train Epoch: 13 [acc: 26%]\tLoss: 2.151839\n",
      "Train Epoch: 14 [acc: 17%]\tLoss: 2.124151\n",
      "Train Epoch: 15 [acc: 17%]\tLoss: 2.195880\n",
      "Train Epoch: 16 [acc: 24%]\tLoss: 2.128168\n",
      "Train Epoch: 17 [acc: 27%]\tLoss: 2.124317\n",
      "Train Epoch: 18 [acc: 30%]\tLoss: 2.045443\n",
      "Train Epoch: 19 [acc: 23%]\tLoss: 2.133019\n",
      "Train Epoch: 20 [acc: 27%]\tLoss: 2.000544\n",
      "Train Epoch: 21 [acc: 22%]\tLoss: 1.996009\n",
      "Train Epoch: 22 [acc: 25%]\tLoss: 2.046394\n",
      "Train Epoch: 23 [acc: 25%]\tLoss: 2.079119\n",
      "Train Epoch: 24 [acc: 23%]\tLoss: 2.092928\n",
      "Train Epoch: 25 [acc: 22%]\tLoss: 2.101141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/venv/torch11/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained for 25 epochs and tested on 5 sets of 2000 images]        Avg Acc: 16.11 +- 0.43 , Avg Loss: 4.98\n",
      "Train Epoch: 26 [acc: 20%]\tLoss: 2.116291\n",
      "Train Epoch: 27 [acc: 23%]\tLoss: 2.069545\n",
      "Train Epoch: 28 [acc: 23%]\tLoss: 2.121457\n",
      "Train Epoch: 29 [acc: 27%]\tLoss: 2.002287\n",
      "Train Epoch: 30 [acc: 19%]\tLoss: 2.124004\n",
      "Train Epoch: 31 [acc: 21%]\tLoss: 2.069081\n",
      "Train Epoch: 32 [acc: 24%]\tLoss: 2.072709\n",
      "Train Epoch: 33 [acc: 21%]\tLoss: 2.114552\n",
      "Train Epoch: 34 [acc: 19%]\tLoss: 2.056277\n",
      "Train Epoch: 35 [acc: 21%]\tLoss: 2.025362\n",
      "Train Epoch: 36 [acc: 22%]\tLoss: 1.961313\n",
      "Train Epoch: 37 [acc: 23%]\tLoss: 2.024331\n",
      "Train Epoch: 38 [acc: 23%]\tLoss: 1.964233\n",
      "Train Epoch: 39 [acc: 25%]\tLoss: 2.103429\n",
      "Train Epoch: 40 [acc: 35%]\tLoss: 1.966812\n",
      "Train Epoch: 41 [acc: 32%]\tLoss: 1.965144\n",
      "Train Epoch: 42 [acc: 24%]\tLoss: 2.013800\n",
      "Train Epoch: 43 [acc: 28%]\tLoss: 1.985408\n",
      "Train Epoch: 44 [acc: 29%]\tLoss: 1.889034\n",
      "Train Epoch: 45 [acc: 35%]\tLoss: 1.959948\n",
      "Train Epoch: 46 [acc: 31%]\tLoss: 1.979236\n",
      "Train Epoch: 47 [acc: 25%]\tLoss: 1.934720\n",
      "Train Epoch: 48 [acc: 28%]\tLoss: 1.974477\n",
      "Train Epoch: 49 [acc: 33%]\tLoss: 1.892017\n",
      "Train Epoch: 50 [acc: 33%]\tLoss: 1.953258\n",
      "[Trained for 50 epochs and tested on 5 sets of 2000 images]        Avg Acc: 17.02 +- 0.46 , Avg Loss: 5.56\n",
      "Train Epoch: 51 [acc: 24%]\tLoss: 2.065087\n",
      "Train Epoch: 52 [acc: 27%]\tLoss: 1.932252\n",
      "Train Epoch: 53 [acc: 26%]\tLoss: 1.983919\n",
      "Train Epoch: 54 [acc: 27%]\tLoss: 1.904087\n",
      "Train Epoch: 55 [acc: 23%]\tLoss: 2.053141\n",
      "Train Epoch: 56 [acc: 33%]\tLoss: 1.976554\n",
      "Train Epoch: 57 [acc: 32%]\tLoss: 1.918392\n",
      "Train Epoch: 58 [acc: 23%]\tLoss: 2.013110\n",
      "Train Epoch: 59 [acc: 23%]\tLoss: 1.963619\n",
      "Train Epoch: 60 [acc: 28%]\tLoss: 1.980975\n",
      "Train Epoch: 61 [acc: 24%]\tLoss: 1.996203\n",
      "Train Epoch: 62 [acc: 28%]\tLoss: 1.945273\n",
      "Train Epoch: 63 [acc: 26%]\tLoss: 1.930491\n",
      "Train Epoch: 64 [acc: 29%]\tLoss: 1.919642\n",
      "Train Epoch: 65 [acc: 31%]\tLoss: 1.821520\n",
      "Train Epoch: 66 [acc: 29%]\tLoss: 1.941346\n",
      "Train Epoch: 67 [acc: 30%]\tLoss: 1.861101\n",
      "Train Epoch: 68 [acc: 25%]\tLoss: 1.983417\n",
      "Train Epoch: 69 [acc: 25%]\tLoss: 1.930530\n",
      "Train Epoch: 70 [acc: 34%]\tLoss: 1.835268\n",
      "Train Epoch: 71 [acc: 25%]\tLoss: 1.945502\n",
      "Train Epoch: 72 [acc: 26%]\tLoss: 1.943932\n",
      "Train Epoch: 73 [acc: 38%]\tLoss: 1.784538\n",
      "Train Epoch: 74 [acc: 32%]\tLoss: 1.876444\n",
      "Train Epoch: 75 [acc: 33%]\tLoss: 1.828524\n",
      "[Trained for 75 epochs and tested on 5 sets of 2000 images]        Avg Acc: 22.75 +- 0.43 , Avg Loss: 2.85\n",
      "Train Epoch: 76 [acc: 31%]\tLoss: 1.842714\n",
      "Train Epoch: 77 [acc: 23%]\tLoss: 1.894245\n",
      "Train Epoch: 78 [acc: 37%]\tLoss: 1.938468\n",
      "Train Epoch: 79 [acc: 33%]\tLoss: 1.910842\n",
      "Train Epoch: 80 [acc: 32%]\tLoss: 2.016012\n",
      "Train Epoch: 81 [acc: 33%]\tLoss: 1.832444\n",
      "Train Epoch: 82 [acc: 35%]\tLoss: 1.896115\n",
      "Train Epoch: 83 [acc: 36%]\tLoss: 1.833937\n",
      "Train Epoch: 84 [acc: 32%]\tLoss: 1.923064\n",
      "Train Epoch: 85 [acc: 36%]\tLoss: 1.890574\n",
      "Train Epoch: 86 [acc: 30%]\tLoss: 2.041652\n",
      "Train Epoch: 87 [acc: 34%]\tLoss: 1.806751\n",
      "Train Epoch: 88 [acc: 43%]\tLoss: 1.720026\n",
      "Train Epoch: 89 [acc: 27%]\tLoss: 1.937842\n",
      "Train Epoch: 90 [acc: 33%]\tLoss: 1.861441\n",
      "Train Epoch: 91 [acc: 27%]\tLoss: 1.924556\n",
      "Train Epoch: 92 [acc: 34%]\tLoss: 1.811125\n",
      "Train Epoch: 93 [acc: 35%]\tLoss: 1.750925\n",
      "Train Epoch: 94 [acc: 38%]\tLoss: 1.805673\n",
      "Train Epoch: 95 [acc: 29%]\tLoss: 1.899054\n",
      "Train Epoch: 96 [acc: 34%]\tLoss: 1.878090\n",
      "Train Epoch: 97 [acc: 33%]\tLoss: 1.899512\n",
      "Train Epoch: 98 [acc: 34%]\tLoss: 1.826628\n",
      "Train Epoch: 99 [acc: 37%]\tLoss: 1.757361\n",
      "Train Epoch: 100 [acc: 40%]\tLoss: 1.761681\n",
      "[Trained for 100 epochs and tested on 5 sets of 2000 images]        Avg Acc: 21.92 +- 0.53 , Avg Loss: 2.97\n",
      "Train Epoch: 101 [acc: 31%]\tLoss: 1.881212\n",
      "Train Epoch: 102 [acc: 34%]\tLoss: 1.796603\n",
      "Train Epoch: 103 [acc: 36%]\tLoss: 1.883275\n",
      "Train Epoch: 104 [acc: 34%]\tLoss: 1.766400\n",
      "Train Epoch: 105 [acc: 32%]\tLoss: 1.784296\n",
      "Train Epoch: 106 [acc: 47%]\tLoss: 1.548816\n",
      "Train Epoch: 107 [acc: 38%]\tLoss: 1.694448\n",
      "Train Epoch: 108 [acc: 37%]\tLoss: 1.765569\n",
      "Train Epoch: 109 [acc: 32%]\tLoss: 1.912863\n",
      "Train Epoch: 110 [acc: 31%]\tLoss: 1.804987\n",
      "Train Epoch: 111 [acc: 37%]\tLoss: 1.818315\n",
      "Train Epoch: 112 [acc: 38%]\tLoss: 1.830470\n",
      "Train Epoch: 113 [acc: 34%]\tLoss: 1.773873\n",
      "Train Epoch: 114 [acc: 37%]\tLoss: 1.699568\n",
      "Train Epoch: 115 [acc: 44%]\tLoss: 1.691775\n",
      "Train Epoch: 116 [acc: 33%]\tLoss: 1.776801\n",
      "Train Epoch: 117 [acc: 37%]\tLoss: 1.683645\n",
      "Train Epoch: 118 [acc: 33%]\tLoss: 1.790209\n",
      "Train Epoch: 119 [acc: 39%]\tLoss: 1.764881\n",
      "Train Epoch: 120 [acc: 34%]\tLoss: 1.645628\n",
      "Train Epoch: 121 [acc: 35%]\tLoss: 1.786141\n",
      "Train Epoch: 122 [acc: 36%]\tLoss: 1.635875\n",
      "Train Epoch: 123 [acc: 42%]\tLoss: 1.604160\n",
      "Train Epoch: 124 [acc: 44%]\tLoss: 1.620722\n",
      "Train Epoch: 125 [acc: 35%]\tLoss: 1.729090\n",
      "[Trained for 125 epochs and tested on 5 sets of 2000 images]        Avg Acc: 24.37 +- 0.58 , Avg Loss: 3.40\n",
      "Train Epoch: 126 [acc: 37%]\tLoss: 1.662044\n",
      "Train Epoch: 127 [acc: 42%]\tLoss: 1.717566\n",
      "Train Epoch: 128 [acc: 39%]\tLoss: 1.705272\n",
      "Train Epoch: 129 [acc: 43%]\tLoss: 1.687995\n",
      "Train Epoch: 130 [acc: 45%]\tLoss: 1.692318\n",
      "Train Epoch: 131 [acc: 39%]\tLoss: 1.627272\n",
      "Train Epoch: 132 [acc: 36%]\tLoss: 1.966505\n",
      "Train Epoch: 133 [acc: 37%]\tLoss: 1.727305\n",
      "Train Epoch: 134 [acc: 36%]\tLoss: 1.705857\n",
      "Train Epoch: 135 [acc: 43%]\tLoss: 1.570870\n",
      "Train Epoch: 136 [acc: 42%]\tLoss: 1.735145\n",
      "Train Epoch: 137 [acc: 36%]\tLoss: 1.709900\n",
      "Train Epoch: 138 [acc: 37%]\tLoss: 1.711773\n",
      "Train Epoch: 139 [acc: 43%]\tLoss: 1.736710\n",
      "Train Epoch: 140 [acc: 36%]\tLoss: 1.683380\n",
      "Train Epoch: 141 [acc: 43%]\tLoss: 1.609529\n",
      "Train Epoch: 142 [acc: 43%]\tLoss: 1.716413\n",
      "Train Epoch: 143 [acc: 45%]\tLoss: 1.603975\n",
      "Train Epoch: 144 [acc: 43%]\tLoss: 1.799178\n",
      "Train Epoch: 145 [acc: 42%]\tLoss: 1.571600\n",
      "Train Epoch: 146 [acc: 36%]\tLoss: 1.767142\n",
      "Train Epoch: 147 [acc: 38%]\tLoss: 1.710971\n",
      "Train Epoch: 148 [acc: 40%]\tLoss: 1.705782\n",
      "Train Epoch: 149 [acc: 49%]\tLoss: 1.497568\n",
      "Train Epoch: 150 [acc: 39%]\tLoss: 1.688878\n",
      "[Trained for 150 epochs and tested on 5 sets of 2000 images]        Avg Acc: 26.47 +- 0.60 , Avg Loss: 2.96\n",
      "Train Epoch: 151 [acc: 29%]\tLoss: 1.901567\n",
      "Train Epoch: 152 [acc: 44%]\tLoss: 1.617621\n",
      "Train Epoch: 153 [acc: 43%]\tLoss: 1.664852\n",
      "Train Epoch: 154 [acc: 39%]\tLoss: 1.694421\n",
      "Train Epoch: 155 [acc: 50%]\tLoss: 1.492013\n",
      "Train Epoch: 156 [acc: 41%]\tLoss: 1.667306\n",
      "Train Epoch: 157 [acc: 45%]\tLoss: 1.634568\n",
      "Train Epoch: 158 [acc: 41%]\tLoss: 1.532723\n",
      "Train Epoch: 159 [acc: 49%]\tLoss: 1.667972\n",
      "Train Epoch: 160 [acc: 44%]\tLoss: 1.748926\n",
      "Train Epoch: 161 [acc: 40%]\tLoss: 1.720346\n",
      "Train Epoch: 162 [acc: 34%]\tLoss: 1.819577\n",
      "Train Epoch: 163 [acc: 40%]\tLoss: 1.569803\n",
      "Train Epoch: 164 [acc: 34%]\tLoss: 1.932729\n",
      "Train Epoch: 165 [acc: 43%]\tLoss: 1.511687\n",
      "Train Epoch: 166 [acc: 44%]\tLoss: 1.718114\n",
      "Train Epoch: 167 [acc: 39%]\tLoss: 1.654907\n",
      "Train Epoch: 168 [acc: 42%]\tLoss: 1.641070\n",
      "Train Epoch: 169 [acc: 44%]\tLoss: 1.673311\n",
      "Train Epoch: 170 [acc: 41%]\tLoss: 1.608287\n",
      "Train Epoch: 171 [acc: 48%]\tLoss: 1.588863\n",
      "Train Epoch: 172 [acc: 40%]\tLoss: 1.699063\n",
      "Train Epoch: 173 [acc: 43%]\tLoss: 1.657323\n",
      "Train Epoch: 174 [acc: 41%]\tLoss: 1.484154\n",
      "Train Epoch: 175 [acc: 44%]\tLoss: 1.640542\n",
      "[Trained for 175 epochs and tested on 5 sets of 2000 images]        Avg Acc: 27.08 +- 0.57 , Avg Loss: 2.50\n",
      "Train Epoch: 176 [acc: 40%]\tLoss: 1.558761\n",
      "Train Epoch: 177 [acc: 37%]\tLoss: 1.542059\n",
      "Train Epoch: 178 [acc: 40%]\tLoss: 1.616793\n",
      "Train Epoch: 179 [acc: 50%]\tLoss: 1.518840\n",
      "Train Epoch: 180 [acc: 49%]\tLoss: 1.559542\n",
      "Train Epoch: 181 [acc: 43%]\tLoss: 1.500416\n",
      "Train Epoch: 182 [acc: 56%]\tLoss: 1.453558\n",
      "Train Epoch: 183 [acc: 48%]\tLoss: 1.573881\n",
      "Train Epoch: 184 [acc: 52%]\tLoss: 1.415281\n",
      "Train Epoch: 185 [acc: 52%]\tLoss: 1.495395\n",
      "Train Epoch: 186 [acc: 41%]\tLoss: 1.620744\n",
      "Train Epoch: 187 [acc: 44%]\tLoss: 1.512209\n",
      "Train Epoch: 188 [acc: 54%]\tLoss: 1.400487\n",
      "Train Epoch: 189 [acc: 42%]\tLoss: 1.689286\n",
      "Train Epoch: 190 [acc: 49%]\tLoss: 1.493758\n",
      "Train Epoch: 191 [acc: 57%]\tLoss: 1.330544\n",
      "Train Epoch: 192 [acc: 52%]\tLoss: 1.519341\n",
      "Train Epoch: 193 [acc: 51%]\tLoss: 1.530928\n",
      "Train Epoch: 194 [acc: 52%]\tLoss: 1.484625\n",
      "Train Epoch: 195 [acc: 47%]\tLoss: 1.634945\n",
      "Train Epoch: 196 [acc: 54%]\tLoss: 1.297940\n",
      "Train Epoch: 197 [acc: 46%]\tLoss: 1.470160\n",
      "Train Epoch: 198 [acc: 51%]\tLoss: 1.245465\n",
      "Train Epoch: 199 [acc: 48%]\tLoss: 1.437471\n",
      "Train Epoch: 200 [acc: 51%]\tLoss: 1.459000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained for 200 epochs and tested on 5 sets of 2000 images]        Avg Acc: 28.62 +- 0.91 , Avg Loss: 3.03\n",
      "Train Epoch: 201 [acc: 54%]\tLoss: 1.424509\n",
      "Train Epoch: 202 [acc: 50%]\tLoss: 1.508255\n",
      "Train Epoch: 203 [acc: 44%]\tLoss: 1.575523\n",
      "Train Epoch: 204 [acc: 48%]\tLoss: 1.422364\n",
      "Train Epoch: 205 [acc: 48%]\tLoss: 1.377148\n",
      "Train Epoch: 206 [acc: 49%]\tLoss: 1.414764\n",
      "Train Epoch: 207 [acc: 40%]\tLoss: 1.554871\n",
      "Train Epoch: 208 [acc: 48%]\tLoss: 1.445502\n",
      "Train Epoch: 209 [acc: 52%]\tLoss: 1.471260\n",
      "Train Epoch: 210 [acc: 51%]\tLoss: 1.464094\n",
      "Train Epoch: 211 [acc: 52%]\tLoss: 1.395939\n",
      "Train Epoch: 212 [acc: 54%]\tLoss: 1.533380\n",
      "Train Epoch: 213 [acc: 53%]\tLoss: 1.476205\n",
      "Train Epoch: 214 [acc: 53%]\tLoss: 1.431048\n",
      "Train Epoch: 215 [acc: 47%]\tLoss: 1.399814\n",
      "Train Epoch: 216 [acc: 48%]\tLoss: 1.541440\n",
      "Train Epoch: 217 [acc: 44%]\tLoss: 1.533271\n",
      "Train Epoch: 218 [acc: 45%]\tLoss: 1.582577\n",
      "Train Epoch: 219 [acc: 47%]\tLoss: 1.486198\n",
      "Train Epoch: 220 [acc: 45%]\tLoss: 1.440551\n",
      "Train Epoch: 221 [acc: 47%]\tLoss: 1.623093\n",
      "Train Epoch: 222 [acc: 61%]\tLoss: 1.275908\n",
      "Train Epoch: 223 [acc: 60%]\tLoss: 1.289232\n",
      "Train Epoch: 224 [acc: 52%]\tLoss: 1.421788\n",
      "Train Epoch: 225 [acc: 44%]\tLoss: 1.521904\n",
      "[Trained for 225 epochs and tested on 5 sets of 2000 images]        Avg Acc: 28.76 +- 0.83 , Avg Loss: 2.91\n",
      "Train Epoch: 226 [acc: 42%]\tLoss: 1.522022\n",
      "Train Epoch: 227 [acc: 54%]\tLoss: 1.515879\n",
      "Train Epoch: 228 [acc: 39%]\tLoss: 1.483300\n",
      "Train Epoch: 229 [acc: 55%]\tLoss: 1.267466\n",
      "Train Epoch: 230 [acc: 51%]\tLoss: 1.383585\n",
      "Train Epoch: 231 [acc: 48%]\tLoss: 1.272026\n",
      "Train Epoch: 232 [acc: 53%]\tLoss: 1.274804\n",
      "Train Epoch: 233 [acc: 41%]\tLoss: 1.582999\n",
      "Train Epoch: 234 [acc: 55%]\tLoss: 1.493667\n",
      "Train Epoch: 235 [acc: 51%]\tLoss: 1.351359\n",
      "Train Epoch: 236 [acc: 51%]\tLoss: 1.326709\n",
      "Train Epoch: 237 [acc: 54%]\tLoss: 1.283597\n",
      "Train Epoch: 238 [acc: 57%]\tLoss: 1.236907\n",
      "Train Epoch: 239 [acc: 62%]\tLoss: 1.267706\n",
      "Train Epoch: 240 [acc: 54%]\tLoss: 1.334919\n",
      "Train Epoch: 241 [acc: 61%]\tLoss: 1.264429\n",
      "Train Epoch: 242 [acc: 52%]\tLoss: 1.411371\n",
      "Train Epoch: 243 [acc: 58%]\tLoss: 1.207787\n",
      "Train Epoch: 244 [acc: 51%]\tLoss: 1.490664\n",
      "Train Epoch: 245 [acc: 58%]\tLoss: 1.301147\n",
      "Train Epoch: 246 [acc: 58%]\tLoss: 1.172254\n",
      "Train Epoch: 247 [acc: 63%]\tLoss: 1.190324\n",
      "Train Epoch: 248 [acc: 51%]\tLoss: 1.257887\n",
      "Train Epoch: 249 [acc: 64%]\tLoss: 1.163889\n",
      "Train Epoch: 250 [acc: 58%]\tLoss: 1.280584\n",
      "[Trained for 250 epochs and tested on 5 sets of 2000 images]        Avg Acc: 27.82 +- 1.09 , Avg Loss: 2.68\n",
      "Train Epoch: 251 [acc: 68%]\tLoss: 1.074360\n",
      "Train Epoch: 252 [acc: 55%]\tLoss: 1.301649\n",
      "Train Epoch: 253 [acc: 61%]\tLoss: 1.290866\n",
      "Train Epoch: 254 [acc: 57%]\tLoss: 1.298305\n",
      "Train Epoch: 255 [acc: 59%]\tLoss: 1.198514\n",
      "Train Epoch: 256 [acc: 53%]\tLoss: 1.301647\n",
      "Train Epoch: 257 [acc: 57%]\tLoss: 1.180666\n",
      "Train Epoch: 258 [acc: 54%]\tLoss: 1.197689\n",
      "Train Epoch: 259 [acc: 53%]\tLoss: 1.342172\n",
      "Train Epoch: 260 [acc: 57%]\tLoss: 1.153163\n",
      "Train Epoch: 261 [acc: 47%]\tLoss: 1.412254\n",
      "Train Epoch: 262 [acc: 59%]\tLoss: 1.119299\n",
      "Train Epoch: 263 [acc: 64%]\tLoss: 1.159211\n",
      "Train Epoch: 264 [acc: 63%]\tLoss: 1.160121\n",
      "Train Epoch: 265 [acc: 57%]\tLoss: 1.186943\n",
      "Train Epoch: 266 [acc: 62%]\tLoss: 1.122872\n",
      "Train Epoch: 267 [acc: 67%]\tLoss: 1.035303\n",
      "Train Epoch: 268 [acc: 64%]\tLoss: 1.137470\n",
      "Train Epoch: 269 [acc: 65%]\tLoss: 1.079000\n",
      "Train Epoch: 270 [acc: 67%]\tLoss: 1.068336\n",
      "Train Epoch: 271 [acc: 58%]\tLoss: 1.179015\n",
      "Train Epoch: 272 [acc: 66%]\tLoss: 1.090932\n",
      "Train Epoch: 273 [acc: 59%]\tLoss: 1.236709\n",
      "Train Epoch: 274 [acc: 70%]\tLoss: 1.142984\n",
      "Train Epoch: 275 [acc: 61%]\tLoss: 1.064495\n",
      "[Trained for 275 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.74 +- 0.57 , Avg Loss: 2.79\n",
      "Train Epoch: 276 [acc: 65%]\tLoss: 1.129737\n",
      "Train Epoch: 277 [acc: 71%]\tLoss: 0.994780\n",
      "Train Epoch: 278 [acc: 68%]\tLoss: 0.984582\n",
      "Train Epoch: 279 [acc: 62%]\tLoss: 1.069834\n",
      "Train Epoch: 280 [acc: 64%]\tLoss: 1.068212\n",
      "Train Epoch: 281 [acc: 67%]\tLoss: 1.301579\n",
      "Train Epoch: 282 [acc: 61%]\tLoss: 1.129198\n",
      "Train Epoch: 283 [acc: 65%]\tLoss: 1.159860\n",
      "Train Epoch: 284 [acc: 63%]\tLoss: 1.114248\n",
      "Train Epoch: 285 [acc: 66%]\tLoss: 1.023250\n",
      "Train Epoch: 286 [acc: 61%]\tLoss: 1.121933\n",
      "Train Epoch: 287 [acc: 62%]\tLoss: 1.070505\n",
      "Train Epoch: 288 [acc: 61%]\tLoss: 1.205921\n",
      "Train Epoch: 289 [acc: 67%]\tLoss: 1.120605\n",
      "Train Epoch: 290 [acc: 54%]\tLoss: 1.421980\n",
      "Train Epoch: 291 [acc: 62%]\tLoss: 1.348748\n",
      "Train Epoch: 292 [acc: 58%]\tLoss: 1.228228\n",
      "Train Epoch: 293 [acc: 53%]\tLoss: 1.209012\n",
      "Train Epoch: 294 [acc: 73%]\tLoss: 0.971529\n",
      "Train Epoch: 295 [acc: 48%]\tLoss: 1.417392\n",
      "Train Epoch: 296 [acc: 57%]\tLoss: 1.114513\n",
      "Train Epoch: 297 [acc: 56%]\tLoss: 1.156743\n",
      "Train Epoch: 298 [acc: 65%]\tLoss: 1.091212\n",
      "Train Epoch: 299 [acc: 68%]\tLoss: 0.992758\n",
      "Train Epoch: 300 [acc: 74%]\tLoss: 0.927418\n",
      "[Trained for 300 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.38 +- 0.91 , Avg Loss: 2.88\n",
      "Train Epoch: 301 [acc: 67%]\tLoss: 0.963985\n",
      "Train Epoch: 302 [acc: 67%]\tLoss: 1.035383\n",
      "Train Epoch: 303 [acc: 56%]\tLoss: 1.197885\n",
      "Train Epoch: 304 [acc: 63%]\tLoss: 1.102608\n",
      "Train Epoch: 305 [acc: 60%]\tLoss: 1.089666\n",
      "Train Epoch: 306 [acc: 60%]\tLoss: 1.106177\n",
      "Train Epoch: 307 [acc: 63%]\tLoss: 0.989510\n",
      "Train Epoch: 308 [acc: 67%]\tLoss: 0.990079\n",
      "Train Epoch: 309 [acc: 59%]\tLoss: 1.212763\n",
      "Train Epoch: 310 [acc: 65%]\tLoss: 1.050381\n",
      "Train Epoch: 311 [acc: 69%]\tLoss: 1.110324\n",
      "Train Epoch: 312 [acc: 70%]\tLoss: 1.035557\n",
      "Train Epoch: 313 [acc: 62%]\tLoss: 1.158885\n",
      "Train Epoch: 314 [acc: 72%]\tLoss: 0.944754\n",
      "Train Epoch: 315 [acc: 71%]\tLoss: 0.845467\n",
      "Train Epoch: 316 [acc: 69%]\tLoss: 0.817658\n",
      "Train Epoch: 317 [acc: 66%]\tLoss: 0.934930\n",
      "Train Epoch: 318 [acc: 72%]\tLoss: 0.841710\n",
      "Train Epoch: 319 [acc: 71%]\tLoss: 0.871986\n",
      "Train Epoch: 320 [acc: 71%]\tLoss: 0.959451\n",
      "Train Epoch: 321 [acc: 69%]\tLoss: 0.945862\n",
      "Train Epoch: 322 [acc: 68%]\tLoss: 1.032876\n",
      "Train Epoch: 323 [acc: 76%]\tLoss: 0.889423\n",
      "Train Epoch: 324 [acc: 76%]\tLoss: 0.789025\n",
      "Train Epoch: 325 [acc: 77%]\tLoss: 0.824679\n",
      "[Trained for 325 epochs and tested on 5 sets of 2000 images]        Avg Acc: 26.97 +- 0.69 , Avg Loss: 3.51\n",
      "Train Epoch: 326 [acc: 68%]\tLoss: 0.905244\n",
      "Train Epoch: 327 [acc: 67%]\tLoss: 0.987647\n",
      "Train Epoch: 328 [acc: 68%]\tLoss: 0.947686\n",
      "Train Epoch: 329 [acc: 77%]\tLoss: 0.706816\n",
      "Train Epoch: 330 [acc: 68%]\tLoss: 0.882664\n",
      "Train Epoch: 331 [acc: 76%]\tLoss: 0.728912\n",
      "Train Epoch: 332 [acc: 66%]\tLoss: 1.189366\n",
      "Train Epoch: 333 [acc: 66%]\tLoss: 1.162520\n",
      "Train Epoch: 334 [acc: 57%]\tLoss: 1.241561\n",
      "Train Epoch: 335 [acc: 65%]\tLoss: 0.977971\n",
      "Train Epoch: 336 [acc: 65%]\tLoss: 1.062047\n",
      "Train Epoch: 337 [acc: 63%]\tLoss: 1.114164\n",
      "Train Epoch: 338 [acc: 71%]\tLoss: 0.870127\n",
      "Train Epoch: 339 [acc: 71%]\tLoss: 0.987662\n",
      "Train Epoch: 340 [acc: 69%]\tLoss: 0.932925\n",
      "Train Epoch: 341 [acc: 66%]\tLoss: 1.181067\n",
      "Train Epoch: 342 [acc: 70%]\tLoss: 1.024729\n",
      "Train Epoch: 343 [acc: 76%]\tLoss: 0.858174\n",
      "Train Epoch: 344 [acc: 66%]\tLoss: 0.960000\n",
      "Train Epoch: 345 [acc: 69%]\tLoss: 0.928485\n",
      "Train Epoch: 346 [acc: 70%]\tLoss: 0.882196\n",
      "Train Epoch: 347 [acc: 75%]\tLoss: 0.921006\n",
      "Train Epoch: 348 [acc: 74%]\tLoss: 0.946959\n",
      "Train Epoch: 349 [acc: 69%]\tLoss: 1.016390\n",
      "Train Epoch: 350 [acc: 73%]\tLoss: 0.905421\n",
      "[Trained for 350 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.82 +- 0.43 , Avg Loss: 3.65\n",
      "Train Epoch: 351 [acc: 61%]\tLoss: 0.936131\n",
      "Train Epoch: 352 [acc: 70%]\tLoss: 0.909388\n",
      "Train Epoch: 353 [acc: 69%]\tLoss: 0.865188\n",
      "Train Epoch: 354 [acc: 71%]\tLoss: 0.885659\n",
      "Train Epoch: 355 [acc: 73%]\tLoss: 0.887168\n",
      "Train Epoch: 356 [acc: 66%]\tLoss: 0.914573\n",
      "Train Epoch: 357 [acc: 72%]\tLoss: 0.828293\n",
      "Train Epoch: 358 [acc: 70%]\tLoss: 0.844857\n",
      "Train Epoch: 359 [acc: 68%]\tLoss: 0.918736\n",
      "Train Epoch: 360 [acc: 69%]\tLoss: 0.928509\n",
      "Train Epoch: 361 [acc: 79%]\tLoss: 0.707771\n",
      "Train Epoch: 362 [acc: 65%]\tLoss: 0.832245\n",
      "Train Epoch: 363 [acc: 65%]\tLoss: 1.044661\n",
      "Train Epoch: 364 [acc: 76%]\tLoss: 0.763643\n",
      "Train Epoch: 365 [acc: 81%]\tLoss: 0.742476\n",
      "Train Epoch: 366 [acc: 66%]\tLoss: 0.873980\n",
      "Train Epoch: 367 [acc: 67%]\tLoss: 1.059947\n",
      "Train Epoch: 368 [acc: 73%]\tLoss: 0.824372\n",
      "Train Epoch: 369 [acc: 69%]\tLoss: 0.957177\n",
      "Train Epoch: 370 [acc: 66%]\tLoss: 0.962079\n",
      "Train Epoch: 371 [acc: 72%]\tLoss: 0.835494\n",
      "Train Epoch: 372 [acc: 74%]\tLoss: 0.749631\n",
      "Train Epoch: 373 [acc: 73%]\tLoss: 0.784321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 374 [acc: 75%]\tLoss: 0.707633\n",
      "Train Epoch: 375 [acc: 77%]\tLoss: 0.777782\n",
      "[Trained for 375 epochs and tested on 5 sets of 2000 images]        Avg Acc: 28.88 +- 0.58 , Avg Loss: 3.39\n",
      "Train Epoch: 376 [acc: 69%]\tLoss: 0.877320\n",
      "Train Epoch: 377 [acc: 75%]\tLoss: 0.729101\n",
      "Train Epoch: 378 [acc: 75%]\tLoss: 0.773058\n",
      "Train Epoch: 379 [acc: 71%]\tLoss: 0.849803\n",
      "Train Epoch: 380 [acc: 79%]\tLoss: 0.662570\n",
      "Train Epoch: 381 [acc: 76%]\tLoss: 0.800932\n",
      "Train Epoch: 382 [acc: 77%]\tLoss: 0.716508\n",
      "Train Epoch: 383 [acc: 72%]\tLoss: 0.803547\n",
      "Train Epoch: 384 [acc: 76%]\tLoss: 0.758541\n",
      "Train Epoch: 385 [acc: 81%]\tLoss: 0.665457\n",
      "Train Epoch: 386 [acc: 82%]\tLoss: 0.667425\n",
      "Train Epoch: 387 [acc: 72%]\tLoss: 0.879336\n",
      "Train Epoch: 388 [acc: 73%]\tLoss: 0.869117\n",
      "Train Epoch: 389 [acc: 78%]\tLoss: 0.822597\n",
      "Train Epoch: 390 [acc: 76%]\tLoss: 0.775286\n",
      "Train Epoch: 391 [acc: 71%]\tLoss: 0.850131\n",
      "Train Epoch: 392 [acc: 73%]\tLoss: 0.819240\n",
      "Train Epoch: 393 [acc: 77%]\tLoss: 0.694973\n",
      "Train Epoch: 394 [acc: 62%]\tLoss: 1.194080\n",
      "Train Epoch: 395 [acc: 76%]\tLoss: 0.639433\n",
      "Train Epoch: 396 [acc: 79%]\tLoss: 0.676837\n",
      "Train Epoch: 397 [acc: 68%]\tLoss: 1.055161\n",
      "Train Epoch: 398 [acc: 73%]\tLoss: 0.771280\n",
      "Train Epoch: 399 [acc: 79%]\tLoss: 0.644552\n",
      "Train Epoch: 400 [acc: 69%]\tLoss: 0.911114\n",
      "[Trained for 400 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.92 +- 0.51 , Avg Loss: 3.23\n",
      "Train Epoch: 401 [acc: 76%]\tLoss: 0.658472\n",
      "Train Epoch: 402 [acc: 74%]\tLoss: 0.771021\n",
      "Train Epoch: 403 [acc: 72%]\tLoss: 0.721020\n",
      "Train Epoch: 404 [acc: 76%]\tLoss: 0.608213\n",
      "Train Epoch: 405 [acc: 82%]\tLoss: 0.599621\n",
      "Train Epoch: 406 [acc: 74%]\tLoss: 0.811990\n",
      "Train Epoch: 407 [acc: 74%]\tLoss: 0.763360\n",
      "Train Epoch: 408 [acc: 83%]\tLoss: 0.599792\n",
      "Train Epoch: 409 [acc: 74%]\tLoss: 0.782400\n",
      "Train Epoch: 410 [acc: 77%]\tLoss: 0.725631\n",
      "Train Epoch: 411 [acc: 73%]\tLoss: 0.915072\n",
      "Train Epoch: 412 [acc: 77%]\tLoss: 0.776076\n",
      "Train Epoch: 413 [acc: 83%]\tLoss: 0.611052\n",
      "Train Epoch: 414 [acc: 68%]\tLoss: 1.032762\n",
      "Train Epoch: 415 [acc: 79%]\tLoss: 0.703239\n",
      "Train Epoch: 416 [acc: 78%]\tLoss: 0.793363\n",
      "Train Epoch: 417 [acc: 77%]\tLoss: 0.629840\n",
      "Train Epoch: 418 [acc: 77%]\tLoss: 0.741208\n",
      "Train Epoch: 419 [acc: 79%]\tLoss: 0.667762\n",
      "Train Epoch: 420 [acc: 79%]\tLoss: 0.613809\n",
      "Train Epoch: 421 [acc: 76%]\tLoss: 0.804913\n",
      "Train Epoch: 422 [acc: 76%]\tLoss: 0.777000\n",
      "Train Epoch: 423 [acc: 73%]\tLoss: 0.867192\n",
      "Train Epoch: 424 [acc: 82%]\tLoss: 0.650289\n",
      "Train Epoch: 425 [acc: 80%]\tLoss: 0.631509\n",
      "[Trained for 425 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.57 +- 0.84 , Avg Loss: 3.16\n",
      "Train Epoch: 426 [acc: 79%]\tLoss: 0.611014\n",
      "Train Epoch: 427 [acc: 86%]\tLoss: 0.577525\n",
      "Train Epoch: 428 [acc: 83%]\tLoss: 0.513416\n",
      "Train Epoch: 429 [acc: 75%]\tLoss: 0.821873\n",
      "Train Epoch: 430 [acc: 83%]\tLoss: 0.657834\n",
      "Train Epoch: 431 [acc: 83%]\tLoss: 0.498358\n",
      "Train Epoch: 432 [acc: 78%]\tLoss: 0.690702\n",
      "Train Epoch: 433 [acc: 83%]\tLoss: 0.527007\n",
      "Train Epoch: 434 [acc: 75%]\tLoss: 0.739380\n",
      "Train Epoch: 435 [acc: 76%]\tLoss: 0.642051\n",
      "Train Epoch: 436 [acc: 70%]\tLoss: 0.821375\n",
      "Train Epoch: 437 [acc: 75%]\tLoss: 0.887100\n",
      "Train Epoch: 438 [acc: 72%]\tLoss: 0.780929\n",
      "Train Epoch: 439 [acc: 77%]\tLoss: 0.708567\n",
      "Train Epoch: 440 [acc: 84%]\tLoss: 0.686626\n",
      "Train Epoch: 441 [acc: 83%]\tLoss: 0.659252\n",
      "Train Epoch: 442 [acc: 75%]\tLoss: 0.742851\n",
      "Train Epoch: 443 [acc: 72%]\tLoss: 0.969036\n",
      "Train Epoch: 444 [acc: 73%]\tLoss: 0.763252\n",
      "Train Epoch: 445 [acc: 78%]\tLoss: 0.705832\n",
      "Train Epoch: 446 [acc: 78%]\tLoss: 0.596067\n",
      "Train Epoch: 447 [acc: 72%]\tLoss: 0.693893\n",
      "Train Epoch: 448 [acc: 71%]\tLoss: 0.835114\n",
      "Train Epoch: 449 [acc: 80%]\tLoss: 0.696307\n",
      "Train Epoch: 450 [acc: 76%]\tLoss: 0.768893\n",
      "[Trained for 450 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.14 +- 0.75 , Avg Loss: 3.64\n",
      "Train Epoch: 451 [acc: 85%]\tLoss: 0.578289\n",
      "Train Epoch: 452 [acc: 76%]\tLoss: 0.666483\n",
      "Train Epoch: 453 [acc: 71%]\tLoss: 0.810531\n",
      "Train Epoch: 454 [acc: 76%]\tLoss: 0.663971\n",
      "Train Epoch: 455 [acc: 76%]\tLoss: 0.700563\n",
      "Train Epoch: 456 [acc: 72%]\tLoss: 0.691073\n",
      "Train Epoch: 457 [acc: 73%]\tLoss: 0.861029\n",
      "Train Epoch: 458 [acc: 79%]\tLoss: 0.695290\n",
      "Train Epoch: 459 [acc: 81%]\tLoss: 0.604404\n",
      "Train Epoch: 460 [acc: 83%]\tLoss: 0.605268\n",
      "Train Epoch: 461 [acc: 84%]\tLoss: 0.565315\n",
      "Train Epoch: 462 [acc: 81%]\tLoss: 0.631758\n",
      "Train Epoch: 463 [acc: 77%]\tLoss: 0.749225\n",
      "Train Epoch: 464 [acc: 83%]\tLoss: 0.593431\n",
      "Train Epoch: 465 [acc: 84%]\tLoss: 0.653812\n",
      "Train Epoch: 466 [acc: 72%]\tLoss: 0.886296\n",
      "Train Epoch: 467 [acc: 79%]\tLoss: 0.557244\n",
      "Train Epoch: 468 [acc: 76%]\tLoss: 0.704312\n",
      "Train Epoch: 469 [acc: 79%]\tLoss: 0.761468\n",
      "Train Epoch: 470 [acc: 77%]\tLoss: 0.651327\n",
      "Train Epoch: 471 [acc: 75%]\tLoss: 0.822291\n",
      "Train Epoch: 472 [acc: 82%]\tLoss: 0.579304\n",
      "Train Epoch: 473 [acc: 84%]\tLoss: 0.510253\n",
      "Train Epoch: 474 [acc: 87%]\tLoss: 0.518403\n",
      "Train Epoch: 475 [acc: 81%]\tLoss: 0.604621\n",
      "[Trained for 475 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.27 +- 0.55 , Avg Loss: 3.70\n",
      "Train Epoch: 476 [acc: 76%]\tLoss: 0.653373\n",
      "Train Epoch: 477 [acc: 85%]\tLoss: 0.476815\n",
      "Train Epoch: 478 [acc: 82%]\tLoss: 0.541068\n",
      "Train Epoch: 479 [acc: 79%]\tLoss: 0.669094\n",
      "Train Epoch: 480 [acc: 87%]\tLoss: 0.459583\n",
      "Train Epoch: 481 [acc: 81%]\tLoss: 0.533109\n",
      "Train Epoch: 482 [acc: 82%]\tLoss: 0.526846\n",
      "Train Epoch: 483 [acc: 83%]\tLoss: 0.567289\n",
      "Train Epoch: 484 [acc: 79%]\tLoss: 0.631045\n",
      "Train Epoch: 485 [acc: 76%]\tLoss: 0.625059\n",
      "Train Epoch: 486 [acc: 73%]\tLoss: 0.758108\n",
      "Train Epoch: 487 [acc: 82%]\tLoss: 0.512493\n",
      "Train Epoch: 488 [acc: 82%]\tLoss: 0.535016\n",
      "Train Epoch: 489 [acc: 82%]\tLoss: 0.672208\n",
      "Train Epoch: 490 [acc: 78%]\tLoss: 0.722231\n",
      "Train Epoch: 491 [acc: 85%]\tLoss: 0.533864\n",
      "Train Epoch: 492 [acc: 76%]\tLoss: 0.695749\n",
      "Train Epoch: 493 [acc: 75%]\tLoss: 0.740856\n",
      "Train Epoch: 494 [acc: 74%]\tLoss: 0.718386\n",
      "Train Epoch: 495 [acc: 80%]\tLoss: 0.627582\n",
      "Train Epoch: 496 [acc: 80%]\tLoss: 0.654772\n",
      "Train Epoch: 497 [acc: 82%]\tLoss: 0.539507\n",
      "Train Epoch: 498 [acc: 82%]\tLoss: 0.551678\n",
      "Train Epoch: 499 [acc: 81%]\tLoss: 0.621777\n",
      "Train Epoch: 500 [acc: 80%]\tLoss: 0.732207\n",
      "[Trained for 500 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.62 +- 0.95 , Avg Loss: 3.86\n",
      "Train Epoch: 501 [acc: 78%]\tLoss: 0.673082\n",
      "Train Epoch: 502 [acc: 75%]\tLoss: 0.603944\n",
      "Train Epoch: 503 [acc: 81%]\tLoss: 0.630838\n",
      "Train Epoch: 504 [acc: 74%]\tLoss: 0.841018\n",
      "Train Epoch: 505 [acc: 80%]\tLoss: 0.732959\n",
      "Train Epoch: 506 [acc: 78%]\tLoss: 0.626935\n",
      "Train Epoch: 507 [acc: 88%]\tLoss: 0.476611\n",
      "Train Epoch: 508 [acc: 75%]\tLoss: 0.812705\n",
      "Train Epoch: 509 [acc: 83%]\tLoss: 0.612743\n",
      "Train Epoch: 510 [acc: 77%]\tLoss: 0.622576\n",
      "Train Epoch: 511 [acc: 78%]\tLoss: 0.761052\n",
      "Train Epoch: 512 [acc: 74%]\tLoss: 0.890966\n",
      "Train Epoch: 513 [acc: 80%]\tLoss: 0.588169\n",
      "Train Epoch: 514 [acc: 84%]\tLoss: 0.618743\n",
      "Train Epoch: 515 [acc: 79%]\tLoss: 0.682051\n",
      "Train Epoch: 516 [acc: 76%]\tLoss: 0.659043\n",
      "Train Epoch: 517 [acc: 78%]\tLoss: 0.769481\n",
      "Train Epoch: 518 [acc: 81%]\tLoss: 0.507739\n",
      "Train Epoch: 519 [acc: 77%]\tLoss: 0.632878\n",
      "Train Epoch: 520 [acc: 83%]\tLoss: 0.605850\n",
      "Train Epoch: 521 [acc: 84%]\tLoss: 0.464758\n",
      "Train Epoch: 522 [acc: 78%]\tLoss: 0.618687\n",
      "Train Epoch: 523 [acc: 85%]\tLoss: 0.460959\n",
      "Train Epoch: 524 [acc: 92%]\tLoss: 0.363498\n",
      "Train Epoch: 525 [acc: 84%]\tLoss: 0.572380\n",
      "[Trained for 525 epochs and tested on 5 sets of 2000 images]        Avg Acc: 27.91 +- 0.50 , Avg Loss: 3.82\n",
      "Train Epoch: 526 [acc: 77%]\tLoss: 0.787347\n",
      "Train Epoch: 527 [acc: 89%]\tLoss: 0.379397\n",
      "Train Epoch: 528 [acc: 83%]\tLoss: 0.558534\n",
      "Train Epoch: 529 [acc: 78%]\tLoss: 0.564743\n",
      "Train Epoch: 530 [acc: 85%]\tLoss: 0.598954\n",
      "Train Epoch: 531 [acc: 84%]\tLoss: 0.421313\n",
      "Train Epoch: 532 [acc: 81%]\tLoss: 0.556105\n",
      "Train Epoch: 533 [acc: 80%]\tLoss: 0.672342\n",
      "Train Epoch: 534 [acc: 80%]\tLoss: 0.668777\n",
      "Train Epoch: 535 [acc: 83%]\tLoss: 0.612068\n",
      "Train Epoch: 536 [acc: 83%]\tLoss: 0.577141\n",
      "Train Epoch: 537 [acc: 82%]\tLoss: 0.599091\n",
      "Train Epoch: 538 [acc: 83%]\tLoss: 0.539471\n",
      "Train Epoch: 539 [acc: 82%]\tLoss: 0.567438\n",
      "Train Epoch: 540 [acc: 82%]\tLoss: 0.586145\n",
      "Train Epoch: 541 [acc: 80%]\tLoss: 0.568399\n",
      "Train Epoch: 542 [acc: 92%]\tLoss: 0.302948\n",
      "Train Epoch: 543 [acc: 80%]\tLoss: 0.500419\n",
      "Train Epoch: 544 [acc: 85%]\tLoss: 0.420463\n",
      "Train Epoch: 545 [acc: 81%]\tLoss: 0.483250\n",
      "Train Epoch: 546 [acc: 80%]\tLoss: 0.497638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 547 [acc: 85%]\tLoss: 0.455451\n",
      "Train Epoch: 548 [acc: 85%]\tLoss: 0.457053\n",
      "Train Epoch: 549 [acc: 81%]\tLoss: 0.630164\n",
      "Train Epoch: 550 [acc: 90%]\tLoss: 0.388346\n",
      "[Trained for 550 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.48 +- 0.83 , Avg Loss: 3.49\n",
      "Train Epoch: 551 [acc: 87%]\tLoss: 0.425309\n",
      "Train Epoch: 552 [acc: 76%]\tLoss: 0.681576\n",
      "Train Epoch: 553 [acc: 84%]\tLoss: 0.437723\n",
      "Train Epoch: 554 [acc: 88%]\tLoss: 0.430569\n",
      "Train Epoch: 555 [acc: 84%]\tLoss: 0.480617\n",
      "Train Epoch: 556 [acc: 82%]\tLoss: 0.519431\n",
      "Train Epoch: 557 [acc: 85%]\tLoss: 0.490569\n",
      "Train Epoch: 558 [acc: 85%]\tLoss: 0.446392\n",
      "Train Epoch: 559 [acc: 85%]\tLoss: 0.444860\n",
      "Train Epoch: 560 [acc: 89%]\tLoss: 0.416115\n",
      "Train Epoch: 561 [acc: 87%]\tLoss: 0.497296\n",
      "Train Epoch: 562 [acc: 81%]\tLoss: 0.579522\n",
      "Train Epoch: 563 [acc: 85%]\tLoss: 0.498872\n",
      "Train Epoch: 564 [acc: 82%]\tLoss: 0.680264\n",
      "Train Epoch: 565 [acc: 87%]\tLoss: 0.451224\n",
      "Train Epoch: 566 [acc: 86%]\tLoss: 0.376970\n",
      "Train Epoch: 567 [acc: 86%]\tLoss: 0.541532\n",
      "Train Epoch: 568 [acc: 84%]\tLoss: 0.561039\n",
      "Train Epoch: 569 [acc: 88%]\tLoss: 0.406714\n",
      "Train Epoch: 570 [acc: 83%]\tLoss: 0.533949\n",
      "Train Epoch: 571 [acc: 89%]\tLoss: 0.389595\n",
      "Train Epoch: 572 [acc: 86%]\tLoss: 0.462974\n",
      "Train Epoch: 573 [acc: 81%]\tLoss: 0.596246\n",
      "Train Epoch: 574 [acc: 87%]\tLoss: 0.438333\n",
      "Train Epoch: 575 [acc: 85%]\tLoss: 0.467017\n",
      "[Trained for 575 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.77 +- 0.71 , Avg Loss: 3.54\n",
      "Train Epoch: 576 [acc: 86%]\tLoss: 0.444929\n",
      "Train Epoch: 577 [acc: 79%]\tLoss: 0.575822\n",
      "Train Epoch: 578 [acc: 87%]\tLoss: 0.497393\n",
      "Train Epoch: 579 [acc: 86%]\tLoss: 0.477487\n",
      "Train Epoch: 580 [acc: 88%]\tLoss: 0.371098\n",
      "Train Epoch: 581 [acc: 81%]\tLoss: 0.569240\n",
      "Train Epoch: 582 [acc: 77%]\tLoss: 0.699287\n",
      "Train Epoch: 583 [acc: 86%]\tLoss: 0.473980\n",
      "Train Epoch: 584 [acc: 81%]\tLoss: 0.605096\n",
      "Train Epoch: 585 [acc: 81%]\tLoss: 0.621289\n",
      "Train Epoch: 586 [acc: 85%]\tLoss: 0.487503\n",
      "Train Epoch: 587 [acc: 89%]\tLoss: 0.495426\n",
      "Train Epoch: 588 [acc: 82%]\tLoss: 0.484576\n",
      "Train Epoch: 589 [acc: 77%]\tLoss: 0.649741\n",
      "Train Epoch: 590 [acc: 82%]\tLoss: 0.530956\n",
      "Train Epoch: 591 [acc: 83%]\tLoss: 0.605965\n",
      "Train Epoch: 592 [acc: 89%]\tLoss: 0.415711\n",
      "Train Epoch: 593 [acc: 83%]\tLoss: 0.525369\n",
      "Train Epoch: 594 [acc: 87%]\tLoss: 0.402978\n",
      "Train Epoch: 595 [acc: 86%]\tLoss: 0.374436\n",
      "Train Epoch: 596 [acc: 84%]\tLoss: 0.466910\n",
      "Train Epoch: 597 [acc: 79%]\tLoss: 0.594830\n",
      "Train Epoch: 598 [acc: 84%]\tLoss: 0.440866\n",
      "Train Epoch: 599 [acc: 85%]\tLoss: 0.457505\n",
      "Train Epoch: 600 [acc: 88%]\tLoss: 0.390319\n",
      "[Trained for 600 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.11 +- 0.58 , Avg Loss: 3.75\n",
      "Train Epoch: 601 [acc: 81%]\tLoss: 0.533053\n",
      "Train Epoch: 602 [acc: 84%]\tLoss: 0.412129\n",
      "Train Epoch: 603 [acc: 83%]\tLoss: 0.521701\n",
      "Train Epoch: 604 [acc: 80%]\tLoss: 0.589597\n",
      "Train Epoch: 605 [acc: 70%]\tLoss: 0.758288\n",
      "Train Epoch: 606 [acc: 88%]\tLoss: 0.465800\n",
      "Train Epoch: 607 [acc: 77%]\tLoss: 0.771108\n",
      "Train Epoch: 608 [acc: 82%]\tLoss: 0.481774\n",
      "Train Epoch: 609 [acc: 83%]\tLoss: 0.560932\n",
      "Train Epoch: 610 [acc: 81%]\tLoss: 0.567806\n",
      "Train Epoch: 611 [acc: 85%]\tLoss: 0.415173\n",
      "Train Epoch: 612 [acc: 90%]\tLoss: 0.333884\n",
      "Train Epoch: 613 [acc: 83%]\tLoss: 0.472333\n",
      "Train Epoch: 614 [acc: 88%]\tLoss: 0.395064\n",
      "Train Epoch: 615 [acc: 91%]\tLoss: 0.334186\n",
      "Train Epoch: 616 [acc: 87%]\tLoss: 0.406668\n",
      "Train Epoch: 617 [acc: 83%]\tLoss: 0.525740\n",
      "Train Epoch: 618 [acc: 83%]\tLoss: 0.566070\n",
      "Train Epoch: 619 [acc: 88%]\tLoss: 0.409337\n",
      "Train Epoch: 620 [acc: 90%]\tLoss: 0.380416\n",
      "Train Epoch: 621 [acc: 81%]\tLoss: 0.568734\n",
      "Train Epoch: 622 [acc: 85%]\tLoss: 0.436407\n",
      "Train Epoch: 623 [acc: 84%]\tLoss: 0.507143\n",
      "Train Epoch: 624 [acc: 86%]\tLoss: 0.546929\n",
      "Train Epoch: 625 [acc: 84%]\tLoss: 0.449956\n",
      "[Trained for 625 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.43 +- 0.59 , Avg Loss: 3.63\n",
      "Train Epoch: 626 [acc: 85%]\tLoss: 0.488174\n",
      "Train Epoch: 627 [acc: 77%]\tLoss: 0.663485\n",
      "Train Epoch: 628 [acc: 82%]\tLoss: 0.598035\n",
      "Train Epoch: 629 [acc: 91%]\tLoss: 0.341599\n",
      "Train Epoch: 630 [acc: 87%]\tLoss: 0.433270\n",
      "Train Epoch: 631 [acc: 84%]\tLoss: 0.447345\n",
      "Train Epoch: 632 [acc: 80%]\tLoss: 0.684228\n",
      "Train Epoch: 633 [acc: 81%]\tLoss: 0.525079\n",
      "Train Epoch: 634 [acc: 86%]\tLoss: 0.403227\n",
      "Train Epoch: 635 [acc: 85%]\tLoss: 0.387020\n",
      "Train Epoch: 636 [acc: 89%]\tLoss: 0.377076\n",
      "Train Epoch: 637 [acc: 77%]\tLoss: 0.602448\n",
      "Train Epoch: 638 [acc: 85%]\tLoss: 0.408940\n",
      "Train Epoch: 639 [acc: 84%]\tLoss: 0.528743\n",
      "Train Epoch: 640 [acc: 81%]\tLoss: 0.490106\n",
      "Train Epoch: 641 [acc: 81%]\tLoss: 0.548521\n",
      "Train Epoch: 642 [acc: 86%]\tLoss: 0.426813\n",
      "Train Epoch: 643 [acc: 91%]\tLoss: 0.332878\n",
      "Train Epoch: 644 [acc: 81%]\tLoss: 0.538482\n",
      "Train Epoch: 645 [acc: 89%]\tLoss: 0.369081\n",
      "Train Epoch: 646 [acc: 81%]\tLoss: 0.644817\n",
      "Train Epoch: 647 [acc: 87%]\tLoss: 0.424178\n",
      "Train Epoch: 648 [acc: 84%]\tLoss: 0.544434\n",
      "Train Epoch: 649 [acc: 89%]\tLoss: 0.292669\n",
      "Train Epoch: 650 [acc: 88%]\tLoss: 0.446313\n",
      "[Trained for 650 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.60 +- 0.88 , Avg Loss: 4.06\n",
      "Train Epoch: 651 [acc: 80%]\tLoss: 0.756114\n",
      "Train Epoch: 652 [acc: 86%]\tLoss: 0.522289\n",
      "Train Epoch: 653 [acc: 92%]\tLoss: 0.290319\n",
      "Train Epoch: 654 [acc: 89%]\tLoss: 0.375298\n",
      "Train Epoch: 655 [acc: 87%]\tLoss: 0.537773\n",
      "Train Epoch: 656 [acc: 88%]\tLoss: 0.375652\n",
      "Train Epoch: 657 [acc: 82%]\tLoss: 0.546171\n",
      "Train Epoch: 658 [acc: 88%]\tLoss: 0.385258\n",
      "Train Epoch: 659 [acc: 87%]\tLoss: 0.394425\n",
      "Train Epoch: 660 [acc: 89%]\tLoss: 0.377118\n",
      "Train Epoch: 661 [acc: 79%]\tLoss: 0.618368\n",
      "Train Epoch: 662 [acc: 91%]\tLoss: 0.364895\n",
      "Train Epoch: 663 [acc: 87%]\tLoss: 0.497043\n",
      "Train Epoch: 664 [acc: 88%]\tLoss: 0.439978\n",
      "Train Epoch: 665 [acc: 87%]\tLoss: 0.390883\n",
      "Train Epoch: 666 [acc: 84%]\tLoss: 0.491041\n",
      "Train Epoch: 667 [acc: 82%]\tLoss: 0.503226\n",
      "Train Epoch: 668 [acc: 89%]\tLoss: 0.463364\n",
      "Train Epoch: 669 [acc: 90%]\tLoss: 0.312927\n",
      "Train Epoch: 670 [acc: 83%]\tLoss: 0.536893\n",
      "Train Epoch: 671 [acc: 79%]\tLoss: 0.656776\n",
      "Train Epoch: 672 [acc: 87%]\tLoss: 0.516728\n",
      "Train Epoch: 673 [acc: 93%]\tLoss: 0.305854\n",
      "Train Epoch: 674 [acc: 86%]\tLoss: 0.531304\n",
      "Train Epoch: 675 [acc: 88%]\tLoss: 0.382705\n",
      "[Trained for 675 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.63 +- 1.04 , Avg Loss: 3.65\n",
      "Train Epoch: 676 [acc: 90%]\tLoss: 0.328364\n",
      "Train Epoch: 677 [acc: 84%]\tLoss: 0.505404\n",
      "Train Epoch: 678 [acc: 86%]\tLoss: 0.462349\n",
      "Train Epoch: 679 [acc: 87%]\tLoss: 0.391819\n",
      "Train Epoch: 680 [acc: 91%]\tLoss: 0.305762\n",
      "Train Epoch: 681 [acc: 88%]\tLoss: 0.465655\n",
      "Train Epoch: 682 [acc: 77%]\tLoss: 0.740958\n",
      "Train Epoch: 683 [acc: 86%]\tLoss: 0.423971\n",
      "Train Epoch: 684 [acc: 84%]\tLoss: 0.485274\n",
      "Train Epoch: 685 [acc: 84%]\tLoss: 0.417396\n",
      "Train Epoch: 686 [acc: 88%]\tLoss: 0.313513\n",
      "Train Epoch: 687 [acc: 90%]\tLoss: 0.322433\n",
      "Train Epoch: 688 [acc: 89%]\tLoss: 0.345133\n",
      "Train Epoch: 689 [acc: 86%]\tLoss: 0.428004\n",
      "Train Epoch: 690 [acc: 87%]\tLoss: 0.429153\n",
      "Train Epoch: 691 [acc: 90%]\tLoss: 0.320951\n",
      "Train Epoch: 692 [acc: 84%]\tLoss: 0.604454\n",
      "Train Epoch: 693 [acc: 85%]\tLoss: 0.381851\n",
      "Train Epoch: 694 [acc: 84%]\tLoss: 0.464623\n",
      "Train Epoch: 695 [acc: 84%]\tLoss: 0.408167\n",
      "Train Epoch: 696 [acc: 89%]\tLoss: 0.307273\n",
      "Train Epoch: 697 [acc: 88%]\tLoss: 0.313779\n",
      "Train Epoch: 698 [acc: 81%]\tLoss: 0.463992\n",
      "Train Epoch: 699 [acc: 79%]\tLoss: 0.707063\n",
      "Train Epoch: 700 [acc: 83%]\tLoss: 0.487917\n",
      "[Trained for 700 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.75 +- 0.68 , Avg Loss: 4.47\n",
      "Train Epoch: 701 [acc: 86%]\tLoss: 0.404661\n",
      "Train Epoch: 702 [acc: 94%]\tLoss: 0.238993\n",
      "Train Epoch: 703 [acc: 83%]\tLoss: 0.471204\n",
      "Train Epoch: 704 [acc: 87%]\tLoss: 0.405570\n",
      "Train Epoch: 705 [acc: 82%]\tLoss: 0.581373\n",
      "Train Epoch: 706 [acc: 86%]\tLoss: 0.386010\n",
      "Train Epoch: 707 [acc: 91%]\tLoss: 0.252848\n",
      "Train Epoch: 708 [acc: 86%]\tLoss: 0.435578\n",
      "Train Epoch: 709 [acc: 83%]\tLoss: 0.433726\n",
      "Train Epoch: 710 [acc: 87%]\tLoss: 0.433152\n",
      "Train Epoch: 711 [acc: 91%]\tLoss: 0.323771\n",
      "Train Epoch: 712 [acc: 87%]\tLoss: 0.366121\n",
      "Train Epoch: 713 [acc: 87%]\tLoss: 0.478154\n",
      "Train Epoch: 714 [acc: 84%]\tLoss: 0.562191\n",
      "Train Epoch: 715 [acc: 85%]\tLoss: 0.595798\n",
      "Train Epoch: 716 [acc: 85%]\tLoss: 0.492182\n",
      "Train Epoch: 717 [acc: 94%]\tLoss: 0.336681\n",
      "Train Epoch: 718 [acc: 88%]\tLoss: 0.413899\n",
      "Train Epoch: 719 [acc: 91%]\tLoss: 0.313589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 720 [acc: 86%]\tLoss: 0.434215\n",
      "Train Epoch: 721 [acc: 90%]\tLoss: 0.344665\n",
      "Train Epoch: 722 [acc: 83%]\tLoss: 0.465253\n",
      "Train Epoch: 723 [acc: 92%]\tLoss: 0.263638\n",
      "Train Epoch: 724 [acc: 89%]\tLoss: 0.382008\n",
      "Train Epoch: 725 [acc: 86%]\tLoss: 0.465212\n",
      "[Trained for 725 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.25 +- 0.94 , Avg Loss: 3.99\n",
      "Train Epoch: 726 [acc: 86%]\tLoss: 0.444160\n",
      "Train Epoch: 727 [acc: 91%]\tLoss: 0.248023\n",
      "Train Epoch: 728 [acc: 93%]\tLoss: 0.221045\n",
      "Train Epoch: 729 [acc: 88%]\tLoss: 0.353692\n",
      "Train Epoch: 730 [acc: 87%]\tLoss: 0.403658\n",
      "Train Epoch: 731 [acc: 83%]\tLoss: 0.528544\n",
      "Train Epoch: 732 [acc: 89%]\tLoss: 0.394739\n",
      "Train Epoch: 733 [acc: 88%]\tLoss: 0.380801\n",
      "Train Epoch: 734 [acc: 90%]\tLoss: 0.327715\n",
      "Train Epoch: 735 [acc: 89%]\tLoss: 0.349909\n",
      "Train Epoch: 736 [acc: 89%]\tLoss: 0.308402\n",
      "Train Epoch: 737 [acc: 87%]\tLoss: 0.369115\n",
      "Train Epoch: 738 [acc: 88%]\tLoss: 0.395132\n",
      "Train Epoch: 739 [acc: 95%]\tLoss: 0.214806\n",
      "Train Epoch: 740 [acc: 89%]\tLoss: 0.444187\n",
      "Train Epoch: 741 [acc: 87%]\tLoss: 0.341124\n",
      "Train Epoch: 742 [acc: 87%]\tLoss: 0.546246\n",
      "Train Epoch: 743 [acc: 88%]\tLoss: 0.424293\n",
      "Train Epoch: 744 [acc: 89%]\tLoss: 0.329559\n",
      "Train Epoch: 745 [acc: 87%]\tLoss: 0.338128\n",
      "Train Epoch: 746 [acc: 89%]\tLoss: 0.320442\n",
      "Train Epoch: 747 [acc: 88%]\tLoss: 0.395313\n",
      "Train Epoch: 748 [acc: 90%]\tLoss: 0.266902\n",
      "Train Epoch: 749 [acc: 90%]\tLoss: 0.317519\n",
      "Train Epoch: 750 [acc: 84%]\tLoss: 0.544832\n",
      "[Trained for 750 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.75 +- 0.69 , Avg Loss: 3.92\n",
      "Train Epoch: 751 [acc: 93%]\tLoss: 0.181406\n",
      "Train Epoch: 752 [acc: 91%]\tLoss: 0.259446\n",
      "Train Epoch: 753 [acc: 89%]\tLoss: 0.321301\n",
      "Train Epoch: 754 [acc: 88%]\tLoss: 0.313855\n",
      "Train Epoch: 755 [acc: 91%]\tLoss: 0.370385\n",
      "Train Epoch: 756 [acc: 86%]\tLoss: 0.478583\n",
      "Train Epoch: 757 [acc: 91%]\tLoss: 0.276586\n",
      "Train Epoch: 758 [acc: 91%]\tLoss: 0.335896\n",
      "Train Epoch: 759 [acc: 82%]\tLoss: 0.484719\n",
      "Train Epoch: 760 [acc: 90%]\tLoss: 0.291537\n",
      "Train Epoch: 761 [acc: 91%]\tLoss: 0.259921\n",
      "Train Epoch: 762 [acc: 92%]\tLoss: 0.298555\n",
      "Train Epoch: 763 [acc: 83%]\tLoss: 0.517680\n",
      "Train Epoch: 764 [acc: 92%]\tLoss: 0.243069\n",
      "Train Epoch: 765 [acc: 92%]\tLoss: 0.258357\n",
      "Train Epoch: 766 [acc: 90%]\tLoss: 0.373874\n",
      "Train Epoch: 767 [acc: 82%]\tLoss: 0.539452\n",
      "Train Epoch: 768 [acc: 88%]\tLoss: 0.381654\n",
      "Train Epoch: 769 [acc: 87%]\tLoss: 0.385470\n",
      "Train Epoch: 770 [acc: 90%]\tLoss: 0.352201\n",
      "Train Epoch: 771 [acc: 93%]\tLoss: 0.256443\n",
      "Train Epoch: 772 [acc: 88%]\tLoss: 0.399360\n",
      "Train Epoch: 773 [acc: 92%]\tLoss: 0.315345\n",
      "Train Epoch: 774 [acc: 82%]\tLoss: 0.407031\n",
      "Train Epoch: 775 [acc: 92%]\tLoss: 0.358168\n",
      "[Trained for 775 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.57 +- 0.79 , Avg Loss: 3.47\n",
      "Train Epoch: 776 [acc: 91%]\tLoss: 0.254639\n",
      "Train Epoch: 777 [acc: 91%]\tLoss: 0.318058\n",
      "Train Epoch: 778 [acc: 92%]\tLoss: 0.320718\n",
      "Train Epoch: 779 [acc: 87%]\tLoss: 0.339304\n",
      "Train Epoch: 780 [acc: 94%]\tLoss: 0.206938\n",
      "Train Epoch: 781 [acc: 88%]\tLoss: 0.308068\n",
      "Train Epoch: 782 [acc: 94%]\tLoss: 0.225555\n",
      "Train Epoch: 783 [acc: 91%]\tLoss: 0.302145\n",
      "Train Epoch: 784 [acc: 86%]\tLoss: 0.357414\n",
      "Train Epoch: 785 [acc: 87%]\tLoss: 0.484406\n",
      "Train Epoch: 786 [acc: 89%]\tLoss: 0.363518\n",
      "Train Epoch: 787 [acc: 88%]\tLoss: 0.332595\n",
      "Train Epoch: 788 [acc: 88%]\tLoss: 0.392968\n",
      "Train Epoch: 789 [acc: 89%]\tLoss: 0.306695\n",
      "Train Epoch: 790 [acc: 86%]\tLoss: 0.441320\n",
      "Train Epoch: 791 [acc: 88%]\tLoss: 0.354848\n",
      "Train Epoch: 792 [acc: 89%]\tLoss: 0.286716\n",
      "Train Epoch: 793 [acc: 89%]\tLoss: 0.351189\n",
      "Train Epoch: 794 [acc: 94%]\tLoss: 0.206590\n",
      "Train Epoch: 795 [acc: 85%]\tLoss: 0.438842\n",
      "Train Epoch: 796 [acc: 86%]\tLoss: 0.452317\n",
      "Train Epoch: 797 [acc: 86%]\tLoss: 0.492597\n",
      "Train Epoch: 798 [acc: 90%]\tLoss: 0.361236\n",
      "Train Epoch: 799 [acc: 90%]\tLoss: 0.347918\n",
      "Train Epoch: 800 [acc: 85%]\tLoss: 0.446058\n",
      "[Trained for 800 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.85 +- 0.32 , Avg Loss: 4.05\n",
      "Train Epoch: 801 [acc: 85%]\tLoss: 0.455454\n",
      "Train Epoch: 802 [acc: 92%]\tLoss: 0.265478\n",
      "Train Epoch: 803 [acc: 83%]\tLoss: 0.502684\n",
      "Train Epoch: 804 [acc: 89%]\tLoss: 0.365061\n",
      "Train Epoch: 805 [acc: 90%]\tLoss: 0.256348\n",
      "Train Epoch: 806 [acc: 89%]\tLoss: 0.328835\n",
      "Train Epoch: 807 [acc: 87%]\tLoss: 0.359522\n",
      "Train Epoch: 808 [acc: 88%]\tLoss: 0.357433\n",
      "Train Epoch: 809 [acc: 88%]\tLoss: 0.315592\n",
      "Train Epoch: 810 [acc: 82%]\tLoss: 0.449163\n",
      "Train Epoch: 811 [acc: 81%]\tLoss: 0.492410\n",
      "Train Epoch: 812 [acc: 90%]\tLoss: 0.453717\n",
      "Train Epoch: 813 [acc: 89%]\tLoss: 0.381294\n",
      "Train Epoch: 814 [acc: 90%]\tLoss: 0.299288\n",
      "Train Epoch: 815 [acc: 90%]\tLoss: 0.413770\n",
      "Train Epoch: 816 [acc: 90%]\tLoss: 0.331762\n",
      "Train Epoch: 817 [acc: 83%]\tLoss: 0.378488\n",
      "Train Epoch: 818 [acc: 94%]\tLoss: 0.236427\n",
      "Train Epoch: 819 [acc: 87%]\tLoss: 0.343539\n",
      "Train Epoch: 820 [acc: 89%]\tLoss: 0.331647\n",
      "Train Epoch: 821 [acc: 91%]\tLoss: 0.329397\n",
      "Train Epoch: 822 [acc: 95%]\tLoss: 0.190692\n",
      "Train Epoch: 823 [acc: 93%]\tLoss: 0.249629\n",
      "Train Epoch: 824 [acc: 90%]\tLoss: 0.344123\n",
      "Train Epoch: 825 [acc: 90%]\tLoss: 0.264217\n",
      "[Trained for 825 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.61 +- 0.60 , Avg Loss: 3.86\n",
      "Train Epoch: 826 [acc: 88%]\tLoss: 0.384107\n",
      "Train Epoch: 827 [acc: 85%]\tLoss: 0.484299\n",
      "Train Epoch: 828 [acc: 91%]\tLoss: 0.272765\n",
      "Train Epoch: 829 [acc: 90%]\tLoss: 0.278654\n",
      "Train Epoch: 830 [acc: 92%]\tLoss: 0.241482\n",
      "Train Epoch: 831 [acc: 86%]\tLoss: 0.402477\n",
      "Train Epoch: 832 [acc: 93%]\tLoss: 0.269351\n",
      "Train Epoch: 833 [acc: 85%]\tLoss: 0.475214\n",
      "Train Epoch: 834 [acc: 83%]\tLoss: 0.474338\n",
      "Train Epoch: 835 [acc: 82%]\tLoss: 0.479381\n",
      "Train Epoch: 836 [acc: 83%]\tLoss: 0.548623\n",
      "Train Epoch: 837 [acc: 83%]\tLoss: 0.449033\n",
      "Train Epoch: 838 [acc: 91%]\tLoss: 0.359114\n",
      "Train Epoch: 839 [acc: 93%]\tLoss: 0.214318\n",
      "Train Epoch: 840 [acc: 83%]\tLoss: 0.496288\n",
      "Train Epoch: 841 [acc: 91%]\tLoss: 0.247599\n",
      "Train Epoch: 842 [acc: 94%]\tLoss: 0.254737\n",
      "Train Epoch: 843 [acc: 88%]\tLoss: 0.372293\n",
      "Train Epoch: 844 [acc: 87%]\tLoss: 0.389832\n",
      "Train Epoch: 845 [acc: 90%]\tLoss: 0.335859\n",
      "Train Epoch: 846 [acc: 84%]\tLoss: 0.469100\n",
      "Train Epoch: 847 [acc: 87%]\tLoss: 0.403006\n",
      "Train Epoch: 848 [acc: 95%]\tLoss: 0.160602\n",
      "Train Epoch: 849 [acc: 86%]\tLoss: 0.388100\n",
      "Train Epoch: 850 [acc: 88%]\tLoss: 0.374174\n",
      "[Trained for 850 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.40 +- 0.76 , Avg Loss: 4.18\n",
      "Train Epoch: 851 [acc: 90%]\tLoss: 0.353144\n",
      "Train Epoch: 852 [acc: 88%]\tLoss: 0.407489\n",
      "Train Epoch: 853 [acc: 91%]\tLoss: 0.326777\n",
      "Train Epoch: 854 [acc: 91%]\tLoss: 0.297836\n",
      "Train Epoch: 855 [acc: 83%]\tLoss: 0.604788\n",
      "Train Epoch: 856 [acc: 86%]\tLoss: 0.330359\n",
      "Train Epoch: 857 [acc: 88%]\tLoss: 0.344683\n",
      "Train Epoch: 858 [acc: 89%]\tLoss: 0.407333\n",
      "Train Epoch: 859 [acc: 88%]\tLoss: 0.338140\n",
      "Train Epoch: 860 [acc: 90%]\tLoss: 0.308704\n",
      "Train Epoch: 861 [acc: 89%]\tLoss: 0.355421\n",
      "Train Epoch: 862 [acc: 93%]\tLoss: 0.278438\n",
      "Train Epoch: 863 [acc: 87%]\tLoss: 0.429761\n",
      "Train Epoch: 864 [acc: 88%]\tLoss: 0.419387\n",
      "Train Epoch: 865 [acc: 94%]\tLoss: 0.223596\n",
      "Train Epoch: 866 [acc: 88%]\tLoss: 0.385804\n",
      "Train Epoch: 867 [acc: 91%]\tLoss: 0.305406\n",
      "Train Epoch: 868 [acc: 86%]\tLoss: 0.389605\n",
      "Train Epoch: 869 [acc: 91%]\tLoss: 0.279441\n",
      "Train Epoch: 870 [acc: 91%]\tLoss: 0.362584\n",
      "Train Epoch: 871 [acc: 89%]\tLoss: 0.334901\n",
      "Train Epoch: 872 [acc: 89%]\tLoss: 0.314527\n",
      "Train Epoch: 873 [acc: 92%]\tLoss: 0.210420\n",
      "Train Epoch: 874 [acc: 92%]\tLoss: 0.237739\n",
      "Train Epoch: 875 [acc: 94%]\tLoss: 0.222594\n",
      "[Trained for 875 epochs and tested on 5 sets of 2000 images]        Avg Acc: 34.76 +- 0.55 , Avg Loss: 3.68\n",
      "Train Epoch: 876 [acc: 87%]\tLoss: 0.365373\n",
      "Train Epoch: 877 [acc: 85%]\tLoss: 0.467915\n",
      "Train Epoch: 878 [acc: 92%]\tLoss: 0.199913\n",
      "Train Epoch: 879 [acc: 91%]\tLoss: 0.279558\n",
      "Train Epoch: 880 [acc: 91%]\tLoss: 0.308906\n",
      "Train Epoch: 881 [acc: 83%]\tLoss: 0.530792\n",
      "Train Epoch: 882 [acc: 89%]\tLoss: 0.312851\n",
      "Train Epoch: 883 [acc: 97%]\tLoss: 0.156751\n",
      "Train Epoch: 884 [acc: 96%]\tLoss: 0.179611\n",
      "Train Epoch: 885 [acc: 87%]\tLoss: 0.368910\n",
      "Train Epoch: 886 [acc: 94%]\tLoss: 0.256237\n",
      "Train Epoch: 887 [acc: 89%]\tLoss: 0.423241\n",
      "Train Epoch: 888 [acc: 87%]\tLoss: 0.429540\n",
      "Train Epoch: 889 [acc: 90%]\tLoss: 0.249066\n",
      "Train Epoch: 890 [acc: 92%]\tLoss: 0.293532\n",
      "Train Epoch: 891 [acc: 91%]\tLoss: 0.309874\n",
      "Train Epoch: 892 [acc: 91%]\tLoss: 0.270443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 893 [acc: 89%]\tLoss: 0.305837\n",
      "Train Epoch: 894 [acc: 94%]\tLoss: 0.242398\n",
      "Train Epoch: 895 [acc: 85%]\tLoss: 0.410225\n",
      "Train Epoch: 896 [acc: 87%]\tLoss: 0.455984\n",
      "Train Epoch: 897 [acc: 92%]\tLoss: 0.223403\n",
      "Train Epoch: 898 [acc: 86%]\tLoss: 0.405915\n",
      "Train Epoch: 899 [acc: 89%]\tLoss: 0.337764\n",
      "Train Epoch: 900 [acc: 91%]\tLoss: 0.328697\n",
      "[Trained for 900 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.58 +- 0.56 , Avg Loss: 3.80\n",
      "Train Epoch: 901 [acc: 88%]\tLoss: 0.365829\n",
      "Train Epoch: 902 [acc: 91%]\tLoss: 0.280500\n",
      "Train Epoch: 903 [acc: 86%]\tLoss: 0.400793\n",
      "Train Epoch: 904 [acc: 91%]\tLoss: 0.299073\n",
      "Train Epoch: 905 [acc: 85%]\tLoss: 0.388184\n",
      "Train Epoch: 906 [acc: 91%]\tLoss: 0.259754\n",
      "Train Epoch: 907 [acc: 88%]\tLoss: 0.294186\n",
      "Train Epoch: 908 [acc: 91%]\tLoss: 0.326948\n",
      "Train Epoch: 909 [acc: 86%]\tLoss: 0.426873\n",
      "Train Epoch: 910 [acc: 90%]\tLoss: 0.351987\n",
      "Train Epoch: 911 [acc: 84%]\tLoss: 0.432686\n",
      "Train Epoch: 912 [acc: 89%]\tLoss: 0.411080\n",
      "Train Epoch: 913 [acc: 91%]\tLoss: 0.263952\n",
      "Train Epoch: 914 [acc: 93%]\tLoss: 0.341538\n",
      "Train Epoch: 915 [acc: 88%]\tLoss: 0.373362\n",
      "Train Epoch: 916 [acc: 88%]\tLoss: 0.278560\n",
      "Train Epoch: 917 [acc: 88%]\tLoss: 0.357961\n",
      "Train Epoch: 918 [acc: 95%]\tLoss: 0.173356\n",
      "Train Epoch: 919 [acc: 88%]\tLoss: 0.326554\n",
      "Train Epoch: 920 [acc: 91%]\tLoss: 0.307840\n",
      "Train Epoch: 921 [acc: 88%]\tLoss: 0.384988\n",
      "Train Epoch: 922 [acc: 85%]\tLoss: 0.448527\n",
      "Train Epoch: 923 [acc: 92%]\tLoss: 0.256772\n",
      "Train Epoch: 924 [acc: 82%]\tLoss: 0.475945\n",
      "Train Epoch: 925 [acc: 92%]\tLoss: 0.276760\n",
      "[Trained for 925 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.60 +- 0.65 , Avg Loss: 4.32\n",
      "Train Epoch: 926 [acc: 90%]\tLoss: 0.303530\n",
      "Train Epoch: 927 [acc: 90%]\tLoss: 0.388248\n",
      "Train Epoch: 928 [acc: 94%]\tLoss: 0.225045\n",
      "Train Epoch: 929 [acc: 93%]\tLoss: 0.264860\n",
      "Train Epoch: 930 [acc: 92%]\tLoss: 0.260548\n",
      "Train Epoch: 931 [acc: 94%]\tLoss: 0.182960\n",
      "Train Epoch: 932 [acc: 90%]\tLoss: 0.326473\n",
      "Train Epoch: 933 [acc: 94%]\tLoss: 0.182014\n",
      "Train Epoch: 934 [acc: 92%]\tLoss: 0.232637\n",
      "Train Epoch: 935 [acc: 89%]\tLoss: 0.268888\n",
      "Train Epoch: 936 [acc: 86%]\tLoss: 0.415008\n",
      "Train Epoch: 937 [acc: 88%]\tLoss: 0.370945\n",
      "Train Epoch: 938 [acc: 89%]\tLoss: 0.280690\n",
      "Train Epoch: 939 [acc: 88%]\tLoss: 0.402464\n",
      "Train Epoch: 940 [acc: 90%]\tLoss: 0.327673\n",
      "Train Epoch: 941 [acc: 91%]\tLoss: 0.213197\n",
      "Train Epoch: 942 [acc: 90%]\tLoss: 0.307004\n",
      "Train Epoch: 943 [acc: 97%]\tLoss: 0.175422\n",
      "Train Epoch: 944 [acc: 91%]\tLoss: 0.317749\n",
      "Train Epoch: 945 [acc: 90%]\tLoss: 0.315026\n",
      "Train Epoch: 946 [acc: 91%]\tLoss: 0.336134\n",
      "Train Epoch: 947 [acc: 93%]\tLoss: 0.235798\n",
      "Train Epoch: 948 [acc: 87%]\tLoss: 0.414518\n",
      "Train Epoch: 949 [acc: 95%]\tLoss: 0.151810\n",
      "Train Epoch: 950 [acc: 90%]\tLoss: 0.363411\n",
      "[Trained for 950 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.27 +- 0.41 , Avg Loss: 4.40\n",
      "Train Epoch: 951 [acc: 86%]\tLoss: 0.366852\n",
      "Train Epoch: 952 [acc: 91%]\tLoss: 0.263614\n",
      "Train Epoch: 953 [acc: 90%]\tLoss: 0.293417\n",
      "Train Epoch: 954 [acc: 92%]\tLoss: 0.454738\n",
      "Train Epoch: 955 [acc: 95%]\tLoss: 0.252948\n",
      "Train Epoch: 956 [acc: 93%]\tLoss: 0.193215\n",
      "Train Epoch: 957 [acc: 94%]\tLoss: 0.220245\n",
      "Train Epoch: 958 [acc: 92%]\tLoss: 0.299823\n",
      "Train Epoch: 959 [acc: 92%]\tLoss: 0.273704\n",
      "Train Epoch: 960 [acc: 86%]\tLoss: 0.416848\n",
      "Train Epoch: 961 [acc: 93%]\tLoss: 0.271968\n",
      "Train Epoch: 962 [acc: 85%]\tLoss: 0.418622\n",
      "Train Epoch: 963 [acc: 86%]\tLoss: 0.355933\n",
      "Train Epoch: 964 [acc: 87%]\tLoss: 0.312028\n",
      "Train Epoch: 965 [acc: 93%]\tLoss: 0.226831\n",
      "Train Epoch: 966 [acc: 92%]\tLoss: 0.200005\n",
      "Train Epoch: 967 [acc: 95%]\tLoss: 0.189055\n",
      "Train Epoch: 968 [acc: 93%]\tLoss: 0.320909\n",
      "Train Epoch: 969 [acc: 90%]\tLoss: 0.315428\n",
      "Train Epoch: 970 [acc: 92%]\tLoss: 0.326062\n",
      "Train Epoch: 971 [acc: 88%]\tLoss: 0.348992\n",
      "Train Epoch: 972 [acc: 91%]\tLoss: 0.315152\n",
      "Train Epoch: 973 [acc: 93%]\tLoss: 0.216060\n",
      "Train Epoch: 974 [acc: 93%]\tLoss: 0.176775\n",
      "Train Epoch: 975 [acc: 91%]\tLoss: 0.298544\n",
      "[Trained for 975 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.04 +- 0.83 , Avg Loss: 3.92\n",
      "Train Epoch: 976 [acc: 85%]\tLoss: 0.436710\n",
      "Train Epoch: 977 [acc: 88%]\tLoss: 0.553762\n",
      "Train Epoch: 978 [acc: 92%]\tLoss: 0.252580\n",
      "Train Epoch: 979 [acc: 91%]\tLoss: 0.245392\n",
      "Train Epoch: 980 [acc: 88%]\tLoss: 0.366126\n",
      "Train Epoch: 981 [acc: 92%]\tLoss: 0.270642\n",
      "Train Epoch: 982 [acc: 89%]\tLoss: 0.329885\n",
      "Train Epoch: 983 [acc: 90%]\tLoss: 0.294900\n",
      "Train Epoch: 984 [acc: 96%]\tLoss: 0.166633\n",
      "Train Epoch: 985 [acc: 88%]\tLoss: 0.484782\n",
      "Train Epoch: 986 [acc: 86%]\tLoss: 0.441311\n",
      "Train Epoch: 987 [acc: 89%]\tLoss: 0.283453\n",
      "Train Epoch: 988 [acc: 91%]\tLoss: 0.332270\n",
      "Train Epoch: 989 [acc: 94%]\tLoss: 0.265151\n",
      "Train Epoch: 990 [acc: 92%]\tLoss: 0.313209\n",
      "Train Epoch: 991 [acc: 93%]\tLoss: 0.220555\n",
      "Train Epoch: 992 [acc: 90%]\tLoss: 0.272195\n",
      "Train Epoch: 993 [acc: 91%]\tLoss: 0.246871\n",
      "Train Epoch: 994 [acc: 92%]\tLoss: 0.253612\n",
      "Train Epoch: 995 [acc: 92%]\tLoss: 0.284373\n",
      "Train Epoch: 996 [acc: 93%]\tLoss: 0.245838\n",
      "Train Epoch: 997 [acc: 90%]\tLoss: 0.272709\n",
      "Train Epoch: 998 [acc: 88%]\tLoss: 0.331640\n",
      "Train Epoch: 999 [acc: 92%]\tLoss: 0.331428\n",
      "Train Epoch: 1000 [acc: 97%]\tLoss: 0.139238\n",
      "[Trained for 1000 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.21 +- 0.39 , Avg Loss: 4.38\n",
      "Train Epoch: 1001 [acc: 91%]\tLoss: 0.312675\n",
      "Train Epoch: 1002 [acc: 87%]\tLoss: 0.401365\n",
      "Train Epoch: 1003 [acc: 92%]\tLoss: 0.272611\n",
      "Train Epoch: 1004 [acc: 88%]\tLoss: 0.308576\n",
      "Train Epoch: 1005 [acc: 91%]\tLoss: 0.314912\n",
      "Train Epoch: 1006 [acc: 90%]\tLoss: 0.275961\n",
      "Train Epoch: 1007 [acc: 89%]\tLoss: 0.250299\n",
      "Train Epoch: 1008 [acc: 88%]\tLoss: 0.376896\n",
      "Train Epoch: 1009 [acc: 94%]\tLoss: 0.195379\n",
      "Train Epoch: 1010 [acc: 94%]\tLoss: 0.203794\n",
      "Train Epoch: 1011 [acc: 93%]\tLoss: 0.205843\n",
      "Train Epoch: 1012 [acc: 93%]\tLoss: 0.212933\n",
      "Train Epoch: 1013 [acc: 88%]\tLoss: 0.344215\n",
      "Train Epoch: 1014 [acc: 94%]\tLoss: 0.270368\n",
      "Train Epoch: 1015 [acc: 96%]\tLoss: 0.170448\n",
      "Train Epoch: 1016 [acc: 92%]\tLoss: 0.254673\n",
      "Train Epoch: 1017 [acc: 94%]\tLoss: 0.217988\n",
      "Train Epoch: 1018 [acc: 90%]\tLoss: 0.331907\n",
      "Train Epoch: 1019 [acc: 92%]\tLoss: 0.289619\n",
      "Train Epoch: 1020 [acc: 90%]\tLoss: 0.322053\n",
      "Train Epoch: 1021 [acc: 92%]\tLoss: 0.288914\n",
      "Train Epoch: 1022 [acc: 89%]\tLoss: 0.275294\n",
      "Train Epoch: 1023 [acc: 93%]\tLoss: 0.153903\n",
      "Train Epoch: 1024 [acc: 90%]\tLoss: 0.251563\n",
      "Train Epoch: 1025 [acc: 93%]\tLoss: 0.325566\n",
      "[Trained for 1025 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.14 +- 0.19 , Avg Loss: 3.92\n",
      "Train Epoch: 1026 [acc: 88%]\tLoss: 0.428499\n",
      "Train Epoch: 1027 [acc: 91%]\tLoss: 0.308236\n",
      "Train Epoch: 1028 [acc: 96%]\tLoss: 0.155375\n",
      "Train Epoch: 1029 [acc: 90%]\tLoss: 0.245284\n",
      "Train Epoch: 1030 [acc: 90%]\tLoss: 0.360249\n",
      "Train Epoch: 1031 [acc: 87%]\tLoss: 0.352671\n",
      "Train Epoch: 1032 [acc: 90%]\tLoss: 0.325926\n",
      "Train Epoch: 1033 [acc: 91%]\tLoss: 0.246021\n",
      "Train Epoch: 1034 [acc: 88%]\tLoss: 0.300857\n",
      "Train Epoch: 1035 [acc: 96%]\tLoss: 0.156826\n",
      "Train Epoch: 1036 [acc: 92%]\tLoss: 0.287554\n",
      "Train Epoch: 1037 [acc: 89%]\tLoss: 0.405346\n",
      "Train Epoch: 1038 [acc: 91%]\tLoss: 0.296826\n",
      "Train Epoch: 1039 [acc: 91%]\tLoss: 0.312537\n",
      "Train Epoch: 1040 [acc: 93%]\tLoss: 0.233184\n",
      "Train Epoch: 1041 [acc: 89%]\tLoss: 0.348973\n",
      "Train Epoch: 1042 [acc: 89%]\tLoss: 0.325017\n",
      "Train Epoch: 1043 [acc: 88%]\tLoss: 0.321937\n",
      "Train Epoch: 1044 [acc: 89%]\tLoss: 0.330451\n",
      "Train Epoch: 1045 [acc: 92%]\tLoss: 0.283842\n",
      "Train Epoch: 1046 [acc: 90%]\tLoss: 0.339288\n",
      "Train Epoch: 1047 [acc: 93%]\tLoss: 0.245159\n",
      "Train Epoch: 1048 [acc: 91%]\tLoss: 0.303378\n",
      "Train Epoch: 1049 [acc: 90%]\tLoss: 0.298258\n",
      "Train Epoch: 1050 [acc: 86%]\tLoss: 0.372283\n",
      "[Trained for 1050 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.15 +- 0.35 , Avg Loss: 4.16\n",
      "Train Epoch: 1051 [acc: 88%]\tLoss: 0.360192\n",
      "Train Epoch: 1052 [acc: 87%]\tLoss: 0.375850\n",
      "Train Epoch: 1053 [acc: 90%]\tLoss: 0.306299\n",
      "Train Epoch: 1054 [acc: 83%]\tLoss: 0.515047\n",
      "Train Epoch: 1055 [acc: 90%]\tLoss: 0.289962\n",
      "Train Epoch: 1056 [acc: 91%]\tLoss: 0.278249\n",
      "Train Epoch: 1057 [acc: 94%]\tLoss: 0.179490\n",
      "Train Epoch: 1058 [acc: 87%]\tLoss: 0.321387\n",
      "Train Epoch: 1059 [acc: 87%]\tLoss: 0.473729\n",
      "Train Epoch: 1060 [acc: 89%]\tLoss: 0.292377\n",
      "Train Epoch: 1061 [acc: 90%]\tLoss: 0.313878\n",
      "Train Epoch: 1062 [acc: 89%]\tLoss: 0.284452\n",
      "Train Epoch: 1063 [acc: 96%]\tLoss: 0.138920\n",
      "Train Epoch: 1064 [acc: 93%]\tLoss: 0.247029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1065 [acc: 93%]\tLoss: 0.225480\n",
      "Train Epoch: 1066 [acc: 93%]\tLoss: 0.233333\n",
      "Train Epoch: 1067 [acc: 82%]\tLoss: 0.446198\n",
      "Train Epoch: 1068 [acc: 95%]\tLoss: 0.179901\n",
      "Train Epoch: 1069 [acc: 92%]\tLoss: 0.377622\n",
      "Train Epoch: 1070 [acc: 95%]\tLoss: 0.215319\n",
      "Train Epoch: 1071 [acc: 93%]\tLoss: 0.227502\n",
      "Train Epoch: 1072 [acc: 94%]\tLoss: 0.246355\n",
      "Train Epoch: 1073 [acc: 94%]\tLoss: 0.289882\n",
      "Train Epoch: 1074 [acc: 89%]\tLoss: 0.391351\n",
      "Train Epoch: 1075 [acc: 90%]\tLoss: 0.237601\n",
      "[Trained for 1075 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.54 +- 0.56 , Avg Loss: 3.72\n",
      "Train Epoch: 1076 [acc: 88%]\tLoss: 0.297678\n",
      "Train Epoch: 1077 [acc: 97%]\tLoss: 0.173317\n",
      "Train Epoch: 1078 [acc: 92%]\tLoss: 0.310626\n",
      "Train Epoch: 1079 [acc: 92%]\tLoss: 0.292943\n",
      "Train Epoch: 1080 [acc: 91%]\tLoss: 0.295999\n",
      "Train Epoch: 1081 [acc: 91%]\tLoss: 0.257612\n",
      "Train Epoch: 1082 [acc: 87%]\tLoss: 0.356668\n",
      "Train Epoch: 1083 [acc: 92%]\tLoss: 0.245187\n",
      "Train Epoch: 1084 [acc: 90%]\tLoss: 0.317259\n",
      "Train Epoch: 1085 [acc: 91%]\tLoss: 0.293659\n",
      "Train Epoch: 1086 [acc: 90%]\tLoss: 0.251107\n",
      "Train Epoch: 1087 [acc: 90%]\tLoss: 0.319492\n",
      "Train Epoch: 1088 [acc: 89%]\tLoss: 0.311681\n",
      "Train Epoch: 1089 [acc: 93%]\tLoss: 0.288156\n",
      "Train Epoch: 1090 [acc: 95%]\tLoss: 0.191858\n",
      "Train Epoch: 1091 [acc: 89%]\tLoss: 0.277792\n",
      "Train Epoch: 1092 [acc: 90%]\tLoss: 0.343897\n",
      "Train Epoch: 1093 [acc: 87%]\tLoss: 0.404838\n",
      "Train Epoch: 1094 [acc: 90%]\tLoss: 0.327209\n",
      "Train Epoch: 1095 [acc: 95%]\tLoss: 0.154876\n",
      "Train Epoch: 1096 [acc: 90%]\tLoss: 0.361407\n",
      "Train Epoch: 1097 [acc: 86%]\tLoss: 0.420841\n",
      "Train Epoch: 1098 [acc: 93%]\tLoss: 0.242377\n",
      "Train Epoch: 1099 [acc: 86%]\tLoss: 0.403140\n",
      "Train Epoch: 1100 [acc: 92%]\tLoss: 0.336924\n",
      "[Trained for 1100 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.50 +- 0.46 , Avg Loss: 4.34\n",
      "Train Epoch: 1101 [acc: 91%]\tLoss: 0.214820\n",
      "Train Epoch: 1102 [acc: 87%]\tLoss: 0.312648\n",
      "Train Epoch: 1103 [acc: 97%]\tLoss: 0.128967\n",
      "Train Epoch: 1104 [acc: 95%]\tLoss: 0.202120\n",
      "Train Epoch: 1105 [acc: 93%]\tLoss: 0.272016\n",
      "Train Epoch: 1106 [acc: 91%]\tLoss: 0.290302\n",
      "Train Epoch: 1107 [acc: 95%]\tLoss: 0.141513\n",
      "Train Epoch: 1108 [acc: 93%]\tLoss: 0.216402\n",
      "Train Epoch: 1109 [acc: 98%]\tLoss: 0.109469\n",
      "Train Epoch: 1110 [acc: 87%]\tLoss: 0.420861\n",
      "Train Epoch: 1111 [acc: 93%]\tLoss: 0.308682\n",
      "Train Epoch: 1112 [acc: 93%]\tLoss: 0.249566\n",
      "Train Epoch: 1113 [acc: 95%]\tLoss: 0.190311\n",
      "Train Epoch: 1114 [acc: 85%]\tLoss: 0.448315\n",
      "Train Epoch: 1115 [acc: 82%]\tLoss: 0.722507\n",
      "Train Epoch: 1116 [acc: 91%]\tLoss: 0.258130\n",
      "Train Epoch: 1117 [acc: 91%]\tLoss: 0.229805\n",
      "Train Epoch: 1118 [acc: 91%]\tLoss: 0.219025\n",
      "Train Epoch: 1119 [acc: 92%]\tLoss: 0.233993\n",
      "Train Epoch: 1120 [acc: 90%]\tLoss: 0.246809\n",
      "Train Epoch: 1121 [acc: 91%]\tLoss: 0.253892\n",
      "Train Epoch: 1122 [acc: 95%]\tLoss: 0.153503\n",
      "Train Epoch: 1123 [acc: 91%]\tLoss: 0.227022\n",
      "Train Epoch: 1124 [acc: 91%]\tLoss: 0.300111\n",
      "Train Epoch: 1125 [acc: 97%]\tLoss: 0.153166\n",
      "[Trained for 1125 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.02 +- 0.48 , Avg Loss: 4.00\n",
      "Train Epoch: 1126 [acc: 86%]\tLoss: 0.319540\n",
      "Train Epoch: 1127 [acc: 89%]\tLoss: 0.280217\n",
      "Train Epoch: 1128 [acc: 90%]\tLoss: 0.256007\n",
      "Train Epoch: 1129 [acc: 87%]\tLoss: 0.345448\n",
      "Train Epoch: 1130 [acc: 96%]\tLoss: 0.151382\n",
      "Train Epoch: 1131 [acc: 93%]\tLoss: 0.289214\n",
      "Train Epoch: 1132 [acc: 90%]\tLoss: 0.266797\n",
      "Train Epoch: 1133 [acc: 89%]\tLoss: 0.327445\n",
      "Train Epoch: 1134 [acc: 93%]\tLoss: 0.227692\n",
      "Train Epoch: 1135 [acc: 89%]\tLoss: 0.315612\n",
      "Train Epoch: 1136 [acc: 89%]\tLoss: 0.413901\n",
      "Train Epoch: 1137 [acc: 91%]\tLoss: 0.247978\n",
      "Train Epoch: 1138 [acc: 93%]\tLoss: 0.209972\n",
      "Train Epoch: 1139 [acc: 92%]\tLoss: 0.194184\n",
      "Train Epoch: 1140 [acc: 94%]\tLoss: 0.164404\n",
      "Train Epoch: 1141 [acc: 92%]\tLoss: 0.204224\n",
      "Train Epoch: 1142 [acc: 90%]\tLoss: 0.239271\n",
      "Train Epoch: 1143 [acc: 92%]\tLoss: 0.243354\n",
      "Train Epoch: 1144 [acc: 92%]\tLoss: 0.383037\n",
      "Train Epoch: 1145 [acc: 90%]\tLoss: 0.349127\n",
      "Train Epoch: 1146 [acc: 93%]\tLoss: 0.209014\n",
      "Train Epoch: 1147 [acc: 92%]\tLoss: 0.243595\n",
      "Train Epoch: 1148 [acc: 95%]\tLoss: 0.182064\n",
      "Train Epoch: 1149 [acc: 90%]\tLoss: 0.241801\n",
      "Train Epoch: 1150 [acc: 95%]\tLoss: 0.164932\n",
      "[Trained for 1150 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.14 +- 0.89 , Avg Loss: 4.24\n",
      "Train Epoch: 1151 [acc: 91%]\tLoss: 0.361221\n",
      "Train Epoch: 1152 [acc: 97%]\tLoss: 0.088515\n",
      "Train Epoch: 1153 [acc: 91%]\tLoss: 0.357161\n",
      "Train Epoch: 1154 [acc: 92%]\tLoss: 0.219538\n",
      "Train Epoch: 1155 [acc: 85%]\tLoss: 0.384324\n",
      "Train Epoch: 1156 [acc: 93%]\tLoss: 0.191889\n",
      "Train Epoch: 1157 [acc: 94%]\tLoss: 0.199955\n",
      "Train Epoch: 1158 [acc: 95%]\tLoss: 0.231144\n",
      "Train Epoch: 1159 [acc: 88%]\tLoss: 0.379178\n",
      "Train Epoch: 1160 [acc: 88%]\tLoss: 0.284028\n",
      "Train Epoch: 1161 [acc: 95%]\tLoss: 0.219875\n",
      "Train Epoch: 1162 [acc: 92%]\tLoss: 0.262925\n",
      "Train Epoch: 1163 [acc: 91%]\tLoss: 0.210727\n",
      "Train Epoch: 1164 [acc: 92%]\tLoss: 0.308952\n",
      "Train Epoch: 1165 [acc: 93%]\tLoss: 0.216141\n",
      "Train Epoch: 1166 [acc: 92%]\tLoss: 0.289979\n",
      "Train Epoch: 1167 [acc: 89%]\tLoss: 0.290951\n",
      "Train Epoch: 1168 [acc: 97%]\tLoss: 0.142041\n",
      "Train Epoch: 1169 [acc: 93%]\tLoss: 0.206355\n",
      "Train Epoch: 1170 [acc: 91%]\tLoss: 0.220738\n",
      "Train Epoch: 1171 [acc: 95%]\tLoss: 0.155562\n",
      "Train Epoch: 1172 [acc: 95%]\tLoss: 0.134745\n",
      "Train Epoch: 1173 [acc: 91%]\tLoss: 0.283910\n",
      "Train Epoch: 1174 [acc: 94%]\tLoss: 0.143881\n",
      "Train Epoch: 1175 [acc: 93%]\tLoss: 0.167588\n",
      "[Trained for 1175 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.56 +- 0.53 , Avg Loss: 4.15\n",
      "Train Epoch: 1176 [acc: 96%]\tLoss: 0.192696\n",
      "Train Epoch: 1177 [acc: 95%]\tLoss: 0.125759\n",
      "Train Epoch: 1178 [acc: 95%]\tLoss: 0.228076\n",
      "Train Epoch: 1179 [acc: 93%]\tLoss: 0.247334\n",
      "Train Epoch: 1180 [acc: 90%]\tLoss: 0.301797\n",
      "Train Epoch: 1181 [acc: 90%]\tLoss: 0.292501\n",
      "Train Epoch: 1182 [acc: 94%]\tLoss: 0.198097\n",
      "Train Epoch: 1183 [acc: 89%]\tLoss: 0.313030\n",
      "Train Epoch: 1184 [acc: 86%]\tLoss: 0.315598\n",
      "Train Epoch: 1185 [acc: 94%]\tLoss: 0.227117\n",
      "Train Epoch: 1186 [acc: 94%]\tLoss: 0.222202\n",
      "Train Epoch: 1187 [acc: 93%]\tLoss: 0.224049\n",
      "Train Epoch: 1188 [acc: 90%]\tLoss: 0.256695\n",
      "Train Epoch: 1189 [acc: 92%]\tLoss: 0.249467\n",
      "Train Epoch: 1190 [acc: 89%]\tLoss: 0.241728\n",
      "Train Epoch: 1191 [acc: 95%]\tLoss: 0.197423\n",
      "Train Epoch: 1192 [acc: 88%]\tLoss: 0.336866\n",
      "Train Epoch: 1193 [acc: 92%]\tLoss: 0.313022\n",
      "Train Epoch: 1194 [acc: 96%]\tLoss: 0.152980\n",
      "Train Epoch: 1195 [acc: 94%]\tLoss: 0.174988\n",
      "Train Epoch: 1196 [acc: 94%]\tLoss: 0.155868\n",
      "Train Epoch: 1197 [acc: 97%]\tLoss: 0.103964\n",
      "Train Epoch: 1198 [acc: 91%]\tLoss: 0.272290\n",
      "Train Epoch: 1199 [acc: 96%]\tLoss: 0.142056\n",
      "Train Epoch: 1200 [acc: 94%]\tLoss: 0.155711\n",
      "[Trained for 1200 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.98 +- 0.89 , Avg Loss: 4.61\n",
      "Train Epoch: 1201 [acc: 97%]\tLoss: 0.109016\n",
      "Train Epoch: 1202 [acc: 91%]\tLoss: 0.257978\n",
      "Train Epoch: 1203 [acc: 91%]\tLoss: 0.232624\n",
      "Train Epoch: 1204 [acc: 91%]\tLoss: 0.200083\n",
      "Train Epoch: 1205 [acc: 97%]\tLoss: 0.122769\n",
      "Train Epoch: 1206 [acc: 97%]\tLoss: 0.156228\n",
      "Train Epoch: 1207 [acc: 92%]\tLoss: 0.257477\n",
      "Train Epoch: 1208 [acc: 93%]\tLoss: 0.254204\n",
      "Train Epoch: 1209 [acc: 90%]\tLoss: 0.243406\n",
      "Train Epoch: 1210 [acc: 95%]\tLoss: 0.147366\n",
      "Train Epoch: 1211 [acc: 90%]\tLoss: 0.296886\n",
      "Train Epoch: 1212 [acc: 99%]\tLoss: 0.099042\n",
      "Train Epoch: 1213 [acc: 93%]\tLoss: 0.247811\n",
      "Train Epoch: 1214 [acc: 95%]\tLoss: 0.183934\n",
      "Train Epoch: 1215 [acc: 91%]\tLoss: 0.289807\n",
      "Train Epoch: 1216 [acc: 93%]\tLoss: 0.290195\n",
      "Train Epoch: 1217 [acc: 98%]\tLoss: 0.092574\n",
      "Train Epoch: 1218 [acc: 86%]\tLoss: 0.405448\n",
      "Train Epoch: 1219 [acc: 93%]\tLoss: 0.219406\n",
      "Train Epoch: 1220 [acc: 86%]\tLoss: 0.371752\n",
      "Train Epoch: 1221 [acc: 93%]\tLoss: 0.231058\n",
      "Train Epoch: 1222 [acc: 96%]\tLoss: 0.211873\n",
      "Train Epoch: 1223 [acc: 91%]\tLoss: 0.314895\n",
      "Train Epoch: 1224 [acc: 95%]\tLoss: 0.192997\n",
      "Train Epoch: 1225 [acc: 91%]\tLoss: 0.318022\n",
      "[Trained for 1225 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.76 +- 0.58 , Avg Loss: 5.07\n",
      "Train Epoch: 1226 [acc: 81%]\tLoss: 0.375393\n",
      "Train Epoch: 1227 [acc: 88%]\tLoss: 0.364684\n",
      "Train Epoch: 1228 [acc: 92%]\tLoss: 0.291269\n",
      "Train Epoch: 1229 [acc: 94%]\tLoss: 0.150596\n",
      "Train Epoch: 1230 [acc: 97%]\tLoss: 0.091866\n",
      "Train Epoch: 1231 [acc: 93%]\tLoss: 0.209342\n",
      "Train Epoch: 1232 [acc: 87%]\tLoss: 0.341088\n",
      "Train Epoch: 1233 [acc: 94%]\tLoss: 0.196195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1234 [acc: 90%]\tLoss: 0.302717\n",
      "Train Epoch: 1235 [acc: 93%]\tLoss: 0.175379\n",
      "Train Epoch: 1236 [acc: 89%]\tLoss: 0.335007\n",
      "Train Epoch: 1237 [acc: 94%]\tLoss: 0.208150\n",
      "Train Epoch: 1238 [acc: 86%]\tLoss: 0.472129\n",
      "Train Epoch: 1239 [acc: 93%]\tLoss: 0.247372\n",
      "Train Epoch: 1240 [acc: 91%]\tLoss: 0.211595\n",
      "Train Epoch: 1241 [acc: 86%]\tLoss: 0.348800\n",
      "Train Epoch: 1242 [acc: 91%]\tLoss: 0.190233\n",
      "Train Epoch: 1243 [acc: 94%]\tLoss: 0.198584\n",
      "Train Epoch: 1244 [acc: 88%]\tLoss: 0.359482\n",
      "Train Epoch: 1245 [acc: 93%]\tLoss: 0.210928\n",
      "Train Epoch: 1246 [acc: 88%]\tLoss: 0.297268\n",
      "Train Epoch: 1247 [acc: 93%]\tLoss: 0.238180\n",
      "Train Epoch: 1248 [acc: 92%]\tLoss: 0.289185\n",
      "Train Epoch: 1249 [acc: 87%]\tLoss: 0.391184\n",
      "Train Epoch: 1250 [acc: 90%]\tLoss: 0.256188\n",
      "[Trained for 1250 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.55 +- 1.14 , Avg Loss: 4.54\n",
      "Train Epoch: 1251 [acc: 95%]\tLoss: 0.217475\n",
      "Train Epoch: 1252 [acc: 88%]\tLoss: 0.368473\n",
      "Train Epoch: 1253 [acc: 88%]\tLoss: 0.373994\n",
      "Train Epoch: 1254 [acc: 93%]\tLoss: 0.151964\n",
      "Train Epoch: 1255 [acc: 89%]\tLoss: 0.345184\n",
      "Train Epoch: 1256 [acc: 94%]\tLoss: 0.263908\n",
      "Train Epoch: 1257 [acc: 95%]\tLoss: 0.270592\n",
      "Train Epoch: 1258 [acc: 95%]\tLoss: 0.150630\n",
      "Train Epoch: 1259 [acc: 93%]\tLoss: 0.208755\n",
      "Train Epoch: 1260 [acc: 95%]\tLoss: 0.099109\n",
      "Train Epoch: 1261 [acc: 95%]\tLoss: 0.166515\n",
      "Train Epoch: 1262 [acc: 93%]\tLoss: 0.190457\n",
      "Train Epoch: 1263 [acc: 92%]\tLoss: 0.255987\n",
      "Train Epoch: 1264 [acc: 88%]\tLoss: 0.410699\n",
      "Train Epoch: 1265 [acc: 94%]\tLoss: 0.220241\n",
      "Train Epoch: 1266 [acc: 93%]\tLoss: 0.188144\n",
      "Train Epoch: 1267 [acc: 92%]\tLoss: 0.278952\n",
      "Train Epoch: 1268 [acc: 92%]\tLoss: 0.342177\n",
      "Train Epoch: 1269 [acc: 94%]\tLoss: 0.249287\n",
      "Train Epoch: 1270 [acc: 92%]\tLoss: 0.312855\n",
      "Train Epoch: 1271 [acc: 87%]\tLoss: 0.441476\n",
      "Train Epoch: 1272 [acc: 90%]\tLoss: 0.387667\n",
      "Train Epoch: 1273 [acc: 87%]\tLoss: 0.390380\n",
      "Train Epoch: 1274 [acc: 93%]\tLoss: 0.172030\n",
      "Train Epoch: 1275 [acc: 92%]\tLoss: 0.276041\n",
      "[Trained for 1275 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.56 +- 0.95 , Avg Loss: 4.64\n",
      "Train Epoch: 1276 [acc: 91%]\tLoss: 0.238812\n",
      "Train Epoch: 1277 [acc: 94%]\tLoss: 0.284465\n",
      "Train Epoch: 1278 [acc: 91%]\tLoss: 0.210183\n",
      "Train Epoch: 1279 [acc: 90%]\tLoss: 0.344350\n",
      "Train Epoch: 1280 [acc: 92%]\tLoss: 0.194946\n",
      "Train Epoch: 1281 [acc: 95%]\tLoss: 0.191822\n",
      "Train Epoch: 1282 [acc: 93%]\tLoss: 0.288914\n",
      "Train Epoch: 1283 [acc: 90%]\tLoss: 0.296184\n",
      "Train Epoch: 1284 [acc: 94%]\tLoss: 0.165150\n",
      "Train Epoch: 1285 [acc: 90%]\tLoss: 0.300258\n",
      "Train Epoch: 1286 [acc: 94%]\tLoss: 0.227316\n",
      "Train Epoch: 1287 [acc: 95%]\tLoss: 0.194911\n",
      "Train Epoch: 1288 [acc: 99%]\tLoss: 0.073943\n",
      "Train Epoch: 1289 [acc: 84%]\tLoss: 0.472207\n",
      "Train Epoch: 1290 [acc: 93%]\tLoss: 0.212755\n",
      "Train Epoch: 1291 [acc: 91%]\tLoss: 0.376508\n",
      "Train Epoch: 1292 [acc: 87%]\tLoss: 0.387375\n",
      "Train Epoch: 1293 [acc: 90%]\tLoss: 0.271330\n",
      "Train Epoch: 1294 [acc: 94%]\tLoss: 0.336313\n",
      "Train Epoch: 1295 [acc: 90%]\tLoss: 0.373527\n",
      "Train Epoch: 1296 [acc: 89%]\tLoss: 0.333960\n",
      "Train Epoch: 1297 [acc: 89%]\tLoss: 0.295547\n",
      "Train Epoch: 1298 [acc: 97%]\tLoss: 0.135044\n",
      "Train Epoch: 1299 [acc: 97%]\tLoss: 0.148781\n",
      "Train Epoch: 1300 [acc: 90%]\tLoss: 0.309724\n",
      "[Trained for 1300 epochs and tested on 5 sets of 2000 images]        Avg Acc: 28.48 +- 0.92 , Avg Loss: 4.57\n",
      "Train Epoch: 1301 [acc: 92%]\tLoss: 0.225250\n",
      "Train Epoch: 1302 [acc: 92%]\tLoss: 0.312940\n",
      "Train Epoch: 1303 [acc: 92%]\tLoss: 0.271143\n",
      "Train Epoch: 1304 [acc: 86%]\tLoss: 0.330500\n",
      "Train Epoch: 1305 [acc: 90%]\tLoss: 0.260618\n",
      "Train Epoch: 1306 [acc: 95%]\tLoss: 0.177264\n",
      "Train Epoch: 1307 [acc: 91%]\tLoss: 0.261660\n",
      "Train Epoch: 1308 [acc: 91%]\tLoss: 0.285055\n",
      "Train Epoch: 1309 [acc: 94%]\tLoss: 0.163855\n",
      "Train Epoch: 1310 [acc: 89%]\tLoss: 0.292435\n",
      "Train Epoch: 1311 [acc: 90%]\tLoss: 0.274896\n",
      "Train Epoch: 1312 [acc: 95%]\tLoss: 0.176209\n",
      "Train Epoch: 1313 [acc: 93%]\tLoss: 0.264381\n",
      "Train Epoch: 1314 [acc: 98%]\tLoss: 0.084570\n",
      "Train Epoch: 1315 [acc: 92%]\tLoss: 0.220410\n",
      "Train Epoch: 1316 [acc: 91%]\tLoss: 0.317084\n",
      "Train Epoch: 1317 [acc: 93%]\tLoss: 0.181421\n",
      "Train Epoch: 1318 [acc: 94%]\tLoss: 0.176606\n",
      "Train Epoch: 1319 [acc: 91%]\tLoss: 0.267458\n",
      "Train Epoch: 1320 [acc: 92%]\tLoss: 0.346662\n",
      "Train Epoch: 1321 [acc: 94%]\tLoss: 0.189249\n",
      "Train Epoch: 1322 [acc: 95%]\tLoss: 0.131901\n",
      "Train Epoch: 1323 [acc: 92%]\tLoss: 0.251993\n",
      "Train Epoch: 1324 [acc: 90%]\tLoss: 0.328012\n",
      "Train Epoch: 1325 [acc: 91%]\tLoss: 0.288283\n",
      "[Trained for 1325 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.71 +- 0.63 , Avg Loss: 4.23\n",
      "Train Epoch: 1326 [acc: 87%]\tLoss: 0.329648\n",
      "Train Epoch: 1327 [acc: 92%]\tLoss: 0.226603\n",
      "Train Epoch: 1328 [acc: 92%]\tLoss: 0.307748\n",
      "Train Epoch: 1329 [acc: 92%]\tLoss: 0.260239\n",
      "Train Epoch: 1330 [acc: 91%]\tLoss: 0.264841\n",
      "Train Epoch: 1331 [acc: 89%]\tLoss: 0.323208\n",
      "Train Epoch: 1332 [acc: 92%]\tLoss: 0.297695\n",
      "Train Epoch: 1333 [acc: 85%]\tLoss: 0.433412\n",
      "Train Epoch: 1334 [acc: 91%]\tLoss: 0.253477\n",
      "Train Epoch: 1335 [acc: 93%]\tLoss: 0.197531\n",
      "Train Epoch: 1336 [acc: 87%]\tLoss: 0.330270\n",
      "Train Epoch: 1337 [acc: 91%]\tLoss: 0.280787\n",
      "Train Epoch: 1338 [acc: 92%]\tLoss: 0.220796\n",
      "Train Epoch: 1339 [acc: 87%]\tLoss: 0.316063\n",
      "Train Epoch: 1340 [acc: 90%]\tLoss: 0.259956\n",
      "Train Epoch: 1341 [acc: 89%]\tLoss: 0.314366\n",
      "Train Epoch: 1342 [acc: 95%]\tLoss: 0.183468\n",
      "Train Epoch: 1343 [acc: 93%]\tLoss: 0.226809\n",
      "Train Epoch: 1344 [acc: 90%]\tLoss: 0.339505\n",
      "Train Epoch: 1345 [acc: 91%]\tLoss: 0.225997\n",
      "Train Epoch: 1346 [acc: 91%]\tLoss: 0.311973\n",
      "Train Epoch: 1347 [acc: 88%]\tLoss: 0.364453\n",
      "Train Epoch: 1348 [acc: 96%]\tLoss: 0.195380\n",
      "Train Epoch: 1349 [acc: 92%]\tLoss: 0.252418\n",
      "Train Epoch: 1350 [acc: 91%]\tLoss: 0.255469\n",
      "[Trained for 1350 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.83 +- 0.89 , Avg Loss: 4.18\n",
      "Train Epoch: 1351 [acc: 94%]\tLoss: 0.307803\n",
      "Train Epoch: 1352 [acc: 90%]\tLoss: 0.193649\n",
      "Train Epoch: 1353 [acc: 90%]\tLoss: 0.256368\n",
      "Train Epoch: 1354 [acc: 93%]\tLoss: 0.221083\n",
      "Train Epoch: 1355 [acc: 91%]\tLoss: 0.270151\n",
      "Train Epoch: 1356 [acc: 94%]\tLoss: 0.229242\n",
      "Train Epoch: 1357 [acc: 95%]\tLoss: 0.260965\n",
      "Train Epoch: 1358 [acc: 93%]\tLoss: 0.281211\n",
      "Train Epoch: 1359 [acc: 92%]\tLoss: 0.186672\n",
      "Train Epoch: 1360 [acc: 97%]\tLoss: 0.102334\n",
      "Train Epoch: 1361 [acc: 93%]\tLoss: 0.221592\n",
      "Train Epoch: 1362 [acc: 92%]\tLoss: 0.300577\n",
      "Train Epoch: 1363 [acc: 91%]\tLoss: 0.240058\n",
      "Train Epoch: 1364 [acc: 95%]\tLoss: 0.246891\n",
      "Train Epoch: 1365 [acc: 93%]\tLoss: 0.256696\n",
      "Train Epoch: 1366 [acc: 92%]\tLoss: 0.236377\n",
      "Train Epoch: 1367 [acc: 91%]\tLoss: 0.222073\n",
      "Train Epoch: 1368 [acc: 93%]\tLoss: 0.189937\n",
      "Train Epoch: 1369 [acc: 93%]\tLoss: 0.234277\n",
      "Train Epoch: 1370 [acc: 91%]\tLoss: 0.208289\n",
      "Train Epoch: 1371 [acc: 93%]\tLoss: 0.178442\n",
      "Train Epoch: 1372 [acc: 90%]\tLoss: 0.276807\n",
      "Train Epoch: 1373 [acc: 96%]\tLoss: 0.205294\n",
      "Train Epoch: 1374 [acc: 93%]\tLoss: 0.228125\n",
      "Train Epoch: 1375 [acc: 91%]\tLoss: 0.392491\n",
      "[Trained for 1375 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.97 +- 0.76 , Avg Loss: 4.65\n",
      "Train Epoch: 1376 [acc: 96%]\tLoss: 0.100585\n",
      "Train Epoch: 1377 [acc: 92%]\tLoss: 0.291289\n",
      "Train Epoch: 1378 [acc: 90%]\tLoss: 0.283472\n",
      "Train Epoch: 1379 [acc: 91%]\tLoss: 0.238083\n",
      "Train Epoch: 1380 [acc: 89%]\tLoss: 0.329658\n",
      "Train Epoch: 1381 [acc: 93%]\tLoss: 0.297834\n",
      "Train Epoch: 1382 [acc: 89%]\tLoss: 0.217112\n",
      "Train Epoch: 1383 [acc: 93%]\tLoss: 0.246721\n",
      "Train Epoch: 1384 [acc: 92%]\tLoss: 0.269476\n",
      "Train Epoch: 1385 [acc: 93%]\tLoss: 0.208203\n",
      "Train Epoch: 1386 [acc: 94%]\tLoss: 0.188233\n",
      "Train Epoch: 1387 [acc: 93%]\tLoss: 0.266564\n",
      "Train Epoch: 1388 [acc: 92%]\tLoss: 0.256055\n",
      "Train Epoch: 1389 [acc: 91%]\tLoss: 0.263236\n",
      "Train Epoch: 1390 [acc: 88%]\tLoss: 0.351095\n",
      "Train Epoch: 1391 [acc: 96%]\tLoss: 0.149970\n",
      "Train Epoch: 1392 [acc: 93%]\tLoss: 0.289814\n",
      "Train Epoch: 1393 [acc: 94%]\tLoss: 0.201136\n",
      "Train Epoch: 1394 [acc: 91%]\tLoss: 0.223127\n",
      "Train Epoch: 1395 [acc: 92%]\tLoss: 0.233285\n",
      "Train Epoch: 1396 [acc: 94%]\tLoss: 0.228448\n",
      "Train Epoch: 1397 [acc: 100%]\tLoss: 0.061235\n",
      "Train Epoch: 1398 [acc: 94%]\tLoss: 0.176565\n",
      "Train Epoch: 1399 [acc: 94%]\tLoss: 0.226113\n",
      "Train Epoch: 1400 [acc: 94%]\tLoss: 0.154495\n",
      "[Trained for 1400 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.84 +- 0.52 , Avg Loss: 3.93\n",
      "Train Epoch: 1401 [acc: 93%]\tLoss: 0.221569\n",
      "Train Epoch: 1402 [acc: 95%]\tLoss: 0.154939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1403 [acc: 95%]\tLoss: 0.191035\n",
      "Train Epoch: 1404 [acc: 92%]\tLoss: 0.217832\n",
      "Train Epoch: 1405 [acc: 91%]\tLoss: 0.198371\n",
      "Train Epoch: 1406 [acc: 95%]\tLoss: 0.195391\n",
      "Train Epoch: 1407 [acc: 100%]\tLoss: 0.060834\n",
      "Train Epoch: 1408 [acc: 95%]\tLoss: 0.171411\n",
      "Train Epoch: 1409 [acc: 96%]\tLoss: 0.147393\n",
      "Train Epoch: 1410 [acc: 96%]\tLoss: 0.126285\n",
      "Train Epoch: 1411 [acc: 90%]\tLoss: 0.260664\n",
      "Train Epoch: 1412 [acc: 90%]\tLoss: 0.282993\n",
      "Train Epoch: 1413 [acc: 88%]\tLoss: 0.284825\n",
      "Train Epoch: 1414 [acc: 97%]\tLoss: 0.134564\n",
      "Train Epoch: 1415 [acc: 93%]\tLoss: 0.235181\n",
      "Train Epoch: 1416 [acc: 96%]\tLoss: 0.114329\n",
      "Train Epoch: 1417 [acc: 94%]\tLoss: 0.286214\n",
      "Train Epoch: 1418 [acc: 96%]\tLoss: 0.104106\n",
      "Train Epoch: 1419 [acc: 92%]\tLoss: 0.284724\n",
      "Train Epoch: 1420 [acc: 90%]\tLoss: 0.328143\n",
      "Train Epoch: 1421 [acc: 92%]\tLoss: 0.213622\n",
      "Train Epoch: 1422 [acc: 91%]\tLoss: 0.206463\n",
      "Train Epoch: 1423 [acc: 90%]\tLoss: 0.349695\n",
      "Train Epoch: 1424 [acc: 96%]\tLoss: 0.175591\n",
      "Train Epoch: 1425 [acc: 91%]\tLoss: 0.322081\n",
      "[Trained for 1425 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.51 +- 0.64 , Avg Loss: 4.13\n",
      "Train Epoch: 1426 [acc: 91%]\tLoss: 0.298611\n",
      "Train Epoch: 1427 [acc: 93%]\tLoss: 0.234770\n",
      "Train Epoch: 1428 [acc: 96%]\tLoss: 0.112823\n",
      "Train Epoch: 1429 [acc: 95%]\tLoss: 0.194788\n",
      "Train Epoch: 1430 [acc: 97%]\tLoss: 0.144153\n",
      "Train Epoch: 1431 [acc: 95%]\tLoss: 0.142694\n",
      "Train Epoch: 1432 [acc: 87%]\tLoss: 0.299709\n",
      "Train Epoch: 1433 [acc: 96%]\tLoss: 0.108223\n",
      "Train Epoch: 1434 [acc: 93%]\tLoss: 0.208585\n",
      "Train Epoch: 1435 [acc: 91%]\tLoss: 0.213428\n",
      "Train Epoch: 1436 [acc: 89%]\tLoss: 0.376236\n",
      "Train Epoch: 1437 [acc: 96%]\tLoss: 0.123412\n",
      "Train Epoch: 1438 [acc: 98%]\tLoss: 0.095657\n",
      "Train Epoch: 1439 [acc: 93%]\tLoss: 0.199761\n",
      "Train Epoch: 1440 [acc: 95%]\tLoss: 0.167792\n",
      "Train Epoch: 1441 [acc: 98%]\tLoss: 0.072329\n",
      "Train Epoch: 1442 [acc: 93%]\tLoss: 0.214444\n",
      "Train Epoch: 1443 [acc: 90%]\tLoss: 0.228328\n",
      "Train Epoch: 1444 [acc: 95%]\tLoss: 0.222215\n",
      "Train Epoch: 1445 [acc: 94%]\tLoss: 0.155450\n",
      "Train Epoch: 1446 [acc: 96%]\tLoss: 0.130351\n",
      "Train Epoch: 1447 [acc: 92%]\tLoss: 0.169782\n",
      "Train Epoch: 1448 [acc: 96%]\tLoss: 0.186114\n",
      "Train Epoch: 1449 [acc: 95%]\tLoss: 0.173619\n",
      "Train Epoch: 1450 [acc: 91%]\tLoss: 0.321125\n",
      "[Trained for 1450 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.16 +- 0.94 , Avg Loss: 4.37\n",
      "Train Epoch: 1451 [acc: 92%]\tLoss: 0.270431\n",
      "Train Epoch: 1452 [acc: 93%]\tLoss: 0.266372\n",
      "Train Epoch: 1453 [acc: 91%]\tLoss: 0.193514\n",
      "Train Epoch: 1454 [acc: 95%]\tLoss: 0.187183\n",
      "Train Epoch: 1455 [acc: 91%]\tLoss: 0.241419\n",
      "Train Epoch: 1456 [acc: 93%]\tLoss: 0.261382\n",
      "Train Epoch: 1457 [acc: 94%]\tLoss: 0.281601\n",
      "Train Epoch: 1458 [acc: 91%]\tLoss: 0.287199\n",
      "Train Epoch: 1459 [acc: 97%]\tLoss: 0.094576\n",
      "Train Epoch: 1460 [acc: 91%]\tLoss: 0.198927\n",
      "Train Epoch: 1461 [acc: 94%]\tLoss: 0.130326\n",
      "Train Epoch: 1462 [acc: 91%]\tLoss: 0.312125\n",
      "Train Epoch: 1463 [acc: 96%]\tLoss: 0.097141\n",
      "Train Epoch: 1464 [acc: 93%]\tLoss: 0.249677\n",
      "Train Epoch: 1465 [acc: 98%]\tLoss: 0.085475\n",
      "Train Epoch: 1466 [acc: 88%]\tLoss: 0.329010\n",
      "Train Epoch: 1467 [acc: 92%]\tLoss: 0.281652\n",
      "Train Epoch: 1468 [acc: 92%]\tLoss: 0.342283\n",
      "Train Epoch: 1469 [acc: 93%]\tLoss: 0.196618\n",
      "Train Epoch: 1470 [acc: 93%]\tLoss: 0.250123\n",
      "Train Epoch: 1471 [acc: 92%]\tLoss: 0.255700\n",
      "Train Epoch: 1472 [acc: 92%]\tLoss: 0.240777\n",
      "Train Epoch: 1473 [acc: 98%]\tLoss: 0.085576\n",
      "Train Epoch: 1474 [acc: 94%]\tLoss: 0.217497\n",
      "Train Epoch: 1475 [acc: 94%]\tLoss: 0.271037\n",
      "[Trained for 1475 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.84 +- 0.73 , Avg Loss: 4.16\n",
      "Train Epoch: 1476 [acc: 92%]\tLoss: 0.263112\n",
      "Train Epoch: 1477 [acc: 90%]\tLoss: 0.260581\n",
      "Train Epoch: 1478 [acc: 93%]\tLoss: 0.160607\n",
      "Train Epoch: 1479 [acc: 93%]\tLoss: 0.245170\n",
      "Train Epoch: 1480 [acc: 93%]\tLoss: 0.179219\n",
      "Train Epoch: 1481 [acc: 89%]\tLoss: 0.381199\n",
      "Train Epoch: 1482 [acc: 97%]\tLoss: 0.105978\n",
      "Train Epoch: 1483 [acc: 98%]\tLoss: 0.128587\n",
      "Train Epoch: 1484 [acc: 86%]\tLoss: 0.413951\n",
      "Train Epoch: 1485 [acc: 92%]\tLoss: 0.212083\n",
      "Train Epoch: 1486 [acc: 92%]\tLoss: 0.243900\n",
      "Train Epoch: 1487 [acc: 92%]\tLoss: 0.281256\n",
      "Train Epoch: 1488 [acc: 90%]\tLoss: 0.342703\n",
      "Train Epoch: 1489 [acc: 95%]\tLoss: 0.205715\n",
      "Train Epoch: 1490 [acc: 91%]\tLoss: 0.275815\n",
      "Train Epoch: 1491 [acc: 95%]\tLoss: 0.119710\n",
      "Train Epoch: 1492 [acc: 92%]\tLoss: 0.319565\n",
      "Train Epoch: 1493 [acc: 91%]\tLoss: 0.314965\n",
      "Train Epoch: 1494 [acc: 90%]\tLoss: 0.217489\n",
      "Train Epoch: 1495 [acc: 93%]\tLoss: 0.160187\n",
      "Train Epoch: 1496 [acc: 97%]\tLoss: 0.196551\n",
      "Train Epoch: 1497 [acc: 93%]\tLoss: 0.235835\n",
      "Train Epoch: 1498 [acc: 90%]\tLoss: 0.315063\n",
      "Train Epoch: 1499 [acc: 92%]\tLoss: 0.213338\n",
      "Train Epoch: 1500 [acc: 95%]\tLoss: 0.156735\n",
      "[Trained for 1500 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.13 +- 0.75 , Avg Loss: 4.69\n",
      "Train Epoch: 1501 [acc: 93%]\tLoss: 0.180312\n",
      "Train Epoch: 1502 [acc: 95%]\tLoss: 0.226337\n",
      "Train Epoch: 1503 [acc: 93%]\tLoss: 0.165849\n",
      "Train Epoch: 1504 [acc: 96%]\tLoss: 0.144113\n",
      "Train Epoch: 1505 [acc: 94%]\tLoss: 0.232271\n",
      "Train Epoch: 1506 [acc: 96%]\tLoss: 0.221867\n",
      "Train Epoch: 1507 [acc: 88%]\tLoss: 0.310785\n",
      "Train Epoch: 1508 [acc: 96%]\tLoss: 0.118336\n",
      "Train Epoch: 1509 [acc: 96%]\tLoss: 0.130531\n",
      "Train Epoch: 1510 [acc: 94%]\tLoss: 0.198978\n",
      "Train Epoch: 1511 [acc: 96%]\tLoss: 0.112915\n",
      "Train Epoch: 1512 [acc: 91%]\tLoss: 0.241347\n",
      "Train Epoch: 1513 [acc: 97%]\tLoss: 0.110895\n",
      "Train Epoch: 1514 [acc: 99%]\tLoss: 0.075972\n",
      "Train Epoch: 1515 [acc: 94%]\tLoss: 0.173248\n",
      "Train Epoch: 1516 [acc: 95%]\tLoss: 0.205589\n",
      "Train Epoch: 1517 [acc: 97%]\tLoss: 0.108316\n",
      "Train Epoch: 1518 [acc: 96%]\tLoss: 0.123536\n",
      "Train Epoch: 1519 [acc: 93%]\tLoss: 0.141589\n",
      "Train Epoch: 1520 [acc: 96%]\tLoss: 0.138008\n",
      "Train Epoch: 1521 [acc: 92%]\tLoss: 0.299988\n",
      "Train Epoch: 1522 [acc: 94%]\tLoss: 0.167027\n",
      "Train Epoch: 1523 [acc: 94%]\tLoss: 0.231661\n",
      "Train Epoch: 1524 [acc: 95%]\tLoss: 0.171811\n",
      "Train Epoch: 1525 [acc: 96%]\tLoss: 0.109680\n",
      "[Trained for 1525 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.02 +- 0.17 , Avg Loss: 4.75\n",
      "Train Epoch: 1526 [acc: 94%]\tLoss: 0.265724\n",
      "Train Epoch: 1527 [acc: 93%]\tLoss: 0.178129\n",
      "Train Epoch: 1528 [acc: 91%]\tLoss: 0.262759\n",
      "Train Epoch: 1529 [acc: 93%]\tLoss: 0.225336\n",
      "Train Epoch: 1530 [acc: 93%]\tLoss: 0.183309\n",
      "Train Epoch: 1531 [acc: 95%]\tLoss: 0.122990\n",
      "Train Epoch: 1532 [acc: 96%]\tLoss: 0.133993\n",
      "Train Epoch: 1533 [acc: 89%]\tLoss: 0.284010\n",
      "Train Epoch: 1534 [acc: 94%]\tLoss: 0.262429\n",
      "Train Epoch: 1535 [acc: 96%]\tLoss: 0.107776\n",
      "Train Epoch: 1536 [acc: 94%]\tLoss: 0.223929\n",
      "Train Epoch: 1537 [acc: 96%]\tLoss: 0.129364\n",
      "Train Epoch: 1538 [acc: 96%]\tLoss: 0.098410\n",
      "Train Epoch: 1539 [acc: 98%]\tLoss: 0.108838\n",
      "Train Epoch: 1540 [acc: 97%]\tLoss: 0.124371\n",
      "Train Epoch: 1541 [acc: 90%]\tLoss: 0.359595\n",
      "Train Epoch: 1542 [acc: 92%]\tLoss: 0.217989\n",
      "Train Epoch: 1543 [acc: 93%]\tLoss: 0.221739\n",
      "Train Epoch: 1544 [acc: 89%]\tLoss: 0.369839\n",
      "Train Epoch: 1545 [acc: 96%]\tLoss: 0.170406\n",
      "Train Epoch: 1546 [acc: 93%]\tLoss: 0.212775\n",
      "Train Epoch: 1547 [acc: 90%]\tLoss: 0.369738\n",
      "Train Epoch: 1548 [acc: 95%]\tLoss: 0.164137\n",
      "Train Epoch: 1549 [acc: 97%]\tLoss: 0.098283\n",
      "Train Epoch: 1550 [acc: 91%]\tLoss: 0.260394\n",
      "[Trained for 1550 epochs and tested on 5 sets of 2000 images]        Avg Acc: 29.49 +- 0.65 , Avg Loss: 5.15\n",
      "Train Epoch: 1551 [acc: 95%]\tLoss: 0.130462\n",
      "Train Epoch: 1552 [acc: 90%]\tLoss: 0.354987\n",
      "Train Epoch: 1553 [acc: 92%]\tLoss: 0.261197\n",
      "Train Epoch: 1554 [acc: 91%]\tLoss: 0.213491\n",
      "Train Epoch: 1555 [acc: 98%]\tLoss: 0.076958\n",
      "Train Epoch: 1556 [acc: 93%]\tLoss: 0.231488\n",
      "Train Epoch: 1557 [acc: 85%]\tLoss: 0.458766\n",
      "Train Epoch: 1558 [acc: 95%]\tLoss: 0.176406\n",
      "Train Epoch: 1559 [acc: 93%]\tLoss: 0.174336\n",
      "Train Epoch: 1560 [acc: 91%]\tLoss: 0.253832\n",
      "Train Epoch: 1561 [acc: 97%]\tLoss: 0.114645\n",
      "Train Epoch: 1562 [acc: 94%]\tLoss: 0.157812\n",
      "Train Epoch: 1563 [acc: 94%]\tLoss: 0.221199\n",
      "Train Epoch: 1564 [acc: 94%]\tLoss: 0.249429\n",
      "Train Epoch: 1565 [acc: 93%]\tLoss: 0.219573\n",
      "Train Epoch: 1566 [acc: 90%]\tLoss: 0.287595\n",
      "Train Epoch: 1567 [acc: 97%]\tLoss: 0.097823\n",
      "Train Epoch: 1568 [acc: 95%]\tLoss: 0.240666\n",
      "Train Epoch: 1569 [acc: 90%]\tLoss: 0.304885\n",
      "Train Epoch: 1570 [acc: 86%]\tLoss: 0.257905\n",
      "Train Epoch: 1571 [acc: 95%]\tLoss: 0.182176\n",
      "Train Epoch: 1572 [acc: 93%]\tLoss: 0.235844\n",
      "Train Epoch: 1573 [acc: 90%]\tLoss: 0.207511\n",
      "Train Epoch: 1574 [acc: 94%]\tLoss: 0.166413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1575 [acc: 89%]\tLoss: 0.277492\n",
      "[Trained for 1575 epochs and tested on 5 sets of 2000 images]        Avg Acc: 35.06 +- 0.62 , Avg Loss: 4.42\n",
      "Train Epoch: 1576 [acc: 92%]\tLoss: 0.230349\n",
      "Train Epoch: 1577 [acc: 90%]\tLoss: 0.313298\n",
      "Train Epoch: 1578 [acc: 99%]\tLoss: 0.057142\n",
      "Train Epoch: 1579 [acc: 95%]\tLoss: 0.151535\n",
      "Train Epoch: 1580 [acc: 95%]\tLoss: 0.140721\n",
      "Train Epoch: 1581 [acc: 96%]\tLoss: 0.116118\n",
      "Train Epoch: 1582 [acc: 96%]\tLoss: 0.141786\n",
      "Train Epoch: 1583 [acc: 94%]\tLoss: 0.159263\n",
      "Train Epoch: 1584 [acc: 93%]\tLoss: 0.231313\n",
      "Train Epoch: 1585 [acc: 93%]\tLoss: 0.246126\n",
      "Train Epoch: 1586 [acc: 97%]\tLoss: 0.084991\n",
      "Train Epoch: 1587 [acc: 96%]\tLoss: 0.084852\n",
      "Train Epoch: 1588 [acc: 94%]\tLoss: 0.158712\n",
      "Train Epoch: 1589 [acc: 93%]\tLoss: 0.233070\n",
      "Train Epoch: 1590 [acc: 95%]\tLoss: 0.119156\n",
      "Train Epoch: 1591 [acc: 89%]\tLoss: 0.281254\n",
      "Train Epoch: 1592 [acc: 94%]\tLoss: 0.175119\n",
      "Train Epoch: 1593 [acc: 95%]\tLoss: 0.192424\n",
      "Train Epoch: 1594 [acc: 89%]\tLoss: 0.325479\n",
      "Train Epoch: 1595 [acc: 93%]\tLoss: 0.185273\n",
      "Train Epoch: 1596 [acc: 92%]\tLoss: 0.272590\n",
      "Train Epoch: 1597 [acc: 95%]\tLoss: 0.180085\n",
      "Train Epoch: 1598 [acc: 95%]\tLoss: 0.166733\n",
      "Train Epoch: 1599 [acc: 95%]\tLoss: 0.227083\n",
      "Train Epoch: 1600 [acc: 90%]\tLoss: 0.251521\n",
      "[Trained for 1600 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.28 +- 0.55 , Avg Loss: 5.09\n",
      "Train Epoch: 1601 [acc: 94%]\tLoss: 0.193220\n",
      "Train Epoch: 1602 [acc: 97%]\tLoss: 0.109175\n",
      "Train Epoch: 1603 [acc: 94%]\tLoss: 0.207354\n",
      "Train Epoch: 1604 [acc: 95%]\tLoss: 0.146713\n",
      "Train Epoch: 1605 [acc: 95%]\tLoss: 0.120825\n",
      "Train Epoch: 1606 [acc: 93%]\tLoss: 0.228093\n",
      "Train Epoch: 1607 [acc: 96%]\tLoss: 0.153515\n",
      "Train Epoch: 1608 [acc: 92%]\tLoss: 0.222862\n",
      "Train Epoch: 1609 [acc: 95%]\tLoss: 0.168253\n",
      "Train Epoch: 1610 [acc: 92%]\tLoss: 0.230264\n",
      "Train Epoch: 1611 [acc: 96%]\tLoss: 0.114494\n",
      "Train Epoch: 1612 [acc: 86%]\tLoss: 0.451906\n",
      "Train Epoch: 1613 [acc: 95%]\tLoss: 0.184110\n",
      "Train Epoch: 1614 [acc: 90%]\tLoss: 0.301349\n",
      "Train Epoch: 1615 [acc: 93%]\tLoss: 0.230871\n",
      "Train Epoch: 1616 [acc: 93%]\tLoss: 0.222563\n",
      "Train Epoch: 1617 [acc: 98%]\tLoss: 0.126834\n",
      "Train Epoch: 1618 [acc: 94%]\tLoss: 0.209090\n",
      "Train Epoch: 1619 [acc: 95%]\tLoss: 0.158654\n",
      "Train Epoch: 1620 [acc: 91%]\tLoss: 0.251178\n",
      "Train Epoch: 1621 [acc: 93%]\tLoss: 0.239746\n",
      "Train Epoch: 1622 [acc: 91%]\tLoss: 0.285755\n",
      "Train Epoch: 1623 [acc: 96%]\tLoss: 0.110520\n",
      "Train Epoch: 1624 [acc: 95%]\tLoss: 0.145698\n",
      "Train Epoch: 1625 [acc: 95%]\tLoss: 0.154954\n",
      "[Trained for 1625 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.07 +- 0.42 , Avg Loss: 4.32\n",
      "Train Epoch: 1626 [acc: 95%]\tLoss: 0.246012\n",
      "Train Epoch: 1627 [acc: 94%]\tLoss: 0.117689\n",
      "Train Epoch: 1628 [acc: 95%]\tLoss: 0.176843\n",
      "Train Epoch: 1629 [acc: 98%]\tLoss: 0.073202\n",
      "Train Epoch: 1630 [acc: 98%]\tLoss: 0.116037\n",
      "Train Epoch: 1631 [acc: 92%]\tLoss: 0.183709\n",
      "Train Epoch: 1632 [acc: 99%]\tLoss: 0.048464\n",
      "Train Epoch: 1633 [acc: 93%]\tLoss: 0.252141\n",
      "Train Epoch: 1634 [acc: 95%]\tLoss: 0.136723\n",
      "Train Epoch: 1635 [acc: 94%]\tLoss: 0.145972\n",
      "Train Epoch: 1636 [acc: 94%]\tLoss: 0.169947\n",
      "Train Epoch: 1637 [acc: 93%]\tLoss: 0.197069\n",
      "Train Epoch: 1638 [acc: 97%]\tLoss: 0.167586\n",
      "Train Epoch: 1639 [acc: 93%]\tLoss: 0.253608\n",
      "Train Epoch: 1640 [acc: 98%]\tLoss: 0.103022\n",
      "Train Epoch: 1641 [acc: 92%]\tLoss: 0.215277\n",
      "Train Epoch: 1642 [acc: 91%]\tLoss: 0.271667\n",
      "Train Epoch: 1643 [acc: 94%]\tLoss: 0.200260\n",
      "Train Epoch: 1644 [acc: 94%]\tLoss: 0.136191\n",
      "Train Epoch: 1645 [acc: 95%]\tLoss: 0.151630\n",
      "Train Epoch: 1646 [acc: 96%]\tLoss: 0.067141\n",
      "Train Epoch: 1647 [acc: 96%]\tLoss: 0.164981\n",
      "Train Epoch: 1648 [acc: 93%]\tLoss: 0.149406\n",
      "Train Epoch: 1649 [acc: 96%]\tLoss: 0.124162\n",
      "Train Epoch: 1650 [acc: 89%]\tLoss: 0.328007\n",
      "[Trained for 1650 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.49 +- 0.98 , Avg Loss: 4.75\n",
      "Train Epoch: 1651 [acc: 96%]\tLoss: 0.123774\n",
      "Train Epoch: 1652 [acc: 90%]\tLoss: 0.351586\n",
      "Train Epoch: 1653 [acc: 97%]\tLoss: 0.095483\n",
      "Train Epoch: 1654 [acc: 93%]\tLoss: 0.274305\n",
      "Train Epoch: 1655 [acc: 94%]\tLoss: 0.181031\n",
      "Train Epoch: 1656 [acc: 95%]\tLoss: 0.171583\n",
      "Train Epoch: 1657 [acc: 91%]\tLoss: 0.238122\n",
      "Train Epoch: 1658 [acc: 96%]\tLoss: 0.199195\n",
      "Train Epoch: 1659 [acc: 96%]\tLoss: 0.138820\n",
      "Train Epoch: 1660 [acc: 93%]\tLoss: 0.174304\n",
      "Train Epoch: 1661 [acc: 96%]\tLoss: 0.112477\n",
      "Train Epoch: 1662 [acc: 92%]\tLoss: 0.201931\n",
      "Train Epoch: 1663 [acc: 95%]\tLoss: 0.133849\n",
      "Train Epoch: 1664 [acc: 96%]\tLoss: 0.178269\n",
      "Train Epoch: 1665 [acc: 90%]\tLoss: 0.294359\n",
      "Train Epoch: 1666 [acc: 95%]\tLoss: 0.136036\n",
      "Train Epoch: 1667 [acc: 96%]\tLoss: 0.182753\n",
      "Train Epoch: 1668 [acc: 93%]\tLoss: 0.169009\n",
      "Train Epoch: 1669 [acc: 92%]\tLoss: 0.194456\n",
      "Train Epoch: 1670 [acc: 98%]\tLoss: 0.104467\n",
      "Train Epoch: 1671 [acc: 94%]\tLoss: 0.154710\n",
      "Train Epoch: 1672 [acc: 94%]\tLoss: 0.258320\n",
      "Train Epoch: 1673 [acc: 95%]\tLoss: 0.125926\n",
      "Train Epoch: 1674 [acc: 91%]\tLoss: 0.272155\n",
      "Train Epoch: 1675 [acc: 94%]\tLoss: 0.182208\n",
      "[Trained for 1675 epochs and tested on 5 sets of 2000 images]        Avg Acc: 31.79 +- 0.26 , Avg Loss: 4.58\n",
      "Train Epoch: 1676 [acc: 91%]\tLoss: 0.242947\n",
      "Train Epoch: 1677 [acc: 96%]\tLoss: 0.124721\n",
      "Train Epoch: 1678 [acc: 96%]\tLoss: 0.221745\n",
      "Train Epoch: 1679 [acc: 93%]\tLoss: 0.216339\n",
      "Train Epoch: 1680 [acc: 94%]\tLoss: 0.188242\n",
      "Train Epoch: 1681 [acc: 93%]\tLoss: 0.197789\n",
      "Train Epoch: 1682 [acc: 94%]\tLoss: 0.194293\n",
      "Train Epoch: 1683 [acc: 93%]\tLoss: 0.198116\n",
      "Train Epoch: 1684 [acc: 97%]\tLoss: 0.131304\n",
      "Train Epoch: 1685 [acc: 94%]\tLoss: 0.147228\n",
      "Train Epoch: 1686 [acc: 93%]\tLoss: 0.225049\n",
      "Train Epoch: 1687 [acc: 94%]\tLoss: 0.165058\n",
      "Train Epoch: 1688 [acc: 96%]\tLoss: 0.117901\n",
      "Train Epoch: 1689 [acc: 91%]\tLoss: 0.193512\n",
      "Train Epoch: 1690 [acc: 95%]\tLoss: 0.118761\n",
      "Train Epoch: 1691 [acc: 95%]\tLoss: 0.145569\n",
      "Train Epoch: 1692 [acc: 94%]\tLoss: 0.197990\n",
      "Train Epoch: 1693 [acc: 97%]\tLoss: 0.134145\n",
      "Train Epoch: 1694 [acc: 96%]\tLoss: 0.098283\n",
      "Train Epoch: 1695 [acc: 96%]\tLoss: 0.122757\n",
      "Train Epoch: 1696 [acc: 92%]\tLoss: 0.206744\n",
      "Train Epoch: 1697 [acc: 97%]\tLoss: 0.117120\n",
      "Train Epoch: 1698 [acc: 97%]\tLoss: 0.141804\n",
      "Train Epoch: 1699 [acc: 98%]\tLoss: 0.121288\n",
      "Train Epoch: 1700 [acc: 94%]\tLoss: 0.155950\n",
      "[Trained for 1700 epochs and tested on 5 sets of 2000 images]        Avg Acc: 34.45 +- 0.26 , Avg Loss: 4.41\n",
      "Train Epoch: 1701 [acc: 98%]\tLoss: 0.112191\n",
      "Train Epoch: 1702 [acc: 95%]\tLoss: 0.148849\n",
      "Train Epoch: 1703 [acc: 95%]\tLoss: 0.174191\n",
      "Train Epoch: 1704 [acc: 95%]\tLoss: 0.152717\n",
      "Train Epoch: 1705 [acc: 93%]\tLoss: 0.239583\n",
      "Train Epoch: 1706 [acc: 95%]\tLoss: 0.158553\n",
      "Train Epoch: 1707 [acc: 93%]\tLoss: 0.175508\n",
      "Train Epoch: 1708 [acc: 98%]\tLoss: 0.083936\n",
      "Train Epoch: 1709 [acc: 93%]\tLoss: 0.171917\n",
      "Train Epoch: 1710 [acc: 95%]\tLoss: 0.147221\n",
      "Train Epoch: 1711 [acc: 93%]\tLoss: 0.162486\n",
      "Train Epoch: 1712 [acc: 95%]\tLoss: 0.150492\n",
      "Train Epoch: 1713 [acc: 93%]\tLoss: 0.244614\n",
      "Train Epoch: 1714 [acc: 91%]\tLoss: 0.275780\n",
      "Train Epoch: 1715 [acc: 93%]\tLoss: 0.228934\n",
      "Train Epoch: 1716 [acc: 93%]\tLoss: 0.216730\n",
      "Train Epoch: 1717 [acc: 95%]\tLoss: 0.134133\n",
      "Train Epoch: 1718 [acc: 97%]\tLoss: 0.087408\n",
      "Train Epoch: 1719 [acc: 97%]\tLoss: 0.140853\n",
      "Train Epoch: 1720 [acc: 98%]\tLoss: 0.086009\n",
      "Train Epoch: 1721 [acc: 93%]\tLoss: 0.250387\n",
      "Train Epoch: 1722 [acc: 91%]\tLoss: 0.297106\n",
      "Train Epoch: 1723 [acc: 95%]\tLoss: 0.160493\n",
      "Train Epoch: 1724 [acc: 93%]\tLoss: 0.185323\n",
      "Train Epoch: 1725 [acc: 98%]\tLoss: 0.117709\n",
      "[Trained for 1725 epochs and tested on 5 sets of 2000 images]        Avg Acc: 34.83 +- 0.33 , Avg Loss: 4.82\n",
      "Train Epoch: 1726 [acc: 94%]\tLoss: 0.214703\n",
      "Train Epoch: 1727 [acc: 96%]\tLoss: 0.179318\n",
      "Train Epoch: 1728 [acc: 96%]\tLoss: 0.166215\n",
      "Train Epoch: 1729 [acc: 96%]\tLoss: 0.155027\n",
      "Train Epoch: 1730 [acc: 97%]\tLoss: 0.094805\n",
      "Train Epoch: 1731 [acc: 94%]\tLoss: 0.138909\n",
      "Train Epoch: 1732 [acc: 94%]\tLoss: 0.204798\n",
      "Train Epoch: 1733 [acc: 95%]\tLoss: 0.191584\n",
      "Train Epoch: 1734 [acc: 94%]\tLoss: 0.190216\n",
      "Train Epoch: 1735 [acc: 94%]\tLoss: 0.183836\n",
      "Train Epoch: 1736 [acc: 92%]\tLoss: 0.170406\n",
      "Train Epoch: 1737 [acc: 95%]\tLoss: 0.218954\n",
      "Train Epoch: 1738 [acc: 87%]\tLoss: 0.437064\n",
      "Train Epoch: 1739 [acc: 96%]\tLoss: 0.194360\n",
      "Train Epoch: 1740 [acc: 99%]\tLoss: 0.075462\n",
      "Train Epoch: 1741 [acc: 91%]\tLoss: 0.203907\n",
      "Train Epoch: 1742 [acc: 96%]\tLoss: 0.102747\n",
      "Train Epoch: 1743 [acc: 91%]\tLoss: 0.318159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1744 [acc: 92%]\tLoss: 0.258450\n",
      "Train Epoch: 1745 [acc: 95%]\tLoss: 0.200334\n",
      "Train Epoch: 1746 [acc: 92%]\tLoss: 0.349224\n",
      "Train Epoch: 1747 [acc: 90%]\tLoss: 0.394925\n",
      "Train Epoch: 1748 [acc: 94%]\tLoss: 0.185571\n",
      "Train Epoch: 1749 [acc: 95%]\tLoss: 0.199728\n",
      "Train Epoch: 1750 [acc: 96%]\tLoss: 0.093285\n",
      "[Trained for 1750 epochs and tested on 5 sets of 2000 images]        Avg Acc: 32.90 +- 0.67 , Avg Loss: 4.37\n",
      "Train Epoch: 1751 [acc: 99%]\tLoss: 0.065901\n",
      "Train Epoch: 1752 [acc: 89%]\tLoss: 0.335816\n",
      "Train Epoch: 1753 [acc: 93%]\tLoss: 0.194855\n",
      "Train Epoch: 1754 [acc: 97%]\tLoss: 0.118738\n",
      "Train Epoch: 1755 [acc: 93%]\tLoss: 0.198381\n",
      "Train Epoch: 1756 [acc: 91%]\tLoss: 0.310581\n",
      "Train Epoch: 1757 [acc: 95%]\tLoss: 0.143106\n",
      "Train Epoch: 1758 [acc: 97%]\tLoss: 0.146292\n",
      "Train Epoch: 1759 [acc: 92%]\tLoss: 0.199741\n",
      "Train Epoch: 1760 [acc: 97%]\tLoss: 0.086256\n",
      "Train Epoch: 1761 [acc: 94%]\tLoss: 0.187009\n",
      "Train Epoch: 1762 [acc: 95%]\tLoss: 0.152203\n",
      "Train Epoch: 1763 [acc: 92%]\tLoss: 0.270757\n",
      "Train Epoch: 1764 [acc: 89%]\tLoss: 0.528743\n",
      "Train Epoch: 1765 [acc: 92%]\tLoss: 0.233180\n",
      "Train Epoch: 1766 [acc: 87%]\tLoss: 0.431107\n",
      "Train Epoch: 1767 [acc: 91%]\tLoss: 0.239674\n",
      "Train Epoch: 1768 [acc: 90%]\tLoss: 0.302520\n",
      "Train Epoch: 1769 [acc: 87%]\tLoss: 0.309141\n",
      "Train Epoch: 1770 [acc: 90%]\tLoss: 0.326814\n",
      "Train Epoch: 1771 [acc: 92%]\tLoss: 0.206090\n",
      "Train Epoch: 1772 [acc: 93%]\tLoss: 0.184139\n",
      "Train Epoch: 1773 [acc: 95%]\tLoss: 0.250624\n",
      "Train Epoch: 1774 [acc: 93%]\tLoss: 0.216788\n",
      "Train Epoch: 1775 [acc: 90%]\tLoss: 0.255848\n",
      "[Trained for 1775 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.60 +- 0.63 , Avg Loss: 4.83\n",
      "Train Epoch: 1776 [acc: 94%]\tLoss: 0.291153\n",
      "Train Epoch: 1777 [acc: 93%]\tLoss: 0.226911\n",
      "Train Epoch: 1778 [acc: 93%]\tLoss: 0.178174\n",
      "Train Epoch: 1779 [acc: 96%]\tLoss: 0.138198\n",
      "Train Epoch: 1780 [acc: 89%]\tLoss: 0.364387\n",
      "Train Epoch: 1781 [acc: 92%]\tLoss: 0.162131\n",
      "Train Epoch: 1782 [acc: 89%]\tLoss: 0.350285\n",
      "Train Epoch: 1783 [acc: 96%]\tLoss: 0.114323\n",
      "Train Epoch: 1784 [acc: 97%]\tLoss: 0.168310\n",
      "Train Epoch: 1785 [acc: 94%]\tLoss: 0.198311\n",
      "Train Epoch: 1786 [acc: 88%]\tLoss: 0.278428\n",
      "Train Epoch: 1787 [acc: 93%]\tLoss: 0.199907\n",
      "Train Epoch: 1788 [acc: 92%]\tLoss: 0.220545\n",
      "Train Epoch: 1789 [acc: 94%]\tLoss: 0.160910\n",
      "Train Epoch: 1790 [acc: 91%]\tLoss: 0.337640\n",
      "Train Epoch: 1791 [acc: 90%]\tLoss: 0.222994\n",
      "Train Epoch: 1792 [acc: 91%]\tLoss: 0.254402\n",
      "Train Epoch: 1793 [acc: 93%]\tLoss: 0.229420\n",
      "Train Epoch: 1794 [acc: 92%]\tLoss: 0.271235\n",
      "Train Epoch: 1795 [acc: 93%]\tLoss: 0.227249\n",
      "Train Epoch: 1796 [acc: 92%]\tLoss: 0.224120\n",
      "Train Epoch: 1797 [acc: 93%]\tLoss: 0.134761\n",
      "Train Epoch: 1798 [acc: 96%]\tLoss: 0.182953\n",
      "Train Epoch: 1799 [acc: 95%]\tLoss: 0.133290\n",
      "Train Epoch: 1800 [acc: 90%]\tLoss: 0.307425\n",
      "[Trained for 1800 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.58 +- 0.72 , Avg Loss: 3.88\n",
      "Train Epoch: 1801 [acc: 92%]\tLoss: 0.222598\n",
      "Train Epoch: 1802 [acc: 96%]\tLoss: 0.136032\n",
      "Train Epoch: 1803 [acc: 92%]\tLoss: 0.235134\n",
      "Train Epoch: 1804 [acc: 92%]\tLoss: 0.221183\n",
      "Train Epoch: 1805 [acc: 95%]\tLoss: 0.184619\n",
      "Train Epoch: 1806 [acc: 90%]\tLoss: 0.255341\n",
      "Train Epoch: 1807 [acc: 94%]\tLoss: 0.211093\n",
      "Train Epoch: 1808 [acc: 92%]\tLoss: 0.210832\n",
      "Train Epoch: 1809 [acc: 92%]\tLoss: 0.300434\n",
      "Train Epoch: 1810 [acc: 94%]\tLoss: 0.139714\n",
      "Train Epoch: 1811 [acc: 92%]\tLoss: 0.420636\n",
      "Train Epoch: 1812 [acc: 95%]\tLoss: 0.190022\n",
      "Train Epoch: 1813 [acc: 97%]\tLoss: 0.073137\n",
      "Train Epoch: 1814 [acc: 94%]\tLoss: 0.179050\n",
      "Train Epoch: 1815 [acc: 98%]\tLoss: 0.108088\n",
      "Train Epoch: 1816 [acc: 93%]\tLoss: 0.207693\n",
      "Train Epoch: 1817 [acc: 96%]\tLoss: 0.119426\n",
      "Train Epoch: 1818 [acc: 97%]\tLoss: 0.151245\n",
      "Train Epoch: 1819 [acc: 94%]\tLoss: 0.126112\n",
      "Train Epoch: 1820 [acc: 96%]\tLoss: 0.138035\n",
      "Train Epoch: 1821 [acc: 95%]\tLoss: 0.163203\n",
      "Train Epoch: 1822 [acc: 93%]\tLoss: 0.251702\n",
      "Train Epoch: 1823 [acc: 95%]\tLoss: 0.172777\n",
      "Train Epoch: 1824 [acc: 94%]\tLoss: 0.179085\n",
      "Train Epoch: 1825 [acc: 94%]\tLoss: 0.143795\n",
      "[Trained for 1825 epochs and tested on 5 sets of 2000 images]        Avg Acc: 34.26 +- 0.36 , Avg Loss: 3.87\n",
      "Train Epoch: 1826 [acc: 98%]\tLoss: 0.083072\n",
      "Train Epoch: 1827 [acc: 95%]\tLoss: 0.180564\n",
      "Train Epoch: 1828 [acc: 92%]\tLoss: 0.211957\n",
      "Train Epoch: 1829 [acc: 94%]\tLoss: 0.143969\n",
      "Train Epoch: 1830 [acc: 98%]\tLoss: 0.058404\n",
      "Train Epoch: 1831 [acc: 94%]\tLoss: 0.177685\n",
      "Train Epoch: 1832 [acc: 96%]\tLoss: 0.072033\n",
      "Train Epoch: 1833 [acc: 99%]\tLoss: 0.050779\n",
      "Train Epoch: 1834 [acc: 94%]\tLoss: 0.227014\n",
      "Train Epoch: 1835 [acc: 95%]\tLoss: 0.245738\n",
      "Train Epoch: 1836 [acc: 95%]\tLoss: 0.132773\n",
      "Train Epoch: 1837 [acc: 95%]\tLoss: 0.159811\n",
      "Train Epoch: 1838 [acc: 95%]\tLoss: 0.209329\n",
      "Train Epoch: 1839 [acc: 98%]\tLoss: 0.090060\n",
      "Train Epoch: 1840 [acc: 93%]\tLoss: 0.160954\n",
      "Train Epoch: 1841 [acc: 96%]\tLoss: 0.141571\n",
      "Train Epoch: 1842 [acc: 98%]\tLoss: 0.069933\n",
      "Train Epoch: 1843 [acc: 93%]\tLoss: 0.206700\n",
      "Train Epoch: 1844 [acc: 96%]\tLoss: 0.113894\n",
      "Train Epoch: 1845 [acc: 92%]\tLoss: 0.178334\n",
      "Train Epoch: 1846 [acc: 96%]\tLoss: 0.139725\n",
      "Train Epoch: 1847 [acc: 91%]\tLoss: 0.188480\n",
      "Train Epoch: 1848 [acc: 96%]\tLoss: 0.162341\n",
      "Train Epoch: 1849 [acc: 92%]\tLoss: 0.235108\n",
      "Train Epoch: 1850 [acc: 96%]\tLoss: 0.122117\n",
      "[Trained for 1850 epochs and tested on 5 sets of 2000 images]        Avg Acc: 35.99 +- 0.69 , Avg Loss: 4.12\n",
      "Train Epoch: 1851 [acc: 91%]\tLoss: 0.254601\n",
      "Train Epoch: 1852 [acc: 96%]\tLoss: 0.121348\n",
      "Train Epoch: 1853 [acc: 91%]\tLoss: 0.292023\n",
      "Train Epoch: 1854 [acc: 94%]\tLoss: 0.152471\n",
      "Train Epoch: 1855 [acc: 95%]\tLoss: 0.165133\n",
      "Train Epoch: 1856 [acc: 91%]\tLoss: 0.269199\n",
      "Train Epoch: 1857 [acc: 92%]\tLoss: 0.212711\n",
      "Train Epoch: 1858 [acc: 93%]\tLoss: 0.200271\n",
      "Train Epoch: 1859 [acc: 95%]\tLoss: 0.181771\n",
      "Train Epoch: 1860 [acc: 95%]\tLoss: 0.139742\n",
      "Train Epoch: 1861 [acc: 92%]\tLoss: 0.195781\n",
      "Train Epoch: 1862 [acc: 95%]\tLoss: 0.171206\n",
      "Train Epoch: 1863 [acc: 93%]\tLoss: 0.166295\n",
      "Train Epoch: 1864 [acc: 96%]\tLoss: 0.118363\n",
      "Train Epoch: 1865 [acc: 92%]\tLoss: 0.214953\n",
      "Train Epoch: 1866 [acc: 96%]\tLoss: 0.123622\n",
      "Train Epoch: 1867 [acc: 96%]\tLoss: 0.132131\n",
      "Train Epoch: 1868 [acc: 94%]\tLoss: 0.185365\n",
      "Train Epoch: 1869 [acc: 92%]\tLoss: 0.217043\n",
      "Train Epoch: 1870 [acc: 93%]\tLoss: 0.141068\n",
      "Train Epoch: 1871 [acc: 98%]\tLoss: 0.090907\n",
      "Train Epoch: 1872 [acc: 94%]\tLoss: 0.307272\n",
      "Train Epoch: 1873 [acc: 95%]\tLoss: 0.134156\n",
      "Train Epoch: 1874 [acc: 94%]\tLoss: 0.182193\n",
      "Train Epoch: 1875 [acc: 95%]\tLoss: 0.125015\n",
      "[Trained for 1875 epochs and tested on 5 sets of 2000 images]        Avg Acc: 34.40 +- 0.59 , Avg Loss: 4.57\n",
      "Train Epoch: 1876 [acc: 93%]\tLoss: 0.226539\n",
      "Train Epoch: 1877 [acc: 93%]\tLoss: 0.135918\n",
      "Train Epoch: 1878 [acc: 94%]\tLoss: 0.217860\n",
      "Train Epoch: 1879 [acc: 93%]\tLoss: 0.228395\n",
      "Train Epoch: 1880 [acc: 93%]\tLoss: 0.133126\n",
      "Train Epoch: 1881 [acc: 96%]\tLoss: 0.087730\n",
      "Train Epoch: 1882 [acc: 97%]\tLoss: 0.133109\n",
      "Train Epoch: 1883 [acc: 93%]\tLoss: 0.166682\n",
      "Train Epoch: 1884 [acc: 94%]\tLoss: 0.185087\n",
      "Train Epoch: 1885 [acc: 90%]\tLoss: 0.305024\n",
      "Train Epoch: 1886 [acc: 90%]\tLoss: 0.285902\n",
      "Train Epoch: 1887 [acc: 95%]\tLoss: 0.143337\n",
      "Train Epoch: 1888 [acc: 91%]\tLoss: 0.273252\n",
      "Train Epoch: 1889 [acc: 94%]\tLoss: 0.163183\n",
      "Train Epoch: 1890 [acc: 93%]\tLoss: 0.150510\n",
      "Train Epoch: 1891 [acc: 93%]\tLoss: 0.154036\n",
      "Train Epoch: 1892 [acc: 93%]\tLoss: 0.274637\n",
      "Train Epoch: 1893 [acc: 93%]\tLoss: 0.218278\n",
      "Train Epoch: 1894 [acc: 93%]\tLoss: 0.181671\n",
      "Train Epoch: 1895 [acc: 94%]\tLoss: 0.183536\n",
      "Train Epoch: 1896 [acc: 92%]\tLoss: 0.224783\n",
      "Train Epoch: 1897 [acc: 92%]\tLoss: 0.188233\n",
      "Train Epoch: 1898 [acc: 95%]\tLoss: 0.161905\n",
      "Train Epoch: 1899 [acc: 96%]\tLoss: 0.181196\n",
      "Train Epoch: 1900 [acc: 97%]\tLoss: 0.085207\n",
      "[Trained for 1900 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.41 +- 0.64 , Avg Loss: 5.39\n",
      "Train Epoch: 1901 [acc: 96%]\tLoss: 0.097193\n",
      "Train Epoch: 1902 [acc: 99%]\tLoss: 0.072590\n",
      "Train Epoch: 1903 [acc: 94%]\tLoss: 0.181523\n",
      "Train Epoch: 1904 [acc: 92%]\tLoss: 0.161480\n",
      "Train Epoch: 1905 [acc: 94%]\tLoss: 0.202538\n",
      "Train Epoch: 1906 [acc: 98%]\tLoss: 0.099840\n",
      "Train Epoch: 1907 [acc: 97%]\tLoss: 0.090523\n",
      "Train Epoch: 1908 [acc: 96%]\tLoss: 0.101229\n",
      "Train Epoch: 1909 [acc: 89%]\tLoss: 0.249239\n",
      "Train Epoch: 1910 [acc: 91%]\tLoss: 0.291115\n",
      "Train Epoch: 1911 [acc: 97%]\tLoss: 0.092046\n",
      "Train Epoch: 1912 [acc: 93%]\tLoss: 0.220850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1913 [acc: 95%]\tLoss: 0.229541\n",
      "Train Epoch: 1914 [acc: 93%]\tLoss: 0.249079\n",
      "Train Epoch: 1915 [acc: 94%]\tLoss: 0.171019\n",
      "Train Epoch: 1916 [acc: 95%]\tLoss: 0.153181\n",
      "Train Epoch: 1917 [acc: 96%]\tLoss: 0.164813\n",
      "Train Epoch: 1918 [acc: 95%]\tLoss: 0.145639\n",
      "Train Epoch: 1919 [acc: 93%]\tLoss: 0.277524\n",
      "Train Epoch: 1920 [acc: 93%]\tLoss: 0.182770\n",
      "Train Epoch: 1921 [acc: 96%]\tLoss: 0.121205\n",
      "Train Epoch: 1922 [acc: 95%]\tLoss: 0.133642\n",
      "Train Epoch: 1923 [acc: 89%]\tLoss: 0.251794\n",
      "Train Epoch: 1924 [acc: 97%]\tLoss: 0.208952\n",
      "Train Epoch: 1925 [acc: 94%]\tLoss: 0.244054\n",
      "[Trained for 1925 epochs and tested on 5 sets of 2000 images]        Avg Acc: 35.60 +- 0.62 , Avg Loss: 4.03\n",
      "Train Epoch: 1926 [acc: 93%]\tLoss: 0.153874\n",
      "Train Epoch: 1927 [acc: 99%]\tLoss: 0.071766\n",
      "Train Epoch: 1928 [acc: 93%]\tLoss: 0.201775\n",
      "Train Epoch: 1929 [acc: 93%]\tLoss: 0.204459\n",
      "Train Epoch: 1930 [acc: 94%]\tLoss: 0.185598\n",
      "Train Epoch: 1931 [acc: 94%]\tLoss: 0.194224\n",
      "Train Epoch: 1932 [acc: 94%]\tLoss: 0.168477\n",
      "Train Epoch: 1933 [acc: 95%]\tLoss: 0.227291\n",
      "Train Epoch: 1934 [acc: 93%]\tLoss: 0.237090\n",
      "Train Epoch: 1935 [acc: 95%]\tLoss: 0.151480\n",
      "Train Epoch: 1936 [acc: 93%]\tLoss: 0.193287\n",
      "Train Epoch: 1937 [acc: 96%]\tLoss: 0.099354\n",
      "Train Epoch: 1938 [acc: 97%]\tLoss: 0.086566\n",
      "Train Epoch: 1939 [acc: 91%]\tLoss: 0.239737\n",
      "Train Epoch: 1940 [acc: 93%]\tLoss: 0.212923\n",
      "Train Epoch: 1941 [acc: 94%]\tLoss: 0.177481\n",
      "Train Epoch: 1942 [acc: 96%]\tLoss: 0.143438\n",
      "Train Epoch: 1943 [acc: 95%]\tLoss: 0.180128\n",
      "Train Epoch: 1944 [acc: 92%]\tLoss: 0.177460\n",
      "Train Epoch: 1945 [acc: 94%]\tLoss: 0.143831\n",
      "Train Epoch: 1946 [acc: 89%]\tLoss: 0.265313\n",
      "Train Epoch: 1947 [acc: 97%]\tLoss: 0.123493\n",
      "Train Epoch: 1948 [acc: 98%]\tLoss: 0.077458\n",
      "Train Epoch: 1949 [acc: 90%]\tLoss: 0.284586\n",
      "Train Epoch: 1950 [acc: 95%]\tLoss: 0.176809\n",
      "[Trained for 1950 epochs and tested on 5 sets of 2000 images]        Avg Acc: 30.72 +- 0.48 , Avg Loss: 4.66\n",
      "Train Epoch: 1951 [acc: 95%]\tLoss: 0.157456\n",
      "Train Epoch: 1952 [acc: 94%]\tLoss: 0.172512\n",
      "Train Epoch: 1953 [acc: 95%]\tLoss: 0.175758\n",
      "Train Epoch: 1954 [acc: 94%]\tLoss: 0.225970\n",
      "Train Epoch: 1955 [acc: 84%]\tLoss: 0.409435\n",
      "Train Epoch: 1956 [acc: 93%]\tLoss: 0.200629\n",
      "Train Epoch: 1957 [acc: 93%]\tLoss: 0.220903\n",
      "Train Epoch: 1958 [acc: 95%]\tLoss: 0.174049\n",
      "Train Epoch: 1959 [acc: 91%]\tLoss: 0.332168\n",
      "Train Epoch: 1960 [acc: 96%]\tLoss: 0.145332\n",
      "Train Epoch: 1961 [acc: 94%]\tLoss: 0.227009\n",
      "Train Epoch: 1962 [acc: 92%]\tLoss: 0.218282\n",
      "Train Epoch: 1963 [acc: 92%]\tLoss: 0.199147\n",
      "Train Epoch: 1964 [acc: 93%]\tLoss: 0.204675\n",
      "Train Epoch: 1965 [acc: 96%]\tLoss: 0.138214\n",
      "Train Epoch: 1966 [acc: 94%]\tLoss: 0.166447\n",
      "Train Epoch: 1967 [acc: 92%]\tLoss: 0.276034\n",
      "Train Epoch: 1968 [acc: 97%]\tLoss: 0.082128\n",
      "Train Epoch: 1969 [acc: 96%]\tLoss: 0.145876\n",
      "Train Epoch: 1970 [acc: 94%]\tLoss: 0.132597\n",
      "Train Epoch: 1971 [acc: 93%]\tLoss: 0.147677\n",
      "Train Epoch: 1972 [acc: 96%]\tLoss: 0.137565\n",
      "Train Epoch: 1973 [acc: 96%]\tLoss: 0.194200\n",
      "Train Epoch: 1974 [acc: 96%]\tLoss: 0.117978\n",
      "Train Epoch: 1975 [acc: 98%]\tLoss: 0.084161\n",
      "[Trained for 1975 epochs and tested on 5 sets of 2000 images]        Avg Acc: 34.62 +- 0.98 , Avg Loss: 4.70\n",
      "Train Epoch: 1976 [acc: 98%]\tLoss: 0.084934\n",
      "Train Epoch: 1977 [acc: 90%]\tLoss: 0.235369\n",
      "Train Epoch: 1978 [acc: 93%]\tLoss: 0.201140\n",
      "Train Epoch: 1979 [acc: 89%]\tLoss: 0.264682\n",
      "Train Epoch: 1980 [acc: 96%]\tLoss: 0.145240\n",
      "Train Epoch: 1981 [acc: 94%]\tLoss: 0.148905\n",
      "Train Epoch: 1982 [acc: 85%]\tLoss: 0.402149\n",
      "Train Epoch: 1983 [acc: 91%]\tLoss: 0.248467\n",
      "Train Epoch: 1984 [acc: 95%]\tLoss: 0.125250\n",
      "Train Epoch: 1985 [acc: 96%]\tLoss: 0.159551\n",
      "Train Epoch: 1986 [acc: 91%]\tLoss: 0.187507\n",
      "Train Epoch: 1987 [acc: 92%]\tLoss: 0.259198\n",
      "Train Epoch: 1988 [acc: 90%]\tLoss: 0.311587\n",
      "Train Epoch: 1989 [acc: 95%]\tLoss: 0.162068\n",
      "Train Epoch: 1990 [acc: 96%]\tLoss: 0.117972\n",
      "Train Epoch: 1991 [acc: 96%]\tLoss: 0.140384\n",
      "Train Epoch: 1992 [acc: 98%]\tLoss: 0.074200\n",
      "Train Epoch: 1993 [acc: 98%]\tLoss: 0.088310\n",
      "Train Epoch: 1994 [acc: 91%]\tLoss: 0.221286\n",
      "Train Epoch: 1995 [acc: 88%]\tLoss: 0.250616\n",
      "Train Epoch: 1996 [acc: 93%]\tLoss: 0.192267\n",
      "Train Epoch: 1997 [acc: 95%]\tLoss: 0.167138\n",
      "Train Epoch: 1998 [acc: 94%]\tLoss: 0.197953\n",
      "Train Epoch: 1999 [acc: 90%]\tLoss: 0.250440\n",
      "Train Epoch: 2000 [acc: 96%]\tLoss: 0.124534\n",
      "[Trained for 2000 epochs and tested on 5 sets of 2000 images]        Avg Acc: 33.03 +- 0.70 , Avg Loss: 4.40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = getModel(MODEL).cuda()\n",
    "optimizer,LR = getOptimizer128(OPTIM,model.parameters())\n",
    "\n",
    "print(' => Total trainable parameters: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))        \n",
    "\n",
    "trainTracker = {\"meanLoss\":[],\"accuracy\":[]}\n",
    "valTracker = {\"allLoss\":[],\"allAcc\":[],\"meanLoss\":[],\"meanAcc\":[],\"stdAcc\":[]}\n",
    "latexTracker = []\n",
    "\n",
    "print(\"Begin Train for {} epochs\".format(EPOCH_NUM))\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    acc, loss = glicoTrain(model, device, train_data[0], optimizer, \n",
    "                      epoch+1,glicoLoader,replaceProb=REPLACE_PROB, display=True)\n",
    "    trainTracker[\"meanLoss\"].append(loss)\n",
    "    trainTracker[\"accuracy\"].append(acc)\n",
    "    \n",
    "    if (epoch+1) % VAL_DISPLAY_DIVISOR == 0 or epoch == 0:\n",
    "        checkTest(model,device,valSets,valTracker,latexTracker,epoch+1,\n",
    "              model_name=MODEL,optim_name=OPTIM,lr=LR,totalTestSamples=VAL_SAMPLE_NUM*VALIDATION_SET_NUM,\n",
    "                  seed=seed,verbose=True)\n",
    "        \n",
    "          \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WideResNet28&25&16.11&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&50&17.02&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&75&22.75&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&100&21.92&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&125&24.37&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&150&26.47&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&175&27.08&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&200&28.62&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&225&28.76&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&250&27.82&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&275&29.74&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&300&29.38&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&325&26.97&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&350&29.82&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&375&28.88&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&400&31.92&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&425&32.57&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&450&29.14&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&475&31.27&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&500&29.62&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&525&27.91&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&550&32.48&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&575&31.77&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&600&33.11&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&625&32.43&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&650&29.6&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&675&30.63&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&700&30.75&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&725&31.25&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&750&33.75&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&775&31.57&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&800&32.85&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&825&30.61&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&850&32.4&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&875&34.76&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&900&33.58&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&925&32.6&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&950&32.27&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&975&33.04&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1000&32.21&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1025&33.14&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1050&33.15&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1075&33.54&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1100&31.5&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1125&33.02&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1150&30.14&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1175&32.56&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1200&32.98&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1225&30.76&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1250&29.55&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1275&30.56&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1300&28.48&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1325&33.71&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1350&33.83&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1375&33.97&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1400&33.84&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1425&31.51&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1450&32.16&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1475&30.84&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1500&33.13&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1525&31.02&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1550&29.49&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1575&35.06&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1600&31.28&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1625&33.07&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1650&33.49&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1675&31.79&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1700&34.45&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1725&34.83&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1750&32.9&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1775&33.6&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1800&33.58&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1825&34.26&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1850&35.99&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1875&34.4&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1900&30.41&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1925&35.6&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1950&30.72&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&1975&34.62&Adam&0.001&10000&Nothing&1620010424\\\\\n",
      "WideResNet28&2000&33.03&Adam&0.001&10000&Nothing&1620010424\\\\\n"
     ]
    }
   ],
   "source": [
    "dirname = latexTracker[-1][:-2] \n",
    "\n",
    "def writeTex(latexTracker,dirname):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        \n",
    "    f= open(os.path.join(dirname,\"latexTable.txt\"),\"w\")\n",
    "    for x in latexTracker:\n",
    "        f.write(x)\n",
    "    f.close()\n",
    "\n",
    "writeTex(latexTracker,dirname)\n",
    "\n",
    "for x in latexTracker:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b80f051ceb38>:39: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "<ipython-input-3-b80f051ceb38>:39: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochList = [x+1 for x in range(len(trainTracker[\"meanLoss\"]))]\n",
    "\n",
    "plot(xlist=epochList,ylist=trainTracker[\"meanLoss\"],xlab=\"Mean Train Loss\",\n",
    "    ylab=\"Epochs\",title=\"Mean Train Loss over Epochs\",\n",
    "    color=\"#243A92\",label=\"mean train loss\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=trainTracker[\"accuracy\"],xlab=\"Train Accuracy\",\n",
    "    ylab=\"Epochs\",title=\"Train Accuracy Over Epochs\",\n",
    "    color=\"#34267E\",label=\"Train Accuracy\",savedir=dirname,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b80f051ceb38>:39: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "<ipython-input-3-b80f051ceb38>:39: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "<ipython-input-3-b80f051ceb38>:39: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "<ipython-input-3-b80f051ceb38>:39: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "<ipython-input-3-b80f051ceb38>:39: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochList = [VAL_DISPLAY_DIVISOR*(x+1) for x in range(len(valTracker[\"meanLoss\"]))]\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"meanLoss\"],xlab=\"Epochs\",\n",
    "    ylab=\"Mean Val Loss\",title=\"Mean Val Loss over Epochs\",\n",
    "    color=\"#243A92\",label=\"mean val loss\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"meanAcc\"],xlab=\"Epochs\",\n",
    "    ylab=\"Val Accuracy\",title=\"Val Accuracy Over Epochs\",\n",
    "    color=\"#34267E\",label=\"Val Accuracy\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"stdAcc\"],xlab=\"Epochs\",\n",
    "    ylab=\"Val Accuracy Standard Deviation\",title=\"Val Accuracy Standard Deviation Over Epochs\",\n",
    "    color=\"#34267E\",label=\"Val Accuracy SD\",savedir=dirname,save=True)\n",
    "\n",
    "\n",
    "valSetEvalCount = VAL_DISPLAY_DIVISOR * EPOCH_NUM * VALIDATION_SET_NUM\n",
    "epochList = [VAL_DISPLAY_DIVISOR*(x+1) for x in range(len(valTracker[\"meanLoss\"]))\\\n",
    "             for y in range(VALIDATION_SET_NUM)]\n",
    "\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"allLoss\"],xlab=\"Val Set Evaluations\",\n",
    "    ylab=\"Val Loss\",title=\"Val loss over val set evaluations ({} \\\n",
    "every {} epochs)\".format(VALIDATION_SET_NUM,VAL_DISPLAY_DIVISOR),\n",
    "    color=\"#34267E\",label=\"Val Loss\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"allAcc\"],xlab=\"Val Set Evaluations\",\n",
    "    ylab=\"Val Accuracy\",title=\"Val loss over val set evaluations ({} \\\n",
    "every {} epochs) \".format(VALIDATION_SET_NUM,VAL_DISPLAY_DIVISOR),\n",
    "    color=\"#34267E\",label=\"Val Accuracy\",savedir=dirname,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
