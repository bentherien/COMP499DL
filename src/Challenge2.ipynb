{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.eugene import train, test\n",
    "import torchvision.models as models\n",
    "\n",
    "from numpy.random import RandomState\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "  \n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Num Samples For Training 100 Num Samples For Val 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /home/benjamin/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f98e44473214448b62ae5145a56030c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=52147035.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 0 [0/100 (0%)]\tLoss: 8.146880\n",
      "Train Epoch: 1 [0/100 (0%)]\tLoss: 8.128654\n",
      "Train Epoch: 2 [0/100 (0%)]\tLoss: 8.077737\n",
      "Train Epoch: 3 [0/100 (0%)]\tLoss: 8.146319\n",
      "Train Epoch: 4 [0/100 (0%)]\tLoss: 8.103650\n",
      "Train Epoch: 5 [0/100 (0%)]\tLoss: 8.019337\n",
      "Train Epoch: 6 [0/100 (0%)]\tLoss: 8.140182\n",
      "Train Epoch: 7 [0/100 (0%)]\tLoss: 8.071136\n",
      "Train Epoch: 8 [0/100 (0%)]\tLoss: 8.150529\n",
      "Train Epoch: 9 [0/100 (0%)]\tLoss: 8.094483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/.local/lib/python3.8/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 8.5938, Accuracy: 1/2000 (0.05%)\n",
      "\n",
      "Num Samples For Training 100 Num Samples For Val 2000\n",
      "Train Epoch: 0 [0/100 (0%)]\tLoss: 8.151623\n",
      "Train Epoch: 1 [0/100 (0%)]\tLoss: 8.065230\n",
      "Train Epoch: 2 [0/100 (0%)]\tLoss: 8.053954\n",
      "Train Epoch: 3 [0/100 (0%)]\tLoss: 8.148664\n",
      "Train Epoch: 4 [0/100 (0%)]\tLoss: 8.125424\n",
      "Train Epoch: 5 [0/100 (0%)]\tLoss: 8.090104\n",
      "Train Epoch: 6 [0/100 (0%)]\tLoss: 8.026558\n",
      "Train Epoch: 7 [0/100 (0%)]\tLoss: 8.071366\n",
      "Train Epoch: 8 [0/100 (0%)]\tLoss: 8.076777\n",
      "Train Epoch: 9 [0/100 (0%)]\tLoss: 8.050603\n",
      "\n",
      "Test set: Average loss: 8.5285, Accuracy: 0/2000 (0.00%)\n",
      "\n",
      "Acc over 2 instances: 0.03 +- 0.03\n"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# We resize images to allow using imagenet pre-trained models, is there a better way?\n",
    "resize = transforms.Resize(224) \n",
    "\n",
    "transform_val = transforms.Compose([resize, transforms.ToTensor(), normalize]) #careful to keep this one same\n",
    "transform_train = transforms.Compose([resize, transforms.ToTensor(), normalize]) \n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device) # you will really need gpu's for this part\n",
    "    \n",
    "##### Cifar Data\n",
    "cifar_data = datasets.CIFAR10(root='.',train=True, transform=transform_train, download=True)\n",
    "    \n",
    "#We need two copies of this due to weird dataset api \n",
    "cifar_data_val = datasets.CIFAR10(root='.',train=True, transform=transform_val, download=True)\n",
    "    \n",
    "# Extract a subset of 100 (class balanced) samples per class\n",
    "\n",
    "accs = []\n",
    "\n",
    "for seed in [1,2]:\n",
    "    prng = RandomState(seed)\n",
    "    random_permute = prng.permutation(np.arange(0, 5000))\n",
    "    indx_train = np.concatenate([np.where(np.array(cifar_data.targets) == classe)[0][random_permute[0:10]] for classe in range(0, 10)])\n",
    "    indx_val = np.concatenate([np.where(np.array(cifar_data.targets) == classe)[0][random_permute[10:210]] for classe in range(0, 10)])\n",
    "\n",
    "    train_data = Subset(cifar_data, indx_train)\n",
    "    val_data = Subset(cifar_data_val, indx_val)\n",
    "\n",
    "    print('Num Samples For Training %d Num Samples For Val %d'%(train_data.indices.shape[0],val_data.indices.shape[0]))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                             batch_size=128, \n",
    "                                             shuffle=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_data,\n",
    "                                           batch_size=128, \n",
    "                                           shuffle=False)\n",
    "    \n",
    "    #     resnet18 = models.resnet18()\n",
    "    #     alexnet = models.alexnet()\n",
    "    #     vgg16 = models.vgg16()\n",
    "    #     squeezenet = models.squeezenet1_0()\n",
    "    #     densenet = models.densenet161()\n",
    "    #     inception = models.inception_v3()\n",
    "    #     googlenet = models.googlenet()\n",
    "    #     shufflenet = models.shufflenet_v2_x1_0()\n",
    "    #     mobilenet = models.mobilenet_v2()\n",
    "    #     resnext50_32x4d = models.resnext50_32x4d()\n",
    "    #     wide_resnet50_2 = models.wide_resnet50_2()\n",
    "    #     mnasnet = models.mnasnet1_0()\n",
    "\n",
    "\n",
    "    model = models.googlenet(pretrained=True)\n",
    "    model.classifier = nn.Linear(256 * 6 * 6, 10)\n",
    "    optimizer = torch.optim.SGD(model.classifier.parameters(), \n",
    "                              lr=0.01, momentum=0.9,\n",
    "                              weight_decay=0.0005)\n",
    "    model.to(device)\n",
    "    for epoch in range(10):\n",
    "        train(model, device, train_loader, optimizer, epoch, display=True)\n",
    "\n",
    "    accs.append(test(model, device, val_loader))\n",
    "\n",
    "accs = np.array(accs)\n",
    "print('Acc over 2 instances: %.2f +- %.2f'%(accs.mean(),accs.std()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-6bd317ee73b6>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-6bd317ee73b6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"Alexnet\" Acc over 2 instances: 50.78 +- 0.82\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"Alexnet\" Acc over 2 instances: 50.78 +- 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
