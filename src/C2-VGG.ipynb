{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import gc\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "from IPython.core.display import display, HTML\n",
    "from numpy.random import RandomState\n",
    "from wide_resnet import WideResNet\n",
    "from auto_augment import AutoAugment, Cutout\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from cifar_loader import SmallSampleController\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "# display(HTML(\"<style>.container { width:40% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getAcc(preds,targets):\n",
    "    return np.sum([1 if preds[i] == targets[i] else 0 for i in range(len(preds))])/len(preds)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch, display=True):\n",
    "    \"\"\"\n",
    "    Summary: Implements the training procedure for a given model\n",
    "    == params ==\n",
    "    model: the model to test\n",
    "    device: cuda or cpu \n",
    "    optimizer: the optimizer for our training\n",
    "    train_loader: dataloader for our train data\n",
    "    display: output flag\n",
    "    == output ==\n",
    "    the mean train loss, the train accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    lossTracker = []\n",
    "    \n",
    "    targets=[]\n",
    "    preds=[]\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lossTracker.append(loss.detach())\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(output,1).cpu().numpy()\n",
    "\n",
    "            preds.extend(pred)\n",
    "            targets.extend(target.cpu().numpy())\n",
    "        \n",
    "    lossTracker = [x.item() for x in lossTracker]\n",
    "    meanLoss = np.mean(lossTracker)\n",
    "    accuracy = getAcc(preds,targets)\n",
    "    if display:\n",
    "        print('Train Epoch: {} [acc: {:.0f}%]\\tLoss: {:.6f}'.format(\n",
    "          epoch, 100. * accuracy, meanLoss))\n",
    "        \n",
    "    return accuracy, meanLoss\n",
    "\n",
    "\n",
    "\n",
    "def test(model, device, test_loader,verbose=True):\n",
    "    \"\"\"\n",
    "    Summary: Implements the testing procedure for a given model\n",
    "    == params ==\n",
    "    model: the model to test\n",
    "    device: cuda or cpu \n",
    "    test_loader: dataloader for our test data\n",
    "    verbose: output flag\n",
    "    == output ==\n",
    "    the mean test loss, the test accuracy\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "\n",
    "    meanLoss = test_loss / len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    if verbose: print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        mean_test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))\n",
    "        \n",
    "    return accuracy, meanLoss\n",
    "\n",
    "\n",
    "def checkTest(model,device,valSets,valTracker,latexTracker,epoch,\n",
    "              model_name,optim_name,lr,totalTestSamples,seed,verbose=True):\n",
    "    \"\"\"\n",
    "    Summary: checks the test accuracy, prints, and saves statistics\n",
    "    \"\"\"\n",
    "    tempAcc = []\n",
    "    tempLoss = []\n",
    "    for val_loader in valSets:\n",
    "        acc,loss = test(model, device, val_loader,verbose = False)\n",
    "        tempAcc.append(acc)\n",
    "        tempLoss.append(loss)\n",
    "        \n",
    "    meanAcc = np.mean(tempAcc)\n",
    "    stdAcc = np.std(tempAcc)\n",
    "    \n",
    "    meanLoss = np.mean(tempLoss)\n",
    "    if verbose:\n",
    "        print('[Trained for {} epochs and tested on {} sets of 2000 images]\\\n",
    "        Avg Acc: {:.2f} +- {:.2f} , Avg Loss: {:.2f}'.format(\n",
    "            epoch,VALIDATION_SET_NUM,meanAcc,stdAcc,meanLoss))\n",
    "        \n",
    "        \n",
    "    tableRow = getLatexRow(architecture=model_name,epoch=epoch,accuracy=meanAcc,optim=optim_name,\n",
    "                           lr=lr,totalTestSamples=totalTestSamples,dataAug=\"Nothing\",\n",
    "                           seed=seed,title=False)\n",
    "    \n",
    "    latexTracker.append(tableRow)\n",
    "        \n",
    "    valTracker[\"allLoss\"].extend(tempLoss)\n",
    "    valTracker[\"allAcc\"].extend(tempAcc)\n",
    "    valTracker[\"meanLoss\"].append(meanLoss)\n",
    "    valTracker[\"meanAcc\"].append(meanAcc)\n",
    "    valTracker[\"stdAcc\"].append(stdAcc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLatexRow(architecture,epoch,accuracy,optim,lr,\n",
    "                totalTestSamples,dataAug,seed,title=False):\n",
    "    \"\"\"\n",
    "    Summary: generates one row of latex for a results table\n",
    "    \"\"\"\n",
    "    categories = [\"Model\",\"Epoch\",\"Accuracy\",\"Optimizer\",\"lr\",\"Test Sample Num\",\n",
    "                  \"data augmentation\",\"seed\"]\n",
    "    row = [str(architecture),str(epoch),str(round(accuracy,3)),str(optim),\n",
    "           str(lr),str(totalTestSamples),str(dataAug),str(seed)]\n",
    "    \n",
    "    if title:\n",
    "        c = \"&\".join(categories)\n",
    "        r = \"&\".join(row)\n",
    "        return \"{}\\\\\\\\\\n{}\\\\\\\\\".format(c,r)\n",
    "    else:\n",
    "        r = \"&\".join(row)\n",
    "        return \"{}\\\\\\\\\".format(r)\n",
    "    \n",
    "    \n",
    "def plot(xlist,ylist,xlab,ylab,title,color,label,savedir=\".\",save=False):\n",
    "    \"\"\"\n",
    "    Summary: plots the given list of numbers against its idices and \n",
    "    allows for high resolution saving\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "    plt.plot(xlist,ylist,color=color,marker=\".\",label=label)\n",
    "    plt.legend()\n",
    "    \n",
    "    if save:\n",
    "        if not os.path.isdir(savedir):\n",
    "            os.mkdir(savedir)\n",
    "        filepath = os.path.join(savedir,\"{}\".format(title))\n",
    "        plt.savefig(filepath+\".pdf\")\n",
    "        os.system(\"pdftoppm -png -r 300 {}.pdf {}.png\".format(filepath,filepath))\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(model_name):\n",
    "    if \"wide\" in model_name.lower():\n",
    "        return WideResNet(28, 10, num_classes=10)\n",
    "    elif \"efficient\" in model_name.lower():\n",
    "        return EfficientNet.from_pretrained(model_name,num_classes = 10) # change to not be pretrained\n",
    "    elif \"vgg16\" in model_name.lower():\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        model.classifier[6] = nn.Linear(4096, 10)\n",
    "        return model\n",
    "    elif \"alexnet\" in model_name.lower():\n",
    "        model = models.alexnet(pretrained=True)\n",
    "        model.classifier = nn.Linear(256 * 6 * 6, 100)\n",
    "        return model\n",
    "    elif \"resnet18\" in model_name.lower():\n",
    "        model = models.resnet18(pretrained=True)\n",
    "#         model.fc.out_features = 10\n",
    "        return model\n",
    "    elif \"resnet50\" in model_name.lower():\n",
    "        model = models.resnet50(pretrained=True)\n",
    "#         model.fc.out_features = 10\n",
    "        return model\n",
    "    elif \"densenet161\" in model_name.lower():\n",
    "        model = models.densenet161(pretrained=True)\n",
    "#         model.fc.out_features = 10\n",
    "        return model\n",
    "    elif \"wideresnet\" in model_name.lower():\n",
    "            model = models.wide_resnet50_2(pretrained=True)\n",
    "    #         model.fc.out_features = 10\n",
    "            return model\n",
    "    elif \"resnext101\" in model_name.lower():\n",
    "            model = models.resnext101_32x8d(pretrained=True)\n",
    "    #         model.fc.out_features = 10\n",
    "            return model\n",
    "    elif \"inception_v3\" in model_name.lower():\n",
    "            model = models.inception_v3(pretrained=True,aux_logits=False)\n",
    "    #         model.fc.out_features = 10\n",
    "            return model\n",
    "    t\n",
    "    \n",
    "    \n",
    "def getOptimizer128(optimizer_name,parameters):\n",
    "    if \"sgd\" in  optimizer_name.lower():\n",
    "        LR = 0.01\n",
    "        optim = torch.optim.SGD(parameters, \n",
    "                                  lr=LR, momentum=0.9,\n",
    "                                  weight_decay=0.0005)\n",
    "        return optim, LR\n",
    "    elif \"adam\" in optimizer_name.lower():\n",
    "        LR = 0.00005\n",
    "        optim = torch.optim.Adam(parameters, \n",
    "                              lr=LR, weight_decay=0)\n",
    "        return optim, LR\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class featureExtractor(nn.Module):\n",
    "    def __init__(self,efficientNet):\n",
    "        super().__init__()\n",
    "        self.eNet = efficientNet \n",
    "        self._avg_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self._dropout = nn.Dropout(self.eNet._global_params.dropout_rate)\n",
    "        self._fc = nn.Linear(2560,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        x = self.eNet.extract_features(inputs)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self._dropout(x)\n",
    "        x = self._fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Generated new permutation of the CIFAR train dataset with                 seed:1619999668, train sample num: 100, test sample num: 2000\n",
      "<bound method Module.parameters of VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")>\n",
      " => Total trainable parameters: 134.30M\n",
      "Begin Train for 1000 epochs\n",
      "Train Epoch: 1 [acc: 8%]\tLoss: 2.646933\n",
      "Train Epoch: 2 [acc: 27%]\tLoss: 2.103820\n",
      "Train Epoch: 3 [acc: 24%]\tLoss: 2.024459\n",
      "Train Epoch: 4 [acc: 32%]\tLoss: 1.861565\n",
      "Train Epoch: 5 [acc: 43%]\tLoss: 1.595575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/venv/torch11/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trained for 5 epochs and tested on 5 sets of 2000 images]        Avg Acc: 47.96 +- 0.48 , Avg Loss: 1.56\n",
      "Train Epoch: 6 [acc: 52%]\tLoss: 1.402733\n",
      "Train Epoch: 7 [acc: 51%]\tLoss: 1.255943\n",
      "Train Epoch: 8 [acc: 48%]\tLoss: 1.468910\n",
      "Train Epoch: 9 [acc: 56%]\tLoss: 1.134326\n",
      "Train Epoch: 10 [acc: 60%]\tLoss: 1.048880\n",
      "[Trained for 10 epochs and tested on 5 sets of 2000 images]        Avg Acc: 58.94 +- 0.30 , Avg Loss: 1.28\n",
      "Train Epoch: 11 [acc: 69%]\tLoss: 0.820446\n",
      "Train Epoch: 12 [acc: 64%]\tLoss: 1.026484\n",
      "Train Epoch: 13 [acc: 75%]\tLoss: 0.773723\n",
      "Train Epoch: 14 [acc: 70%]\tLoss: 0.691225\n",
      "Train Epoch: 15 [acc: 86%]\tLoss: 0.498535\n",
      "[Trained for 15 epochs and tested on 5 sets of 2000 images]        Avg Acc: 60.23 +- 0.24 , Avg Loss: 1.20\n",
      "Train Epoch: 16 [acc: 78%]\tLoss: 0.683533\n",
      "Train Epoch: 17 [acc: 82%]\tLoss: 0.509918\n",
      "Train Epoch: 18 [acc: 80%]\tLoss: 0.576631\n",
      "Train Epoch: 19 [acc: 88%]\tLoss: 0.382131\n",
      "Train Epoch: 20 [acc: 88%]\tLoss: 0.314594\n",
      "[Trained for 20 epochs and tested on 5 sets of 2000 images]        Avg Acc: 58.32 +- 0.50 , Avg Loss: 1.79\n",
      "Train Epoch: 21 [acc: 83%]\tLoss: 0.442416\n",
      "Train Epoch: 22 [acc: 88%]\tLoss: 0.599448\n",
      "Train Epoch: 23 [acc: 84%]\tLoss: 0.339439\n",
      "Train Epoch: 24 [acc: 83%]\tLoss: 0.460562\n",
      "Train Epoch: 25 [acc: 79%]\tLoss: 0.531158\n",
      "[Trained for 25 epochs and tested on 5 sets of 2000 images]        Avg Acc: 59.32 +- 1.02 , Avg Loss: 1.57\n",
      "Train Epoch: 26 [acc: 88%]\tLoss: 0.360695\n",
      "Train Epoch: 27 [acc: 84%]\tLoss: 0.536586\n",
      "Train Epoch: 28 [acc: 82%]\tLoss: 0.566487\n",
      "Train Epoch: 29 [acc: 85%]\tLoss: 0.421765\n",
      "Train Epoch: 30 [acc: 86%]\tLoss: 0.395273\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "#     resnet18 = models.resnet18()\n",
    "#     alexnet = models.alexnet()\n",
    "#     vgg16 = models.vgg16()\n",
    "#     squeezenet = models.squeezenet1_0()\n",
    "#     densenet = models.densenet161()\n",
    "#     inception = models.inception_v3()\n",
    "#     googlenet = models.googlenet()\n",
    "#     shufflenet = models.shufflenet_v2_x1_0()\n",
    "#     mobilenet = models.mobilenet_v2()\n",
    "#     resnext50_32x4d = models.resnext50_32x4d()\n",
    "#     wide_resnet50_2 = models.wide_resnet50_2()\n",
    "#     mnasnet = models.mnasnet1_0()\n",
    "\n",
    "OPTIM = \"sgd\"\n",
    "MODEL = \"vgg16\"\n",
    "EPOCH_NUM = 1000\n",
    "TRAIN_SAMPLE_NUM = 100\n",
    "VAL_SAMPLE_NUM = 2000\n",
    "BATCH_SIZE = 64\n",
    "VALIDATION_SET_NUM = 5\n",
    "AUGMENT = True\n",
    "VAL_DISPLAY_DIVISOR =5\n",
    "CIFAR_TRAIN = True\n",
    "\n",
    "#cifar-10:\n",
    "#mean = (0.4914, 0.4822, 0.4465)\n",
    "#std = (0.247, 0.243, 0.261)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                  std=[0.229, 0.224, 0.225])\n",
    "if AUGMENT:\n",
    "    dataAugmentation = [ \n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        AutoAugment(),\n",
    "        Cutout()\n",
    "    ]\n",
    "    augment = \"Crop,Flip,AutoAugment,Cutout\"\n",
    "else: \n",
    "    dataAugmentation = []\n",
    "    augment = \"Nothing\"\n",
    "\n",
    "\n",
    "# We resize images to allow using imagenet pre-trained models, is there a better way?\n",
    "resize = transforms.Resize(224) \n",
    "\n",
    "transform_train = transforms.Compose(dataAugmentation + [resize, transforms.ToTensor(), normalize]) \n",
    "transform_val = transforms.Compose([resize, transforms.ToTensor(), normalize]) #careful to keep this one same\n",
    "\n",
    "cifar_train = datasets.CIFAR10(root='.',train=CIFAR_TRAIN, transform=transform_train, download=True)\n",
    "cifar_val = datasets.CIFAR10(root='.',train=CIFAR_TRAIN, transform=transform_val, download=True)\n",
    "\n",
    "ss = SmallSampleController(numClasses=10,trainSampleNum=TRAIN_SAMPLE_NUM, # abstract the data-loading procedure\n",
    "                           valSampleNum=VAL_SAMPLE_NUM, batchSize=BATCH_SIZE, \n",
    "                           multiplier=VALIDATION_SET_NUM, trainDataset=cifar_train, \n",
    "                           valDataset=cifar_val)\n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_data, valSets, seed = ss.generateNewSet(device,valMultiplier = VALIDATION_SET_NUM) #Sample from datasets\n",
    "\n",
    "\n",
    "\n",
    "eNet = getModel(MODEL).cuda()\n",
    "\n",
    "# for param in eNet.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "# model = featureExtractor(eNet).cuda()\n",
    "model = eNet\n",
    "\n",
    "# model.fc.out_features = 10\n",
    "\n",
    "print(model.parameters)\n",
    "\n",
    "parameters = list(model.features[26:].parameters()) +  list(model.classifier.parameters())\n",
    "    \n",
    "optimizer,LR = getOptimizer128(OPTIM, parameters)\n",
    "\n",
    "# print(model.features[28:].parameters() + model.classifier.parameters())\n",
    "print(' => Total trainable parameters: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))        \n",
    "\n",
    "trainTracker = {\"meanLoss\":[],\"accuracy\":[]}\n",
    "valTracker = {\"allLoss\":[],\"allAcc\":[],\"meanLoss\":[],\"meanAcc\":[],\"stdAcc\":[]}\n",
    "latexTracker = []\n",
    "\n",
    "print(\"Begin Train for {} epochs\".format(EPOCH_NUM))\n",
    "for epoch in range(EPOCH_NUM):\n",
    "    acc, loss = train(model, device, train_data[0], optimizer, epoch+1, display=True)\n",
    "    trainTracker[\"meanLoss\"].append(loss)\n",
    "    trainTracker[\"accuracy\"].append(acc)\n",
    "    \n",
    "    if (epoch+1) % VAL_DISPLAY_DIVISOR == 0:\n",
    "        checkTest(model,device,valSets,valTracker,latexTracker,epoch+1,\n",
    "              model_name=MODEL,optim_name=OPTIM,lr=LR,totalTestSamples=VAL_SAMPLE_NUM*VALIDATION_SET_NUM,\n",
    "                  seed=seed,verbose=True)\n",
    "        \n",
    "          \n",
    "# print(parameters)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latexTracker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1ef361c41e7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatexTracker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwriteTex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatexTracker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'latexTracker' is not defined"
     ]
    }
   ],
   "source": [
    "dirname = latexTracker[-1][:-2] \n",
    "\n",
    "def writeTex(latexTracker,dirname):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.mkdir(dirname)\n",
    "        \n",
    "    f= open(os.path.join(dirname,\"latexTable.txt\"),\"w\")\n",
    "    for x in latexTracker:\n",
    "        f.write(x)\n",
    "    f.close()\n",
    "\n",
    "writeTex(latexTracker,dirname)\n",
    "\n",
    "for x in latexTracker:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochList = [x+1 for x in range(len(trainTracker[\"meanLoss\"]))]\n",
    "\n",
    "plot(xlist=epochList,ylist=trainTracker[\"meanLoss\"],xlab=\"Mean Train Loss\",\n",
    "    ylab=\"Epochs\",title=\"Mean Train Loss over Epochs\",\n",
    "    color=\"#243A92\",label=\"mean train loss\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=trainTracker[\"accuracy\"],xlab=\"Train Accuracy\",\n",
    "    ylab=\"Epochs\",title=\"Train Accuracy Over Epochs\",\n",
    "    color=\"#34267E\",label=\"Train Accuracy\",savedir=dirname,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochList = [VAL_DISPLAY_DIVISOR*(x+1) for x in range(len(valTracker[\"meanLoss\"]))]\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"meanLoss\"],xlab=\"Epochs\",\n",
    "    ylab=\"Mean Val Loss\",title=\"Mean Val Loss over Epochs\",\n",
    "    color=\"#243A92\",label=\"mean val loss\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"meanAcc\"],xlab=\"Epochs\",\n",
    "    ylab=\"Val Accuracy\",title=\"Val Accuracy Over Epochs\",\n",
    "    color=\"#34267E\",label=\"Val Accuracy\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"stdAcc\"],xlab=\"Epochs\",\n",
    "    ylab=\"Val Accuracy Standard Deviation\",title=\"Val Accuracy Standard Deviation Over Epochs\",\n",
    "    color=\"#34267E\",label=\"Val Accuracy SD\",savedir=dirname,save=True)\n",
    "\n",
    "\n",
    "valSetEvalCount = VAL_DISPLAY_DIVISOR * EPOCH_NUM * VALIDATION_SET_NUM\n",
    "epochList = [VAL_DISPLAY_DIVISOR*(x+1) for x in range(len(valTracker[\"meanLoss\"]))\\\n",
    "             for y in range(VALIDATION_SET_NUM)]\n",
    "\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"allLoss\"],xlab=\"Val Set Evaluations\",\n",
    "    ylab=\"Val Loss\",title=\"Val loss over val set evaluations ({} \\\n",
    "every {} epochs)\".format(VALIDATION_SET_NUM,VAL_DISPLAY_DIVISOR),\n",
    "    color=\"#34267E\",label=\"Val Loss\",savedir=dirname,save=True)\n",
    "\n",
    "plot(xlist=epochList,ylist=valTracker[\"allAcc\"],xlab=\"Val Set Evaluations\",\n",
    "    ylab=\"Val Accuracy\",title=\"Val loss over val set evaluations ({} \\\n",
    "every {} epochs) \".format(VALIDATION_SET_NUM,VAL_DISPLAY_DIVISOR),\n",
    "    color=\"#34267E\",label=\"Val Accuracy\",savedir=dirname,save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
